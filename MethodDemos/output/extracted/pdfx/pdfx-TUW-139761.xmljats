<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  SYSTEM "http://dtd.nlm.nih.gov/archiving/3.0/archivearticle3.dtd">
<article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns:mml="http://www.w3.org/1998/Math/MathML"
         xmlns:xlink="http://www.w3.org/1999/xlink">
   <front>
      <journal-meta>
         <journal-id/>
         <journal-title-group>
            <journal-title/>
         </journal-title-group>
         <issn/>
         <publisher>
            <publisher-name/>
         </publisher>
      </journal-meta>
      <article-meta>
         <title-group>
            <article-title>Option Pricing by means of Genetic Programming</article-title>
         </title-group>
         <supplement>
            <p>DIPLOMARBEIT</p>
            <p>ausgeführt am Institut für Computer Graphik und Algorithmen der Technischen Universität Wien unter Anleitung von a.o. Univ.-Prof. Dipl.-Ing. Dr.techn. Günther Raidl und Univ.-Prof. Dr. Michael Hanke durch Andreas Heigl Markt 115 5611 GROSSARL</p>
            <p>Abstract</p>
            <p>This master thesis describes how to price options by means of Genetic Programming. The underlying model is the Generalized Autoregressive Conditional Heteroskedastic (GARCH) asset return process. The goal of this master thesis is to find a closed-form solution for the price of European call options where the underlying securities follow a GARCH process. The data are simulated over a wide range to cover a lot of existing options in one single equation. Genetic Programming is used to generate the pricing function from the data. Genetic Programming is a method of producing programs just by defining a problem- dependent fitness function. The resulting equation is found via a heuristic algorithm inspired by natural evolution. Three different methods of bloat control are used. Additionally Automatic Defined Functions (ADFs) and a hybrid approach are tested, too. To ensure that a good configuration setting is used, preliminary testing of many different settings has been done, suggesting that simpler configurations are more successful in this environment. The resulting equation can be used to calculate the price of an option in the given range with minimal errors. This equation is well behaved and can be used in standard spread sheet programs. It offers a wider range of utilization or a higher accuracy, respectively than other existing approaches.  Diese Diplomarbeit beschreibt, wie Optionen mit Hilfe Genetischer Programmierung bewertet werden können. Das zugrunde liegende Modell nennt sich GARCH (Generalized Autoregressive Conditional Heteroskedastic) Renditeprozess. Das Ziel dieser Diplomarbeit ist eine geschlossene Formel, die als Ergebnis den Preis einer europäischen Kaufoption liefert, dessen dahinter liegende Wertpapier einem GARCH Prozess folgt. Die Daten werden innerhalb eines breiten Wertebereiches simuliert, um die meisten existierenden Optionen mit einer Formel bewerten zu können. Die Formel wird mittels Genetischer Programmierung aus den Daten generiert. Genetische Programmierung ist eine Methode, bei der nur durch Definition einer zum Problem passenden Bewertungsfunktion vollständige Programme produziert werden können. Die Ergebnisgleichung wird schließlich mittels eines der Evolution ähnlichen Algorithmus gefunden. Drei verschiedene Methoden zum Bloat Control wurden verwendet. Zusätzlich wurden auch Automatisch Definierte Funktionen sowie ein hybrider Ansatz untersucht. Um sicherzustellen, dass eine gute Konfiguration gewählt wird, gibt es Vortests vieler verschiedener Konfigurationen. Es zeigt sich, dass in diesem Umfeld einfachere Konfigurationen erfolgreicher sind. Die Ergebnisgleichung kann schließlich zur Errechnung der Optionspreise mit min- imalem Fehler verwendet werden. Diese Gleichung verhält sich gut und kann auch in Standardtabellenkalkulationen verwendet werden. Im Vergleich mit anderen existierenden Ansätzen, bietet diese Gleichung eine weitere Verwendbarkeit beziehungsweise eine höhere Genauigkeit.</p>
            <p>Zusammenfassung</p>
         </supplement>
      </article-meta>
   </front>
   <body>
      <sec>
         <title>Acknowledgements</title>
         <p>I have to thank my family, my professors and all my friends. Special thanks to Dr. Hanke, who has helped me to find this interesting topic of research and to Dr. Raidl, who has showed me how to write a good master thesis. All the brave programmers who have made libraries I have used, are mentioned here too. Magister Katarina Kocian has read my thesis very often to find even the last mistake. Without these people it would not have been possible to write this thesis.</p>
      </sec>
      <sec>
         <title>Contents</title>
         <p>6</p>
      </sec>
      <sec>
         <title>1 Introduction 2 Option pricing</title>
         <p>8</p>
         <p>2.1 Basic approaches in option pricing . . . . . . . . . . . . . . . . . . . . . 8 2.1.1 Some definitions and basic models . . . . . . . . . . . . . . . . . 8 2.1.2 The Black-Scholes formula . . . . . . . . . . . . . . . . . . . . . 10 2.2 Discrete-time stochastic processes and the GARCH model . . . . . . . 11 2.2.1 Discrete-time stochastic processes . . . . . . . . . . . . . . . . . 11 2.2.2 The GARCH model . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.2.3 Monte Carlo simulation of a GARCH process . . . . . . . . . . 12</p>
      </sec>
      <sec>
         <title>3 Overview of Genetic Programming</title>
         <p>15</p>
         <p>3.1 Genetic algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 3.1.1 Basic terminology . . . . . . . . . . . . . . . . . . . . . . . . . . 16 3.1.2 Flowchart of a simple genetic algorithm . . . . . . . . . . . . . . 18 3.1.3 Additional settings . . . . . . . . . . . . . . . . . . . . . . . . . 18 3.2 Genetic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.2.1 Terminal set and function set . . . . . . . . . . . . . . . . . . . 20 3.2.2 Creation of the initial population . . . . . . . . . . . . . . . . . 20 3.2.3 Genetic operations . . . . . . . . . . . . . . . . . . . . . . . . . 21 3.2.4 Automatic defined functions . . . . . . . . . . . . . . . . . . . . 23 3.2.5 Bloat control . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.2.6 Control parameters . . . . . . . . . . . . . . . . . . . . . . . . . 24</p>
      </sec>
      <sec>
         <title>4 A survey of existing approaches in option pricing</title>
         <p>26</p>
         <p>4.1 Neural networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26 4.2 Markov chain approximation . . . . . . . . . . . . . . . . . . . . . . . . 27 4.3 Genetic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . 29</p>
      </sec>
      <sec>
         <title>5 Strategic decisions of the new approach</title>
         <p>31</p>
         <p>5.1 GARCH process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 5.2 Genetic Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 5.2.1 Functions and terminals . . . . . . . . . . . . . . . . . . . . . . 32 5.2.2 Fitness function and bloat control . . . . . . . . . . . . . . . . . 32</p>
         <p>5.2.3 Population size, number of generations and mutation . . . . . . 34 5.2.4 Automatic defined functions and hybrid approaches . . . . . . . 34</p>
      </sec>
      <sec>
         <title>6 Implementation details</title>
         <p>36</p>
         <p>6.1 Libraries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 6.1.1 The Genetic Programming kernel . . . . . . . . . . . . . . . . . 36 6.1.2 A random number generator library . . . . . . . . . . . . . . . . 38 6.1.3 GNU Scientific Library . . . . . . . . . . . . . . . . . . . . . . . 40 6.2 New classes and functions . . . . . . . . . . . . . . . . . . . . . . . . . 41 6.2.1 Additional functions . . . . . . . . . . . . . . . . . . . . . . . . 41 6.2.2 GPOPdata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 6.2.3 MyGPVariables . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 6.2.4 MyGene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 6.2.5 MyGP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.2.6 MyPopulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.2.7 Executables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.3 Overview UML diagram . . . . . . . . . . . . . . . . . . . . . . . . . . 44</p>
      </sec>
      <sec>
         <title>7 Results and statistics</title>
         <p>46</p>
         <p>7.1 Statistics of the identification of the best configuration . . . . . . . . . 46 7.1.1 Setting of the test environment . . . . . . . . . . . . . . . . . . 46 7.1.2 Test results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 7.1.3 Utilization of the ADFs and the hybrid approaches . . . . . . . 49 7.2 Comparison of the best equation found with the original process . . . . 50 7.2.1 Setting of the Genetic Algorithm . . . . . . . . . . . . . . . . . 50 7.2.2 The result . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50 7.2.3 The original process . . . . . . . . . . . . . . . . . . . . . . . . 52 7.3 Comparison of the results with other approaches . . . . . . . . . . . . . 54 7.3.1 Comparison of the result with [Han98] . . . . . . . . . . . . . . 56 7.3.2 Comparison of the result with [DS01] . . . . . . . . . . . . . . . 56 7.3.3 Comparison of the result with [Keb99] . . . . . . . . . . . . . . 57</p>
      </sec>
      <sec>
         <title>8 Conclusion</title>
         <p>58</p>
         <p>8.1 New approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 8.2 Summary of the result . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 8.3 Future issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59</p>
      </sec>
      <sec>
         <title>Chapter 1 Introduction</title>
         <p>Options are derivative securities. At expiration date the value of an option is exactly determined by an underlying cash instrument. The process of finding the value of an option before expiration date is called option pricing. The history of the theory of option pricing began in 1900 when the French mathematician Louis Bachelier derived an option pricing formula. His formula is based on the assumption that stock prices follow a Brownian motion with zero drift. Since that time, numerous researchers have contributed to the theory. In the year 1973 Fischer Black, Myron Scholes and Robert Merton made a breakthrough in the pricing of options. They have derived a single equation for pricing options, under the assumption of a lognormal distribution of the underlying asset. Still there are some problems with the model’s assumption. Empirical evidence (compare with [BC <xref id="XR41" ref-type="bibr" rid="R19">K92]) has shown that the underlying securities do not behave according to that assumption. The probability of large price changes is much higher than it should be possible under the lognormality assumption. Another typical feature of empirical return distributions is called heteroskedasticity, the changing of the variance in time. In practise, many return series show volatility clustering, where bad news lead to a significant increase of the volatility. After some time volatility returns to the old value. The GARCH (Generalized Autoregressive Conditional Heteroskedas- ticity) model of Tim Bollerslev is an answer to these problems. Jin-Chuan Duan has developed an option pricing model for underlyings following GARCH processes. Still one drawback remains. It is not possible to derive a closed-form equation for option pricing similar to the Black-Scholes formula. Option prices can only be calculated via Monte Carlo simulation, which is computationally expensive and time consuming. Meanwhile new approaches to solve complex problems evolved in the field of com- puter science. Many of them have been inspired by the way nature “solves problems”. Neural networks are now widely used in different areas. [Hol75] introduced the concept of Genetic Algorithms, which is very successful in the field of Operations Research. [Koz92] enhanced the Genetic Algorithm to the so called Genetic Programming ap- proach, which is applicable in fields as different as electrical engineering and symbolic regression (compare with [K + 03</xref>]). Brokers frequently need to make decisions within seconds. Until recently it was not possible to use the GARCH model for more than a small number of options, because it takes too much time to perform a Monte Carlo simulation. [Han98] used a Neural Network to overcome this problem. [DS01] provide a Markov chain approximation. This master thesis will use Genetic Programming to derive an approximate analytic formula for pricing options when the underlying follows a GARCH process. The thesis is organized as follows. Chapter 2 provides a brief overview of the concepts of option pricing. Chapter 3 introduces Genetic Programming. Chapter 4 gives an overview of existing approaches. They are all related to this work and are used as a benchmark for the results. Our new approach is presented in chapter 5. It shows also the strategic modus operandi of this work. Chapter 6 discusses implementation issues. This chapter also gives information about the libraries used, which are freely available on the internet. Chapter 7 gives a detailed experimental analysis of the results and a comparison to existing approaches. It includes statistical tests to find out the best configurations. Chapter 8 concludes this master thesis and gives some suggestions for further research.</p>
      </sec>
      <sec>
         <title>Chapter 2 Option pricing</title>
         <p>This chapter gives a brief overview of option pricing and shows approaches which are used in later chapters. A comprehensive introduction to option pricing can be found in [Hul02]. Some of the more complex mathematical aspects can be found in [Nef00].  2.1 Basic approaches in option pricing 2.1.1 Some definitions and basic models According to [Nef00], p. 2 “a financial contract is called a derivative security , or a contingent claim, if its value at expiration date T is determined exactly by the market price of the underlying cash instrument at time T. Hence, at the time of expiration of the derivative contract, denoted by T, the price F(T) of a derivative asset is completely determined by S(T), the value of the underlying asset. After that date, the security ceases to exist.” The underlying asset can be • stocks, • currencies, • interest rates, • indexes • commodities like crude oil, gold and many more. It is possible to group derivative securities under three general headings: • Futures and forwards • Options • Swaps A future and a forward contract is an obligation to buy (or sell) an underlying asset at a specified price on a known date. If the specified price is not equal to the market price of the underlying at expiry the holder of the contract makes a loss or a profit. In contrast to that, an option is the right, but not the obligation to buy (or sell) the underlying asset at a specified price on a specified date. The specified price in the contract is known as the exercise price or strike price . The specified date in the contract is known as the expiration date or maturity . If it is a right to buy it is a call option , if it is a right to sell it is a put option (compare with [Hul02] p. 1 - 15). Options may be classified by their exercise mode: American options can be exercised at any time up to the expiration date. European options can only be exercised on the expiration date itself. If X is the strike price and S T is the final price of the underlying asset, the payoff at the expiration time of a European call option is</p>
         <p>This reflects the fact that the option will be exercised if S T &gt; X and will not be exercised if S T &lt; X . Similarly the payoff at expiration time of a European put option is</p>
         <p>Before expiration, the price of a stock option is affected by six factors ([Hul02]): • Current stock price. • Strike price. • Risk-free interest rate • Volatility of the stock price, which is the annualized standard deviation. • Time to expiration. • Dividends expected during the life of the option. If the current stock price is high then it is more likely that the stock price at expiration time will be high too. According to equation 2.1 the value of a call option will be higher when the stock price is higher at expiration time. The strike price is not subject to change until the expiration date and influences the value of the option in a direct manner. The risk-free interest rate affects the price of an option in a less clear-cut way. As interest rates in the economy increase, the expected growth rate of the stock price tends to increase. However, the present value of any future cash flow received by the holder of the option decreases.  As volatility increases, the chance that the stock will do very well or very poorly increases. For the owner of the underlying, these two outcomes tend to offset each other. However the owner of a call benefits from price increases but has limited downside risk in the event of price decreases because he has no obligation to exercise the option. Therefore as volatility increases the value of an option also increases. The time to expiration influences the value of a call option in two ways. More time until expiration means a higher change of large changes in the underlying price, which increases the price of options. At the same time more interest has to be paid. This decreases the value of an option. According to [Hul02] p. 170, dividends have the effect of reducing the stock price on the ex-dividend date. This is bad news for the value of call options and good news for the value of put options. The value of a call option is therefore negatively related to the size of any anticipated dividends, and the value of a put option is positively related to the size of any anticipated dividends. The moneyness ratio is defined as S t /X . A call option is called out-of-the-money if the moneyness ratio is less than 1. If it is worth more than 1, it is called in-the-money. In case it is close to 1 it is called at-the-money. 2.1.2 The Black-Scholes formula As long as it is possible to determine which process the underlying will follow in the future it is possible to calculate the price of an option before the expiration date too. Because there are countless factors which can influence the price of a stock and these factors are usually not known in advance the process cannot be deterministic, but is stochastic. Stochastic processes can be classified as discrete-time or continuous-time. A discrete-time stochastic process is one where the value of the variable can change only at certain fixed points in time, whereas a continuous-time stochastic process is one where change can take place at any time (compare with [Hul02] p. 216). A Wiener process or Brownian motion is a continuous-time stochastic process. It is a particular type of Markov stochastic process with a mean change of zero and a variance rate of 1.0 per year. A good overview of the properties of a Wiener process may be found in [Nef00] p. 173 - 202. We are assume that the underlying follows a generalized Wiener process</p>
         <p>where S is the price of the underlying, dt is the time between two measure points, μ is the expected return of the underlying, σ is the volatility of the process and z is a standard Wiener process. This equation implies that stock prices have the lognormal property. This means that the percentage changes ( dS/S ) of stock prices are normally distributed. [BS73] found a solution to a stochastic differential equation derived from this process by constructing a locally riskless hedge-portfolio. This leads to the following formula</p>
         <p>for pricing call options:</p>
         <p>The function N ( x ) is the cumulative standard normal probability distribution function. Furthermore r is the riskless interest rate and T is the time left to maturity. A derivation of this formula can be found in [Nef00].  2.2 Discrete-time stochastic processes and the GARCH model 2.2.1 Discrete-time stochastic processes Another approach to model the price process of the underlying are discrete-time stochastic processes. In contrast to the generalized Wiener process, only discrete time steps are used. The discretized version of the generalized Wiener process leads to the following equation:</p>
         <p>where S t is the price of the underlying at time t , μ is its expected return, σ its volatility and ε t is a normally distributed random variable with mean 0 and variance σ 2 . The left-hand side of the equation is defined as the yield ( y ) of the underlying. With the yield it is possible to calculate S t from S t − 1 via the following formula:</p>
         <p>As can be seen from equation 2.7 the Black-Scholes model assumes that the probability distribution of the underlying asset at any given future time is lognormal, which is a less than perfect assumption because the probability of high losses and profits is much higher in reality. Therefore the true probability distribution seems to have a higher kurtosis than the normal distribution. Another wrong assumption of the Black- Scholes model is that the volatility of the underlying is constant in time (compare [Hul02] p. 331 - 345).  2.2.2 The GARCH model The Generalized Autoregressive Conditional Heteroskedasticity (GARCH) model was first introduced by [Bol86]. It is a more flexible variant of the ARCH model proposed by [Eng82]. A good overview of the different types and applications of the GARCH model can be found in [BCK92]. The GARCH model is a discrete-time stochastic process. Every GARCH process consists of two equations. One defines the mean, the other the conditional variance. The yield of a GARCH(1,1) process is defined as</p>
         <table-wrap id="Tx81">
            <caption>
               <p>Table 2.1: Input data</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> parameter</td>
                     <td> description</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> S t /X</td>
                     <td> moneyness ratio</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> interest rate</td>
                  </tr>
                  <tr>
                     <td> σ 2</td>
                     <td> unconditional variance</td>
                  </tr>
                  <tr>
                     <td> T − t</td>
                     <td> expiration time</td>
                  </tr>
                  <tr>
                     <td> √ h t /σ relation between</td>
                     <td> conditional and unconditional standard deviation</td>
                  </tr>
                  <tr>
                     <td> a 1</td>
                     <td> GARCH parameter</td>
                  </tr>
                  <tr>
                     <td> b 1</td>
                     <td> GARCH parameter</td>
                  </tr>
                  <tr>
                     <td> λ</td>
                     <td> risk premium</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>with</p>
         <p>where r is the riskless interest rate, S t is the price of the underlying at time t , λ is the risk premium, h t is the conditional variance, a 0 , a 1 , b 1 are GARCH parameters and η t is a normally distributed random variable with mean 0 and variance h t ( η t ∼ N (0 , h t )). The difference between a GARCH process and the discretized Geometric Brownian motion (used in the Black-Scholes model) is that the variance may now change over time. The variance ( h t ) depends on the GARCH parameters ( a 0 , a 1 , a 2 ), the variance from one period before and random disturbances ( η t ). Although η t is normally distributed, the unconditional variance of the whole process is not normally distributed. Therefore, depending on the values of the GARCH parameters, the distribution is not the same as in the Black-Scholes framework (compare with [Han98]). Usually a GARCH process is estimated by the maximum-likelihood method, where all parameters ( a 0 , a 1 and b 1 ) are estimated at the same time. To produce sample time-series Monte Carlo simulation might be used. Until yet it was not possible to find a solution for the differential equations of the GARCH process in general.  2.2.3 Monte Carlo simulation of a GARCH process The data will be simulated according to [Dua95] and [GS96]. In [Dua95] the concept of locally risk-neutral valuation relationship (LRNVR) was introduced. The LRNVR leads to a transformation of the formula of the yield and the conditional variance, which holds under realistic assumptions about the behavior of investors. The given input data are shown in <xref id="XR95" ref-type="table" rid="T2.1">table 2.1</xref> and are usually estimated from historical data. The condition a 1 + b 1 &lt; 1 must always be satisfied, otherwise the unconditional variance is not defined. The GARCH parameter a 0 is given by the following formula:</p>
         <p>The next conditional variance is given by</p>
         <p>where η t 2 = h t in the first case. Next time the i th instance (this means the i th path of simulation) of η t +1 ,i is constructed with standard normal random numbers z t +1 ,i :</p>
         <p>The yield, error term and conditional standard deviation at the next time points u = t + 2 , ..., T are calculated equally:</p>
         <p>with</p>
         <p>And finally the price of an European call option relative to the strike price K at time t:</p>
         <p>To decrease the variance of the different simulation paths variance reduction methods are used. This reduces the time to do the simulation. [BBG97] describes the theoretical fundamentals of this approach. Three methods are described.  The method of antithetic variates is described in [BBG97]. For each set of random numbers ( z ui ) another set with negative values of these random numbers ( − z ui ) is calculated. An option price is calculated by using the original random numbers ( z ui ), another by using the negative value of the original random numbers. The variance reduced price is the average of these two prices. The second is the Empirical Martingale Simulation (EMS) introduced by [DS95]. It is a simple enhancement of the Monte Carlo simulation that ensures that the price estimated satisfies rational option pricing bounds. The new simulation procedure generates the EMS asset prices at a sequence of time points, t 1 , t 2 , ..., t m using the following dynamics:</p>
         <p>where</p>
         <p>Note that S i ( t ) is the i t h simulated asset path at time t prior to the EMS adjustment. The last one is called the control variate method which is described in [BBG97]. With the same random numbers used in the calculation of GARCH prices ( P gsim ) Black-Scholes prices are simulated by using equation 2.8 which leads to a simulated Black-Scholes price ( P bssim ). But the Black-Scholes price ( P bsana ) can also be calculated analytically by the Black-Scholes formula given in 2.4. The new GARCH(1,1) price ( P gcv ) after the control variate correction is</p>
         <p>The β should be chosen to minimize the variance and is therefore:</p>
      </sec>
      <sec>
         <title>Chapter 3 Overview of Genetic Programming</title>
         <p>Genetic Programming has been introduced in [Koz92]. It is based on genetic algorithms which were originally described in [Hol75]. These two basic approaches will be introduced in the following sections.  This section gives a brief overview of genetic algorithms. More information can be found in [BFM97] or in [Mic92]. In biology the evolutionary process results in a selection of the fittest individual in a given environment. The environment might be a specific area, a continent or the whole world. In [Hol75] a general framework for adaptive systems is given. The book shows how these adaptive systems (like the evolutionary process) might be applied to artificial systems. Any problem in adaptation can generally be formulated in genetic terms. Once formulated in those terms, such a problem can often be solved by what we now call the “Genetic algorithm” (compare with [Koz92], p. 17-18). [Mic92], p. 14 states: “The idea behind genetic algorithms is to do what nature does. Let us take rabbits as an example: at any given time there is a population of rabbits. Some of them are faster and smarter than other rabbits. These faster, smarter rabbits are less likely to be eaten by foxes, and therefore more of them survive to do what rabbits do best: make more rabbits. Of course, some of the slower, dumber rabbits will survive just because they are lucky. This surviving population of rabbits starts breeding. The breeding results in a good mixture of rabbit genetic material: some slow rabbits breed with fast rabbits, some fast with fast, some smart rabbits with dumb rabbits and so on. And on the top of that, nature throws in a ‘wild hare’ every once in while by mutating some of the rabbit genetic material. The resulting baby rabbits will (on average) be faster and smarter than those in the original population because more faster, smarter parents survived the foxes.” 3.1.1 Basic terminology A genetic algorithm works on individuals (or genotypes, structures ), which might be a living organism in nature or a solution to a known problem in an artificial system (= environment ). Each individual is completely described by its constant-size genome . This genome or chromosome may be encoded in bits and bytes, alphanumerical letters or nucleotide bases, like it is done in nature. Chromosomes are also called strings . In nature every species carries a certain number of chromosomes (humans for example, have 46 of them). However in artificial problems usually one chromosome is sufficient. Chromosomes are made of units - genes (also called features , characters ) - arranged in linear succession. Every gene controls the inheritance of one or several characters (compare with [Mic92]). Every individual has an associated fitness value. This fitness value describes the capability of an individual to survive in the environment . Operations designed to mimic the Darwinian principle of reproduction and survival of the fittest are used on a set of individuals (= population ). A population therefore consists of many individuals which are in general different, but it can also contain identical individuals . An algorithm describes which individuals are going to survive where the individuals with better fitness will have a competitive advantage. According to [Mic92] p. 17-18 a genetic algorithm for a particular problem must have the following five components: • a genetic representation for potential solutions to the problem, • a way to create an initial population of potential solutions, • an evaluation function that plays the role of the environment, rating solutions in terms of their fitness, • genetic operators that alter the composition of children during reproduction, • values for various parameters that the genetic algorithm uses (population size, probabilities of applying genetic operators, etc.). Genetic operations which determine a genetic algorithm are reproduction where one individual can reproduce itself (in real life this means that it is able to live longer than the others). crossover or sexual reproduction where two individuals ( parents ) produce one or more individuals. mutation where the genome of an individual (and therefore the individual itself too) are changed in a random way. 3.1.2 Flowchart of a simple genetic algorithm In <xref id="XR151" ref-type="fig" rid="F3.1">figure 3.1</xref> the basic steps of a genetic algorithm are shown. First the generation (=population) counter is set to zero. Then an initial population is generated randomly and the fitness of each individual in the population is examined. If the termination criterion is already satisfied, the genetic algorithm will stop and the result may be used. The termination criterion might be a limit on the number of generations or a specific quality criterion of the individuals. The result is usually the best individual found in the whole algorithm. To produce a new generation the variable i counts the number of new individuals, which will be set to zero initially. The number of individuals in each population equals M . The next steps are repeated until M new individuals have been created. The three different genetic operations are chosen randomly. With probability P r an individual is simply selected, reproduced and copied to the new population. With probability P m an individual will be mutated and with probability P c crossover will occur. In this case two individuals are selected, some kind of crossover is performed and the two offspring are copied into the new population. This is repeated until the new generation is completed. The generation counter is now increased. Then the fitness of each individual is evaluated to find out whether the termination criterion is satisfied. 3.1.3 Additional settings There are numerous minor variations of the basic genetic algorithm shown in <xref id="XR153" ref-type="fig" rid="F3">figure 3.1</xref>. Some approaches put the mutation operation after crossover and reproduction with some (low) probability. It is not shown how the crossover operation is done exactly. This is often domain dependent, which means that it depends on the specific problem the genetic algorithm is supposed to solve. Another variation is called the steady state framework which is first used in [Rey92] and was originally proposed in [Hol75]. In this case the new population is not produced at once and then replaces the old one, but there exists just one population. The parents are chosen from this population and the generated offsprings are immediately incorporated into the population by replacing one or two existing individuals. The individuals to be replaced can be the worst or randomly chosen ones. An iteration (generations do not exist any more) is considered as completed, once the number of children created by this method is equal to the size of the population. This procedure saves memory and increases the convergence. The disadvantage is that it increases the danger of premature convergence which leads to worse results. Two selection strategies are important to mention (compare [Fra94]). Possible solutions or chromosomes are assigned a fitness f by the fitness function. In fitness proportionate selection , the probability P selection that a specific individual y will be selected is</p>
         <p>3.1 Genetic algorithms</p>
         <p>Gen:=0 Create initial random population Termination Designate Yes criterion satisfied? result No End Evaluate fitness of each individual in population i:=0 Gen:=Gen+1 Yes i=M? No Select genetic operation probabilistically P r P m P c Select one Select two Select one individual based individuals based individual based on fitness on fitness on fitness Perform i:=i+1 Perform mutation redproduction Perform Copy into new Crossover Insert mutant into population new population Insert two offspring into new population i:=i+1</p>
         <fig id="F3.1">
            <caption>
               <p>Figure 3.1: Flowchart of a simple genetic algorithm. Source: [Koz92]</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>where N is the number of individuals in the population. While candidate solutions with a lower fitness will be less likely to be selected, there is still a chance that they may be. Contrast this with a less sophisticated selection algorithm, such as truncation selection, which will choose a fixed percentage of the best candidates. With fitness proportionate selection there is a chance some weaker solutions may survive the selection process; this is an advantage, as though a solution may be weak, it may include some components which could prove useful following the recombination process. Tournament selection chooses a specific number of individuals from the population (for example 10). These individuals are selected randomly with each individual having the same probability to be chosen. Then the best one or best two of these individuals will be selected for the genetic operation. This method is easier to implement and more robust than fitness proportional selection. The disadvantage is that the fitness measure is no longer an absolute value which determines the probability to be chosen. The fitness measure just provides a relative measure for the selection process. With demetic grouping the selection process may also be altered. In this case the whole population is subdivided into a number of groups. These groups undergo their own genetic algorithm and interact only rarely. This allows the demes to evolve along separate paths with solutions differing more from each other, which might lead to better individuals at later generations.  Genetic Programming was introduced by [Koz92]. A good introduction can be found in [BNKF98]. It is an extension of the genetic algorithms where the chromosomes are of variable size. The chromosomes now describe hierarchical computer programs encoded in tree-like structures. This leads to additional complexity and some further issues described in the following subsections. According to [KBAK99], p. 33 the five major preparatory steps for Genetic Programming entail determining 1. the set of terminals (e.g., the actual variables of the problem, zero-argument functions, and random constants, if any) for each branch of the to-be-evolved computer program, 2. the set of primitive functions for each to-be-evolved branch, 3. the fitness measure (or other arrangements for explicitly measuring fitness), 4. the parameters for controlling the run, and 5. the termination criterion and the method of result designation for the run. 3.2.1 Terminal set and function set An example of a genetic program is given in <xref id="XR166" ref-type="fig" rid="F3">figure 3.2</xref>. With this tree-like representation it is possible to describe every computer program. In the example we have an IF statement, some elementary mathematical functions, variables and a constant. The statements may be subdivided into a function set and a terminal set . The terminal set consists of end-points of the tree (=leaves) which do not have any arguments. The variables and constants are subsets of it. The function set statements or non-terminals all have arguments (one or more subtrees) and consist of the subsets of arithmetic operations (+,-,*,/), mathematical functions (such as sin, log), Boolean operations, conditional operations (like IF) and functions causing iterations (like do-until loops). The function and the terminal set must fulfill two properties. The closure property requires that each of the functions be able to accept, as its arguments, any value and data type that may possibly be returned by any function and any value that may possibly be assumed by any terminal (compare with [Koz92], p. 81 - 88). The divide function for example does not fulfill the closure property when the second argument is zero. Solutions to this problem are to define an extra value, like “undefined” or the function may return a very high (or very low when maximizing) value. The sufficiency property requires that the set of terminals and functions are in principle capable of expressing a solution to the given problem. 3.2.2 Creation of the initial population The initial population of Genetic Programming is usually created in some random way. Here, we have the problem of variable size chromosomes. The type of creation performed can (according to [<xref id="XR168" ref-type="bibr" rid="R22">Koz92</xref>], p. 91 - 94) be one of five types: Variable: Where a created genetic program can be of a size or structure up to the maximum depth specified for creation. This means that at any point in the tree a function or terminal is arbitrarily chosen. If the maximum size is reached (which need not be the case) a terminal will be selected.</p>
         <p>3.2 Genetic Programming</p>
         <p>+ IF ln &lt; X / Y X Y 2 Y</p>
         <fig id="F3.2">
            <caption>
               <p>Figure 3.2: An example of a genetic program</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
      </sec>
      <sec>
         <title>Grow:</title>
      </sec>
      <sec>
         <title>Ramped</title>
      </sec>
      <sec>
         <title>Ramped</title>
      </sec>
      <sec>
         <title>Ramped</title>
         <p>Where the creation mechanism can only choose functions until the maximum depth is reached when a terminal must be chosen. This causes the size and structure of the genetic program to be the same in all random creations. variable: It changes the variable creation type so that the creation mechanism attempts to produce genetic programs with increasing limiting depths up to the maximum depth for creation. grow: It changes the grow creation type so that the creation mechanism attempts to produce genetic programs with increasing limiting depths up to the maximum depth for creation. half-and-half: This is the creation mechanism used in the majority of Genetic Programming applications. The algorithm permits half the population to be created with ramped variable and the other half to use ramped grow (compare with [Fra94]).</p>
         <p>3.2.3 Genetic operations Reproduction is defined similarly as in the genetic algorithm approach. It just copies the selected individual to the next generation. Crossover is a little more complicated. <xref id="XR176" ref-type="fig" rid="F3.3">Figure 3.3</xref> shows two parents and two possible offsprings. After two parents have been selected, one random point in each parent has to be found. In <xref id="XR177" ref-type="fig" rid="F3.3">figure 3.3</xref> these are in both cases the right-hand sides after the root functions. Note that the two parents typically are of unequal size and that the crossover point may also be above a terminal. Then the subtrees are exchanged and the results are the two children for the new generation (compare [Koz92], p. 101 - 105). If accidentally the newly created individuals are bigger than the maximum allowed size, new crossover points have to be chosen and the crossover operation is repeated. The mutation operation introduces random changes in structures of the population. The point where mutation takes place may be chosen randomly like it is done in the crossover operation. According to [Fra94], two types of mutation are meaningful. Allele mutation just swaps an n -argument function with another n -argument function or a terminal with another terminal. This operation preserves the shape of an individual. Shrink mutation as described in [Fra94] takes the child of a particular gene and moves that child into the position of the parent. This means that genetic programs will shrink. This is a particularly useful property considering how large some genetic programs get as the evolutionary process continues. In [KBAK99], p. 43 - 44, another approach to mutate genetic programs is used. A random point is chosen in the parental program. The subtree rooted at the chosen mutation point is deleted from the program, and a new subtree is randomly grown, using the available functions and terminals in the same manner as trees are grown when creating the initial random population of generation 0. Then the random subtree is implanted at the chosen mutation point. According to [KBAK99], p. 44, “the mutation operation is generally sparingly used in Genetic Programming”. An operation which is not defined in genetic algorithms is editing . This operation is asexual in that it operates on only one individual. The editing operation applies some domain-specific editing rules. This usually decreases the size of individuals by mathematical simplifications of formulas and similar editing rules. 3.2.4 Automatic defined functions In [Koz94] the concept of automatic defined functions (=ADF) is elaborated in detail. With ADFs the search space may be significantly decreased by using problem domain knowledge. In fact ADFs correspond to the concept of subroutines which may be reused many times by the main program. Therefore the set of non-terminals will be augmented by some ADFs (=subroutines) in the main tree. These subroutines may have a specific (domain dependent) number of arguments. Each ADF now is a genetic program itself and has a terminal and a non-terminal set, which might be useful to a specific problem. If a problem can be divided into subproblems then ADFs are useful. The description of each ADF equals the description of the subproblem. In general it is not necessary to have premature knowledge of the subproblem. This can be solved by the Genetic Programming algorithm. The whole problem may then be solved by using the solutions of the ADF. Another advantage is that an ADF might be used in the main genetic program more than once. This increases the efficiency of the genetic program. If ADFs are used in addition to the five major preparatory steps (compare with chapter 3.2), the architecture of the to-be-evolved program must be determined in some way. For example this can be the number of different ADF’s and the number of arguments each ADF has. According to [KBAK99] p. 71 - 74, five methods have been used previously for making the necessary architectural choices. The first four of these methods are manual; the fifth is an automated technique: 1. prospective analysis of the nature of the problem, where human insight is used after analyzing the problem in advance, 2. retrospective analysis of the results of actual runs of similar problems, 3. seemingly sufficient capacity, 4. affordable capacity, which might be the memory-size of a computer, and 5. evolutionary selection of the architecture. The last method uses the same genetic algorithm to choose the architecture. After generation 0, there is a competition among the existing architectures during the course of the run. This means that individuals with different architectures exist in every population. A whole book [KBAK99] describes in detail all the problems which arise from this approach and how new architectures may emerge and bad architectures may disappear. 3.2.5 Bloat control When evolutionary computation uses arbitrarily-sized representations, often the evolutionary process progresses not only towards fitter individuals, but to dramatically larger individuals. This rapid increase in size, known as bloat, can hinder the evolutionary mechanism itself and can slow down successive generations to a point where further progress is not feasible anymore (compare with [PL04]). This is especially true when Genetic Programming gets out of memory. According to [PL04], the most common approach to bloat control is establishing hard limits on size or depth, primarily because this approach was popularized by early work in Genetic Programming [Koz92]. If a newly created child is deeper than a specific number, it is rejected and a new child will be created with lower depth. Depth limiting has proven a surprisingly successful method and usually all other methods are combined with some restrictions on tree depth as well. Another straightforward approach is called parsimony pressure . Parsimony pressure has often been parametric, meaning that it considers the actual value of size and fitness together in a parametric statistical model for selection. This may easily be done by adding a penalty to the fitness function which is proportional to the size of the individual. Care has to be taken of the penalty factor, because this influences Genetic Programming in a high manner. A penalty factor that is too high leads to small (in size) but poor (in quality) results. [PL04] suggests a new approach which is called death by size . Death by size is intended for methods such as steady-state evolution which requires a procedure for marking individuals for death. The bloat control approach uses fitness to select individuals for breeding, as usual, but when selecting an individual for death, selection is done by size (preferring to kill larger individuals). 3.2.6 Control parameters [Koz92] has defined 19 control parameters which determine a Genetic Programming algorithm. These control parameters include such important variables as the population size, the maximum number of generations and some probabilistic values. In <xref id="XR188" ref-type="table" rid="T3.1">table 3.1</xref> these parameters are shown with the default values proposed by [Koz92]. Of course in practice the values of the control parameters should be domain-dependent.</p>
         <p>+ IF ln X Y &lt; X / Y X Y 2 Y + IF Y X ln &lt; X / Y X Y 2 Y</p>
         <fig id="F3.3">
            <caption>
               <p>Figure 3.3: An example of a crossover operation</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Parameter Default value Population size 500 Maximum number G of generations to be run 51 Probability of crossover 90 % Probability of reproduction 10 % Probability of choosing internal points for crossover 10 % Maximum size for S-expressions created during the run 17 Maximum size for initial random S-expressions 6 Probability of mutation 0% Probability of permutation 0% Frequency of editing 0 Probability of encapsulation 0% Condition for decimation NIL Decimation target percentage 0% Generative method for initial random population ramped half-and-half Basic selection method fitness proportionate Spousal selection method fitness proportionate Adjusted fitness used Over selection not used Elitist strategy not used</p>
         <table-wrap id="T3.1">
            <caption>
               <p>Table 3.1: Control parameters</p>
            </caption>
         </table-wrap>
      </sec>
      <sec>
         <title>Chapter 4 A survey of existing approaches in option pricing</title>
         <p>This chapter gives a brief overview of existing approaches in option pricing. [Han97] and [DS95] use two different methods to price options, where the underlying follows a GARCH process. [Keb99] is the first attempt to use Genetic Programming in option pricing at all. He assumes that the underlying follows a Wiener process (compare with chapter 2.1.2). These approaches will also be used later to assess the quality of the results of the new approach. The new approach will use Genetic Programming to price options following a GARCH process (compare with chapter 5).  The first approach to use neural networks for pricing options according to a GARCH model was introduced by [Han98] (some results may also be found in [Han97]). In this doctoral thesis a huge variation of different models and options have been estimated by neural networks. It ranges from European to Asian options, from the Black-Scholes framework to the GARCH framework and even empirical data have been used to train the neural networks. At the end an adaptive non-linear model has been proposed, which is built upon a hybrid approach of Black-Scholes prices and the daily deviation between these prices and the market prices. The network topology used in [Han97] is feedforward, i.e. loop-free. Three layers have been used, where each layer is connected to the next one fully (i.e. each neuron of a specific layer is connected to every neuron of the next layer). The first layer is called the input layer. This layer has the number of input parameters as the number of neurons. Each neuron is therefore assigned to a specific input parameter. The second layer is called the hidden layer. This layer is tested with different numbers of neurons for each problem. It ranges between 4 and 40 neurons with step size 4. The third layer is called the output layer. It consists of only one neuron, because the output should only lead to one result: The price of the given option.</p>
         <p>4.1 Neural networks</p>
         <p>The activation function of the neurons in the hidden layer is the hyperbolic tangent</p>
         <p>where x is the sum of the weighted values of all input neurons. The output neuron computes the sum of all values from the hidden layer using its own weights and it applies the identity function ( id ( x ) = x ) as activation function. This leads to the following mathematical representation of the whole neural network:</p>
         <p>where o ( x, w ) is the output (the result) of the neural network, I is the number of input parameters and J is the number of hidden neurons. x i is therefore a specific input parameter, except x 0 which is a constant. All w ’s are the weights of the connections between two neurons. The determination of the weights ( w ) is called learning. In [<xref id="XR205" ref-type="bibr" rid="R15">Han97</xref>] the back prop- agation algorithm and the Broyden-Fletcher-Goldfarb-Shanno one-step memoryless quasi-Newton method is used for learning. In all cases the second method leads to better results. Both learning methods are supervised, which means that they use data (historical or model driven) to determine the weights. 1000, 2500, 5000 and 10000 data points are used for each learning algorithm. In the first step the neural network is trained according to the Black-Scholes model and then the results are compared to the calculated values (with the Black-Scholes formula). The best result gives a root mean squared error (RMSE) of 1 . 99 ∗ 10 − 4 where the (RMSE) is defined as follows:</p>
         <p>with N the number of data points and e ( n ) the network error. In the second step European call options are estimated under the GARCH model. The simulation of the GARCH prices is done exactly as described in chapter 2.2.3. The input data are uniformly distributed in the ranges listed in <xref id="XR209" ref-type="table" rid="T4">table 4.1</xref>. The best results give a RMSE of 5 . 63 ∗ 10 − 4 . In both cases a short analysis of the deviation related to some input data ranges is given. Noticeable is the higher deviation for at-the-money options. The deviation is also significantly higher for short-maturity options. Additionally in the GARCH case the deviation is higher at long maturities. [DS01] propose a Markov chain approximation to price options. The stock prices and the volatilities are assumed to be discrete and elements of a fixed set. This fixed partitioning of the state space simplifies the task of option pricing to a sequence of standard matrix operations. Under a Markov chain representation, the conditional expected value is simply a product of two components. For European options, the first component is the transition probability matrix raised to a power equal to the maturity of the option (measured in terms of the basic transition period), and the second is the payoff vector associated with the option. The time step is fixed to one day. A mn × 1 vector V ( t ) contains the approximate option values at time t for all possible states. This means that the stock price can only have m different values while the volatilities can take n different values. The transition probability matrix is given by the conditional distribution function. Additionally the option values at each time step are adjusted to</p>
         <p>4.2 Markov chain approximation</p>
         <table-wrap id="Tx214">
            <caption>
               <p>Table 4.1: Input data ranges in [Han98]</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> parameter</td>
                     <td> description</td>
                     <td> range</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> S t /X</td>
                     <td> moneyness ratio</td>
                     <td> [0.7,1.3]</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> annualized risk free interest rate</td>
                     <td> [0,0.1]</td>
                  </tr>
                  <tr>
                     <td> σ 2</td>
                     <td> annualized unconditional variance</td>
                     <td> [0.01,0.16]</td>
                  </tr>
                  <tr>
                     <td> T − t</td>
                     <td> expiration time in days</td>
                     <td> [1,30]</td>
                  </tr>
                  <tr>
                     <td> √ h t /σ</td>
                     <td> relation between conditional and unconditional standard</td>
                     <td> [0.8,1.2]</td>
                  </tr>
                  <tr>
                     <td/>
                     <td> deviation</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> a 1</td>
                     <td> GARCH parameter</td>
                     <td> [0,1]</td>
                  </tr>
                  <tr>
                     <td> b 1</td>
                     <td> GARCH parameter</td>
                     <td> [0,1]</td>
                  </tr>
                  <tr>
                     <td> λ</td>
                     <td> risk premium</td>
                     <td> [0,0.001]</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>to avoid a trend in time of the option prices. Additional information about the problems of implementing American options by a Markov chain approximation can be found in [DS01]. Four different types of options are evaluated. The first two are European put options and American put options in the Black-Scholes framework. The others are European put options and American put options in the GARCH framework. The GARCH option pricing model used in the paper is the NGARCH(1,1) model. This model has an additional term to capture the leverage effect (by the leverage parameter θ ). The European put prices in the Black-Scholes framework are compared with the Black-Scholes prices. The parameters like the interest rate and the GARCH parameters are set to realistic values (see <xref id="XR220" ref-type="table" rid="T4.2">table 4.2</xref>). Three values for the maturity (1, 3 and 9 months) and three values for the moneyness ratio (1.1, 1.0 and 0.9) are used. In the Black-Scholes framework, volatility is assumed to be constant, therefore n = 1, while m is simulated in the range between 11 and 501. The results are good, they only vary in the range of 10 − 4 for m = 501. European put prices under the GARCH framework are compared to prices calculated by Monte carlo simulation. Realistic values for the parameters are chosen and listed in <xref id="XR229" ref-type="table" rid="T4">table 4.2</xref>. The values for the moneyness ratio and the maturity are chosen as before. The values of n are in the range between 25 and 51, while m ranges from 25 up to 357. When m = 357 and n = 51 the results vary dependent on the maturity (higher maturity means less accuracy). At a maturity of 1 month the error is at worst 6 ∗ 10 − 3 and at 3 and 9 months around 12 ∗ 10 − 3 . The first implementation of Genetic Programming for option pricing is [Keb99]. He uses this approach to determine a formula for American put options. In this case the prices of the options are calculated by the finite difference method (an introduction can be found in [Hul02], p. 418 - 426). The ranges of the parameters are given in <xref id="XR232" ref-type="table" rid="T4">table 4.3</xref>. As terminals he uses the variables S 0 , X , r , T , σ , α and the √ constants π and e . As functions he uses the mathematical functions +, − , ∗ , / , x , ln( x ), x 2 , x y , the distribution function of the standard normal distribution Φ( x ), the logical functions &lt; , ≤ , =, &gt; , ≥ and the functions with side effects IF, THEN and ELSE. The size of the population is fixed with only 50 individuals, the crossover and muta- tion probability were p c = 0 . 9 and p m = 0 . 01 respectively. The number of generations is set to 20000. The fitness function is defined as</p>
         <table-wrap id="Tx223">
            <caption>
               <p>Table 4.2: Parameter values in [DS01]</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> parameter</td>
                     <td> describtion</td>
                     <td> value</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> S 0</td>
                     <td> initial price of the option</td>
                     <td> 50</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> annualized interest rate</td>
                     <td> 0.05</td>
                  </tr>
                  <tr>
                     <td> β 0</td>
                     <td> GARCH parameter</td>
                     <td> 0.00001</td>
                  </tr>
                  <tr>
                     <td> β 1</td>
                     <td> GARCH parameter</td>
                     <td> 0.8</td>
                  </tr>
                  <tr>
                     <td> β 2</td>
                     <td> GARCH parameter</td>
                     <td> 0.1</td>
                  </tr>
                  <tr>
                     <td> θ</td>
                     <td> leverage factor</td>
                     <td> 0.3</td>
                  </tr>
                  <tr>
                     <td> λ</td>
                     <td> risk premium</td>
                     <td> 0.2</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="Tx226">
            <caption>
               <p>Table 4.3: Parameter range in [Keb99]</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> parameter</td>
                     <td> description</td>
                     <td> value</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> S 0</td>
                     <td> initial price of the option</td>
                     <td> [10,100]</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> annualized interest rate</td>
                     <td> [3%,7%]</td>
                  </tr>
                  <tr>
                     <td> σ</td>
                     <td> annualized volatility</td>
                     <td> [5%,50%]</td>
                  </tr>
                  <tr>
                     <td> α</td>
                     <td> moneyness ratio</td>
                     <td> [0.9,1.1]</td>
                  </tr>
                  <tr>
                     <td> ∆ T</td>
                     <td> maturity of the option</td>
                     <td> [0,1] years</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>4.3 Genetic Programming</p>
         <p>where A i refers to the value calculated by the genetic program and A i S refers to the real value. The results are good compared to other numerical approaches to find prices for this specific type of option. The derivation of the evaluation equation yields - as a by-product - an expression for the killing price. This gives the pricing equation a nice economic interpretation. Usually the equation derived via Genetic Programming is empirically good, but it is not possible to analyze them economically. A disadvantage of this approach is that usually the underlying of the option doesn’t follow a Wiener process, but more likely a GARCH process. Still the result of the work shows that it is possible to use Genetic Programming in the area of option pricing and that even American options can be priced via this method.</p>
      </sec>
      <sec>
         <title>Chapter 5 Strategic decisions of the new approach</title>
         <p>This chapter describes all the strategic decisions and approaches used in this master thesis. The result should be an analytic formula that calculates prices of European options when the underlying follows a GARCH(1,1) process. Therefore, in a first step, sample data points have to be generated. Then Genetic Programming searches for a formula (which is a subset of a program) which fits best to the sample data points. This task is called symbolic regression (compare with [Koz92]).  The input data are used similar to [Han98] and are shown in <xref id="XR243" ref-type="table" rid="T5">table 5.1</xref>. All input data are uniformly distributed in the given ranges except S t /X has a normal distribution with mean 1 and standard deviation 0 . 1. Option prices are then simulated using the Monte Carlo approach described in chapter 2.2.3. In the data set all values are transformed from annually to daily, with the assumption of 260 trading days a year. The number of simulation paths is set to 10000 to get values with a low variance. Two samples are produced, one with 1000 data points and one with 10000 data points. Both are used in my analysis, the first one for the derivation of option prices via Genetic Programming, and the second one to evaluate the results. On my computer (AMD Athlon XP 2200+ CPU with 512 MByte DDRAM) it took around one hour for the 1000 data points and around ten hours for the 10000 data points to be generated via Monte Carlo simulation. 5.2 Genetic Programming 5.2.1 Functions and terminals <xref id="XR250" ref-type="table" rid="T5.2">Table 5.2</xref> shows all the terminals used in the Genetic Programming algorithm. The terminal set consists of constants and variables. The constants 0, 1 and 2 are added to get some basic numbers. The Genetic Programming algorithm can generate all numbers of the set of rational numbers from these constants via simple functions. The constant 2 is selected to allow for easy generation of the square and the square root from the power function. The constants π and e increase the numbers the Genetic Programming algorithm can create to some irrational numbers. They also support the creation of some special functions from basic functions (e.g. e x ). The remaining terminals correspond to the input parameters of section 5.1. Assum- ing that these variables have a large impact on the value of the option, all variables must be part of a function (genetic program) which calculates the price of the option. <xref id="XR251" ref-type="table" rid="T5.3">Table 5.3</xref> shows all the functions used in the Genetic Programming algorithm. They consist of the four basic functions addition, subtraction, division and multiplication. The natural logarithm and the power function are also used to get functions like e x and many more. The maximum and the minimum function seem to be important because of equations 2.1 and 2.2. Due to the utilization in the Black-Scholes formula and in [Keb99], a distribution function seems to be useful too. The normal distribution function, the Student-t distribution function and the paretian stable distribution function, respectively, are therefore added. The paretian stable distribution function was calculated according to [Nol97]. 5.2.2 Fitness function and bloat control The overall task is to find an equation that approximates as good as possible the price of a call option depending on the input data. This is done via Genetic Programming as described in [Koz92]. The fitness function will be the root mean square error (RMSE) between the result of the genetic program and the real result (see also equation 4.3). One major task in Genetic Programming is to prevent the resulting equations from being too large in size. The concept is called bloat control (compare with [PL04]). Three methods which are all described in [PL04] are used in this master thesis. The first is called depth limiting method, where the resulting tree is restricted to certain depth limit. In this case it will be set to a small number between 7 and 10. The other two approaches use a depth limit too, but it will be relaxed to 20. The second approach is called parsimony pressure . In this approach, the fitness function penalties bigger trees by the following equation: Length F itness = StandardF itness + (5.1) P enalty where Length means the number of nodes in a given genetic program and P enalty is a constant penalty factor. The higher P enalty is, the lower bigger trees will worsen the Fitness. Values between 50000 and 100000 have shown to lead to good results. The third method is introduced in [PL04] and is called death by size . Here bigger individuals are selected for death randomly at some time in the program. 5.2.3 Population size, number of generations and mutation Two different major configurations are used. The configuration without mutation is proposed by [Koz92]. Here we have a huge population size (like 40000) and no mutation at all. A small number of generations (like 50) is assumed to be sufficient to build the best fitted solution. The configuration with mutation uses only a small population size (like 4000) but a much higher number of generations (like 500). To ensure that genetic material cannot be lost forever, mutation is used in this case. This approach was used in an even more extreme way by [Keb99]. 5.2.4 Automatic defined functions and hybrid approaches Four different approaches are selected. They differ in the number of automatic defined functions (ADFs) and in the type of equations assumed. In <xref id="XR267" ref-type="table" rid="T5.4">table 5.4</xref> they are listed. The standard approach uses just one genetic program tree, where all functions of the function set from <xref id="XR268" ref-type="table" rid="T5.3">table 5.3</xref> might be used. (Usually just one of the three distribution functions is used.) Also all terminals from the terminal set from <xref id="XR269" ref-type="table" rid="T5.2">table 5.2</xref> are used. Therefore the task of the Genetic Programming algorithm is to find a single equation which fits best to the given data set, without the use of any pre-defined knowledge and automatic defined functions. The standard with ADF approach uses two genetic program trees at the same time. In addition to the standard approach the main tree can also call a second genetic tree with two arguments. The second genetic tree uses all functions from the function set except for the distribution functions. As terminals it uses only the two arguments which are calculated at run-time, depending on the kind of arguments it gets from the main program. This corresponds exactly to the concept of automatic defined functions with one ADF and two arguments as described in chapter 3.2.4. The two hybrid approaches assume an equation similar to the Black-Scholes function, which has the following form:</p>
         <p>5.1 GARCH process</p>
         <table-wrap id="Tx245">
            <caption>
               <p>Table 5.1: Input data and ranges</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> parameter</td>
                     <td> description</td>
                     <td> range</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> S t /X</td>
                     <td> moneyness ratio</td>
                     <td> N(1,0.1)</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> annualized risk free interest rate</td>
                     <td> [0,0.1]</td>
                  </tr>
                  <tr>
                     <td> σ 2</td>
                     <td> annualized unconditional variance</td>
                     <td> [0.01,1.00]</td>
                  </tr>
                  <tr>
                     <td> √ T − t</td>
                     <td> expiration time (days)</td>
                     <td> [1,90]</td>
                  </tr>
                  <tr>
                     <td> h t /σ</td>
                     <td> relation between conditional and unconditional standard</td>
                     <td> [0.8,1.2]</td>
                  </tr>
                  <tr>
                     <td/>
                     <td> deviation</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> a 1</td>
                     <td> GARCH parameter</td>
                     <td> [0,1]</td>
                  </tr>
                  <tr>
                     <td> b 1</td>
                     <td> GARCH parameter</td>
                     <td> [0,1]</td>
                  </tr>
                  <tr>
                     <td> λ</td>
                     <td> risk premium</td>
                     <td> [0,0.001]</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="Tx255">
            <caption>
               <p>Table 5.2: Terminal set</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> Symbol</td>
                     <td> description</td>
                     <td> type</td>
                  </tr>
                  <tr>
                     <td> 0</td>
                     <td> zero</td>
                     <td> constant</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> 1</td>
                     <td> one</td>
                     <td> constant</td>
                  </tr>
                  <tr>
                     <td> 2</td>
                     <td> two</td>
                     <td> constant</td>
                  </tr>
                  <tr>
                     <td> π</td>
                     <td> PI</td>
                     <td> constant</td>
                  </tr>
                  <tr>
                     <td> e</td>
                     <td> Euler’s constant</td>
                     <td> constant</td>
                  </tr>
                  <tr>
                     <td> S t /X</td>
                     <td> moneyness ratio</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> r</td>
                     <td> annualized risk free interest rate</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> σ 2</td>
                     <td> annualized unconditional variance</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> √ T − t</td>
                     <td> expiration time (days)</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> h t /σ</td>
                     <td> relation between conditional and unconditional standard</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td/>
                     <td> deviation</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> a 1</td>
                     <td> GARCH parameter</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> b 1</td>
                     <td> GARCH parameter</td>
                     <td> variable</td>
                  </tr>
                  <tr>
                     <td> λ</td>
                     <td> risk premium</td>
                     <td> variable</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="Tx258">
            <caption>
               <p>Table 5.3: Function set</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> name of the function</td>
                     <td> description number</td>
                     <td> of arguments</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> addition</td>
                     <td> x + y</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> subtraction</td>
                     <td> x − y</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> division</td>
                     <td> x/y</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> multiplication</td>
                     <td> xy</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> natural logarithm</td>
                     <td> ln y</td>
                     <td> 1</td>
                  </tr>
                  <tr>
                     <td> power function</td>
                     <td> x y</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> maximum</td>
                     <td> max ( x ; y )</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> minimum</td>
                     <td> min ( x ; y )</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> normal distribution function</td>
                     <td> N ( x )</td>
                     <td> 1</td>
                  </tr>
                  <tr>
                     <td> student distribution function</td>
                     <td> S ( t, x )</td>
                     <td> 2</td>
                  </tr>
                  <tr>
                     <td> paretian stable distribution function</td>
                     <td> P ( α, β, x )</td>
                     <td> 3</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="Tx262">
            <caption>
               <p>Table 5.4: Different approaches used</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> name of the approach number of</td>
                     <td> genetic program trees</td>
                     <td> equation assumed</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> standard</td>
                     <td> 1</td>
                     <td> no</td>
                  </tr>
                  <tr>
                     <td> standard with ADF</td>
                     <td> 2</td>
                     <td> no</td>
                  </tr>
                  <tr>
                     <td> hybrid without ADFs</td>
                     <td> 2 − 6</td>
                     <td> yes</td>
                  </tr>
                  <tr>
                     <td> hybrid with ADFs</td>
                     <td> 3 − 9</td>
                     <td> yes</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>Depending on the type of the cumulated density function ( cdf ) it may have one (normal), two (student-t) or three (stable paretian) arguments, where each argument is a genetic program tree ( f x ). In the hybrid without ADFs approach, the 2 − 6 genetic program trees are not used with ADFs and are therefore solved separately. In the hybrid with ADFs approach two genetic program trees, which represent the same argument in the two cdf’s, have one additional genetic program tree. This additional genetic program tree might be called from the two genetic program trees without arguments and is therefore an ADF.</p>
      </sec>
      <sec>
         <title>Chapter 6 Implementation details</title>
         <p>This chapter provides an overview of the implementation details of the genetic program. It shows which libraries are used and how they are used. Furthermore, all classes are described and finally a UML (Unified Modeling Language) diagram gives some insight into the relationships between the classes. It does not provide a full description of the source code.  The whole program is written in C++ and should correspond to the ANSI standard (compare with [Str98]). It should therefore be platform independent. In fact, I was able to run it under Microsoft Windows 2000 and SUSE LINUX 9.0 without changing any line of code. The CD you can find attached to this thesis reflects this by offering a standard make-file for Linux and at the same time a configuration file for Microsoft Visual C++ 6.0. Luckily, it was not necessary to implement the whole program from scratch. I take advantage of the possibility to use several libraries which are available for free from the internet. The next few chapters give a short overview of all libraries I have used with www-links and some additional information. 6.1.1 The Genetic Programming kernel The first Genetic Programming library in C++ was implemented by [Sin94]. It was not really object-orientated and pretty hard to use. Therefore, in [Fra94] a better approach was started. Later it was modified by [Wei97] 1 and is now a save and widely usable tool for a wide range of problems that make use of the Genetic Programming approach. <xref id="XR281" ref-type="fig" rid="F6.1">Figure 6.1</xref> shows the class hierarchy of this library. It is according to the UML Version 1.5 specification, which can be found in [Obj03]. Two different abstract classes are defined. The class GPObject is the base class of all classes used in this library. 1 The library can be found at <ext-link ext-link-type="uri"
                      href="http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/weinbenner/gp.html">http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/weinbenner/gp.html</ext-link> This means that all classes are derived from GPObject. Another abstract class is GPContainer . This class manages an array of objects of type GPObject. It provides all necessary methods to handle its objects. GPNode is a class derived from GPObject which represents a node that can be a terminal or a function, respectively. Each genetic tree has its own function and terminal set. For this purpose, the class GPNodeSet is introduced and serves as a container to hold all the different nodes. A genetic program consists of the main tree and the ADF trees. Each tree type can have different functions and terminals. This allows the user to introduce a priori knowledge of the task to be performed by the genetic program (compare with chapter 3.2.4). The container class GPAdfNodeSet is used to collect the node sets for each ADF and the main tree, respectively. If the GPAdfNodeSet object has only one GPNodeSet object, no ADFs were defined (compare with [Wei97]). A GPPopulation object is a container that contains all the genetic programs of a population. It also has one object of type GPAdfNodeSet to have the information of all the different nodes it might use for creation. One genetic program is represented by the class GP . For each ADF and the main program, a GP contains one object of type GPGene which represents the root of a genetic program tree. Genetic Programming uses this tree structure to internally store genetic programs (compare with chapter 3.2.1). A tree consists of genes, each of which can be the parent gene for one or more children. A gene is also a container, so the class GPContainer is used as a base class. A gene object has only one component: a pointer to an object of class GPNode. By referencing a node object, GPGene knows which type of function it represents (compare with [Wei97]).</p>
         <p>6.1 Libraries</p>
         <fig id="F6.1">
            <caption>
               <p>Figure 6.1: UML diagram of the Genetic Programming kernel. Source: [Wei97]</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Parameter Possible range Population size [1...MaxInt] Number of generations [0...MaxInt] Crossover probability [0.0...100.0] % Creation probability [0.0...100.0] % Creation type [0...5] Maximum depth for creation [2...MaxInt] Maximum depth for crossover [MaximumDepthForCreation...MaxInt] Selection type [0...1] Tournament size [1...MaxInt] Demetic grouping [0...1] Deme size [0...PopulationSize] Demetic migration probability [0.0...100.0] Swap mutation probability [0.0...100.0] Shrink mutation probability [0.0...100.0] Add best to new population [0..1] Steady state [0..1]</p>
         <table-wrap id="T6.1">
            <caption>
               <p>Table 6.1: Properties of GPVariable. Source: [Wei97]</p>
            </caption>
         </table-wrap>
         <p>The GPVariable class is used to control the behavior of several aspects of Genetic Programming. Each GPPopulation object has an object of this class as a member. <xref id="XR290" ref-type="table" rid="T6.1">Table 6.1</xref> shows all the variables used by this library. The creation type is the same as defined in chapter 3.2.2, except that there is an additional one, which is a user defined creation type. The selection type may be probabilistic selection or tournament selection, respectively. ”Demetic grouping” and ”Add best to population” may be switched on (when equals one) or off (when equals zero). 6.1.2 A random number generator library Newran02B 2 is a C++ library for generating sequences of random numbers from a wide variety of distributions. It is particularly appropriate for the situation where sequences of identically distributed random numbers are required since the set up time for each type of distribution is relatively long, but the generation of a new random number is fast. The library includes classes for generating random numbers from a number of distributions and is easily extended to be able to generate random numbers from almost any of the standard distributions (compare with [Dav02]). <xref id="XR292" ref-type="fig" rid="F6.2">Figure 6.2</xref> shows the static UML structure of the Newran library. Random is a class used by all other classes as base class at least indirectly. It generates uniformly distributed random numbers by the Lewis-Goodman-Miller algorithm with Marsaglia 2 The library can be found at <ext-link ext-link-type="uri" href="http://www.robertnz.net">http://www.robertnz.net</ext-link> mixing. Via the static method Set, the random generator is initialized with a real number between zero and one. It is possible to instance one of the distribution classes to get random numbers via the Next method. I have only used the Uniform and the Normal class to create the random numbers for the Monte Carlo simulation and to get random distributed input data, respectively. All distribution classes (like Uniform, Pareto, Normal, Cauchy, ...) provide random numbers with different distributions. They usually take as input the uniformly distributed random numbers created by the Random base class. Therefore, they just have to provide an inverse distribution function to generate the random numbers. OperationRandom is a synonym for a whole range of classes which provide some functions to existing distribution classes and may also have subclasses. Details can be found in [Dav02]. 6.1.3 GNU Scientific Library The GNU Scientific Library 3 (gsl) is a collection of numerical routines for scientific computing. A complete documentation can be found in [<xref id="XR303" ref-type="bibr" rid="R13">G + 04</xref>] 4 . The library files specfns.h and gsl integration.h contains some globally defined functions which are used in the program. They are listed in <xref id="XR304" ref-type="table" rid="T6">table 6.2</xref>. The normal cdf function returns the normal distribution function and the sut- dents cdf returns the Student-t distribution function. The gsl integration qag implements a numerical integration. This function is used to calculate the distribution function of the paretian stable distribution function. The QAG algorithm is a simple adaptive integration procedure. The integration region is divided into subintervals, and on each iteration the subinterval with the largest estimated error is bisected. This reduces the overall error rapidly, as the subintervals become concentrated around local difficulties in the integrand. The algorithm is based on Gauss-Kronrod rules. A Gauss-Kronrod rule begins with a classical Gaussian quadrature rule of order m. This is extended with additional points between each of the abscissas to give a higher order Kronrod rule of order 2 m +1. The Kronrod rule is efficient because it reuses existing function evaluations from the 3 The current stable version is available from ftp.gnu.org in the directory /pub/gnu. The project homepage is <ext-link ext-link-type="uri" href="http://www.gnu.org/software/gsl/.">http://www.gnu.org/software/gsl/.</ext-link> 4 This book is also online available at <ext-link ext-link-type="uri" href="http://www.gnu.org/software/gsl/manual/">http://www.gnu.org/software/gsl/manual/</ext-link>
         </p>
         <p>Uniform Normal Constant SymGen Cauchy PosGen Exponential SymGenX ChiSq PosGenX AsymGen AsymGenX Random Gamma NegativBinomial Pareto DiscreteGen Poisson Binomial OperationRandom</p>
         <fig id="F6.2">
            <caption>
               <p>Figure 6.2: UML diagram of Newran02B. Source: [Dav02]</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <table-wrap id="Tx299">
            <caption>
               <p>Table 6.2: Some functions of the GNU Scientific Library</p>
            </caption>
            <table>
               <tbody>
                  <tr>
                     <td/>
                     <td> Name</td>
                     <td> Description</td>
                  </tr>
                  <tr>
                     <td/>
                     <td> normal cdf</td>
                     <td> Returns the normal distribution function</td>
                  </tr>
                  <tr>
                     <td/>
                     <td> students cdf</td>
                     <td> Returns the Student t distribution function</td>
                  </tr>
                  <tr>
                     <td> gsl</td>
                     <td> integration qag</td>
                     <td> Numerical integration</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>Name Description stable cdf Returns the Stable distribution function gsl integration Gives an easy accessible interface to the gsl integration functions simpson Returns the value of a bounded integral according to the simpson algorithm trapez Returns the value of a bounded integral according to the trapezoid algorithm adapt Returns the value of a bounded integral according to an adaptive algorithm <xref id="XR309" ref-type="table" rid="T6.3">Table 6.3</xref>: Additional functions</p>
         <p>Gaussian rule. The higher order Kronrod rule is used as the best approximation to the integral, and the difference between the two rules is used as an estimate of the error in the approximation (compare with [ <xref id="XR311" ref-type="bibr" rid="R13">G + 04</xref>]). 6.2 New classes and functions 6.2.1 Additional functions <xref id="XR313" ref-type="table" rid="T6.3">Table 6.3</xref> shows the additionally programmed functions. They are included in the library headers integration.h and specfns.h. The distribution function of the stable distribution is written according to the numerical approximation in [Nol97]. This is necessary, because there are no analytic formulas for most stable densities and distribution functions. This approximation uses integral formulas for the density and distribution function according to [Zol86]. Some problems emerge when α is close to 1, then α is set to one. I assume that this is a good approximation. 6.2.2 GPOPdata To give an easy access to the data and to create the data in a unified way, I have programmed the class GPOPData and its subclass. The structure is shown in <xref id="XR315" ref-type="fig" rid="F6">figure 6.3</xref>. GPOPdata is the base class and provides all the basic functions necessary. The methods save and load provide access to a file, which is in ASCII text style. It is a character separated value (csv) file where all the data are separated by tabs. The methods value and varname provide access to a value or the name of the variable, respectively. Size vars and Size data return the size of the data matrix. The method create makes the data from scratch. This is the only method which differs in the GPOPgarch class. In this case it produces random data according to a GARCH process. These data can be stored and read by a GPOPdata class. 6.2.3 MyGPVariables This class is similar to the GPVariables class of the Genetic Programming kernel (compare with chapter 6.1.1). It adds some additional parameters to the program. In <xref id="XR323" ref-type="table" rid="T6.4">table 6.4</xref>, all the additional parameters are listed. If the bloat method parameter (compare with chapter 3.2.5) is set to 0, no bloat control (except depth limiting) will be enforced. If the parameter is set to 1, parsimony pressure, and if it is set to 2, death by size will be used. The penalty parameter is only necessary when parsimony pressure is used and leads to a worse fitness (compare with chapter 5.2.2). The parameters normal, student and stable add the appropriate distribution function to the function set, when they are set to 1 instead of 0. Additionally the name of the resulting file (Infofilename) and the name of the data source (Datafilename) can be given, too. If not given, the resulting files will have the name “result” and the filename will be “data.in”. All these parameters are determined in the initialization file. 6.2.4 MyGene The class MyGene is derived from the GPGene class of the Genetic Programming kernel . <xref id="XR325" ref-type="table" rid="T6.5">Table 6.5</xref> shows all the methods which have to be rewritten. The printOn method calls the printMathStyle method and the printTexStyle method, respectively</p>
         <p>GPOPdata GPOPgarch -data : double -varNames : char +save() +create() +load() +value() : double +varname() : char +size_vars() : int +size_data() : int +create()</p>
         <fig id="F6.3">
            <caption>
               <p>Figure 6.3: UML diagram of GPOPdata</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <table-wrap id="Tx320">
            <caption>
               <p>Table 6.4: Properties of GPVariable. Source: [Wei97]</p>
            </caption>
            <table>
               <tbody>
                  <tr>
                     <td> Bloat method</td>
                     <td> [0...2]</td>
                  </tr>
                  <tr>
                     <td> Penalty</td>
                     <td> [0...MaxInt]</td>
                  </tr>
                  <tr>
                     <td> Normal</td>
                     <td> [0...1]</td>
                  </tr>
                  <tr>
                     <td> Student</td>
                     <td> [0...1]</td>
                  </tr>
                  <tr>
                     <td> Stable</td>
                     <td> [0...1]</td>
                  </tr>
                  <tr>
                     <td> Infofilename</td>
                     <td> String</td>
                  </tr>
                  <tr>
                     <td> Datafilename</td>
                     <td> String</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>Methods Description printOn Output function printMathStyle Output function to ASCII style printTeXStyle Output function to TeX style evaluate Evaluates the gene</p>
         <table-wrap id="T6.5">
            <caption>
               <p>Table 6.5: Methods of MyGene</p>
            </caption>
         </table-wrap>
         <p>Methods Description printOn Output function evaluate Evaluates the genetic program <xref id="XR330" ref-type="table" rid="T6.6">Table 6.6</xref>: Methods of MyGP</p>
         <p>depending on a global variable. The printTeXStyle method prints a Gene according to the TeX style and the printMathStyle according to a normal math style with brackets. One of the core functions in Genetic Programming is the evaluate method. It calculates the result of a single gene. It has to provide values for the whole function set defined in the genetic program. The value of variables and constants used in the genetic program has to be returned, too. If ADFs (compare with chapter 3.2.4) exist, it has to provide the arguments of the ADFs.  6.2.5 MyGP The class MyGP is derived from the GP class of the Genetic Programming kernel . <xref id="XR333" ref-type="table" rid="T6.6">Table 6.6</xref> shows all the methods which have to be rewritten. The printOn method outputs all the necessary information for TeX style output files. The evaluation method calculates the fitness of a genetic program. It calculates the root of the average of the squared errors of all data points (compare with chapter 5.2.2). 6.2.6 MyPopulation The class MyPopulation is derived from the GPPopulation class of the Genetic Programming kernel . <xref id="XR335" ref-type="table" rid="T6.7">Table 6.7</xref> shows all the methods which have to be rewritten. The tournamentSelection method has to be rewritten to provide death by size as bloat control method. 6.2.7 Executables According to chapter 5, four different strategies to solve the problem are used. This leads to four different executables (files which are executed by the operating system) for Genetic Programming. They only differ in the type of function which are prede- termined for evaluation and in the number and type of ADFs used. <xref id="XR343" ref-type="table" rid="T6.8">Table 6.8</xref> shows the different executables which are produced and what they are supposed to do. They also correspond to the four different approaches from <xref id="XR344" ref-type="table" rid="T5">table 5.4</xref>. Proddata is the executable file which simulates the GARCH process to get the sample data points (compare with chapter 6.2.2).  <xref id="XR347" ref-type="fig" rid="F6.4">Figure 6.4</xref> shows a UML diagram of the whole program. The GNU library on the right hand side is globally defined and is used by various parts of the program. The two utilities are the executables and they actually produce output. The output is written to a file, which a user can specify via the initialization file. The name of the initialization file is given as a parameter to the program.</p>
         <p>Methods Description tournamentSelection Rewrites the selection strategy</p>
         <table-wrap id="T6.7">
            <caption>
               <p>Table 6.7: Methods of MyPopulation</p>
            </caption>
            <table>
               <tbody>
                  <tr>
                     <td> gpop</td>
                     <td> Simple Genetic Programming</td>
                  </tr>
                  <tr>
                     <td> gpop2</td>
                     <td> Simple Genetic Programming with pre-build function</td>
                  </tr>
                  <tr>
                     <td> adf</td>
                     <td> Genetic Programming with one ADF</td>
                  </tr>
                  <tr>
                     <td> adf2</td>
                     <td> Genetic Programming with ADFs and pre-build function</td>
                  </tr>
                  <tr>
                     <td> proddata</td>
                     <td> Executable to make file with the GARCH-data Table 6.8: Executables</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>6.3 Overview UML diagram</p>
         <fig id="F6.4">
            <caption>
               <p>Figure 6.4: UML diagram of the whole program</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
      </sec>
      <sec>
         <title>Chapter 7 Results and statistics</title>
         <p>This chapter shows the results of the best genetic programs found. In the early stages I have tried to figure out which is the most promising configuration. Therefore the chapter starts with a statistical test of different configurations. Afterwards the best genetic program found is introduced and some properties of this equation are shown. At the end, my result is compared with the three existing approaches described in chapter 4.  7.1 Statistics of the identification of the best configuration 7.1.1 Setting of the test environment Each of the two configurations from 5.2.2 (with and without mutation) is used with the three bloat control methods described in chapter 5.2.2. Additionally, all 6 resulting approaches are tried with a Student t distribution and with a standard normal distribution. This leads to 12 different test cases where each test is repeated 25 times to get statistically relevant results. <xref id="XR354" ref-type="table" rid="T7.1">Table 7.1</xref> shows all different test cases. Due to the huge number of test cases (12 ∗ 25 = 300), the control parameters (compare with chapter 3.2.6) have been chosen as run-time decreasing and as little memory consuming as possible: 1. The configuration without mutation is used with a population size of 30000 and for 50 generations. 2. The configuration with mutation is used with a population size of 3000 and for 500 generations. 3. In the depth limiting bloat control method, the maximum depth parameter is set to 7.</p>
         <table-wrap id="Tx357">
            <caption>
               <p>Table 7.1: Test cases for configuration identification</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> No.</td>
                     <td> configuration</td>
                     <td> bloat control</td>
                     <td> cdf used</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> 1</td>
                     <td> without mutation</td>
                     <td> depth limiting</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 2</td>
                     <td> without mutation</td>
                     <td> depth limiting</td>
                     <td> student-t</td>
                  </tr>
                  <tr>
                     <td> 3</td>
                     <td> without mutation</td>
                     <td> parsimony pressure</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 4</td>
                     <td> without mutation</td>
                     <td> parsimony pressure</td>
                     <td> student-t</td>
                  </tr>
                  <tr>
                     <td> 5</td>
                     <td> without mutation</td>
                     <td> death by size</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 6</td>
                     <td> without mutation</td>
                     <td> death by size</td>
                     <td> student-t</td>
                  </tr>
                  <tr>
                     <td> 7</td>
                     <td> with mutation</td>
                     <td> depth limiting</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 8</td>
                     <td> with mutation</td>
                     <td> depth limiting</td>
                     <td> student-t</td>
                  </tr>
                  <tr>
                     <td> 9</td>
                     <td> with mutation</td>
                     <td> parsimony pressure</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 10</td>
                     <td> with mutation</td>
                     <td> parsimony pressure</td>
                     <td> student-t</td>
                  </tr>
                  <tr>
                     <td> 11</td>
                     <td> with mutation</td>
                     <td> death by size</td>
                     <td> normal</td>
                  </tr>
                  <tr>
                     <td> 12</td>
                     <td> with mutation</td>
                     <td> death by size</td>
                     <td> student-t</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>4. In the death by size and the parsimony pressure bloat control method, the maximum depth is set to 20. 5. The penalty parameter in the parsimony pressure bloat control method is set to only 20000.</p>
         <p>7.1.2 Test results <xref id="XR361" ref-type="table" rid="T7.2">Table 7.2</xref> shows the mean and the standard deviation of the results as well as the average execution time. The computer I have used is an AMD Athlon XP 2200+ CPU with 512 MByte DDRAM. To draw statistically correct conclusions, the results are compared according to Student’s t-test. This test shows whether two samples come from the same population. This statistical test works under the assumption of a normal distribution of the universe, that both samples are statistically independent and that the population of both have identical variances. According to [Vie97] it applies the following formula:</p>
         <p>No. Mean Deviation Average time 1 0.01532 0.00126 158 2 0.01545 0.00144 190 3 0.01875 0.00183 126 4 0.01825 0.00137 127 5 0.04356 0.00455 12 6 0.04361 0.00342 15 7 0.01853 0.00294 204 8 0.02057 0.00525 205 9 0.02512 0.00917 109 10 0.02978 0.01024 74 11 0.06559 0.00925 3 12 0.06884 0.01006 3</p>
         <table-wrap id="T7.2">
            <caption>
               <p>Table 7.2: Results of configuration identification</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> No</td>
                     <td> 1</td>
                     <td> 2</td>
                     <td> 3</td>
                     <td> 4</td>
                     <td> 5</td>
                     <td> 6</td>
                     <td> 7</td>
                     <td> 8</td>
                     <td> 9</td>
                     <td> 10</td>
                     <td> 11</td>
                     <td> 12</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> 1</td>
                     <td> -</td>
                     <td> 74.1</td>
                     <td> 1.0</td>
                     <td> 7.3</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 2</td>
                     <td> 74.1</td>
                     <td> -</td>
                     <td> 2.6</td>
                     <td> 16.4</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 3</td>
                     <td> 1.0</td>
                     <td> 2.6</td>
                     <td> -</td>
                     <td> 27.2</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.9</td>
                     <td> 0.1</td>
                     <td> 0.2</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 4</td>
                     <td> 7.3</td>
                     <td> 16.4</td>
                     <td> 27.2</td>
                     <td> -</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.1</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 5</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> -</td>
                     <td> 96.5</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 6</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 96.5</td>
                     <td> -</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 7</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.9</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> -</td>
                     <td> 9.7</td>
                     <td> 3.2</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 8</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.1</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 9.7</td>
                     <td> -</td>
                     <td> 28.1</td>
                     <td> 0.3</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 9</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.2</td>
                     <td> 0.1</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 3.2</td>
                     <td> 28.1</td>
                     <td> -</td>
                     <td> 8.5</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 10</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.3</td>
                     <td> 8.5</td>
                     <td> -</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                  </tr>
                  <tr>
                     <td> 11</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> -</td>
                     <td> 24.1</td>
                  </tr>
                  <tr>
                     <td> 12</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 0.0</td>
                     <td> 24.1</td>
                     <td> -</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="T7.3">
            <caption>
               <p>Table 7.3: Results of the t-statistic in percent</p>
            </caption>
         </table-wrap>
         <p>The result of the t-test of each tuple of configuration is shown in <xref id="XR373" ref-type="table" rid="T7">table 7.3</xref>. This table shows the probability in percent of α - the probability of rejecting a correct null hypothesis. If α is higher than 5%, I have assumed that the two configurations are of the same quality. Additionally this table shows which configuration is better with respect to the mean value according to <xref id="XR374" ref-type="table" rid="T7">table 7.2</xref>. A grey entry signifies that the row configuration is better (on average) than the column configuration. If the entry is black, it is vice versa. The configuration with mutation leads in all cases to a significantly worse result than the configuration without mutation. Also the execution time is most of the time longer with mutation. Therefore, I have decided to prefer the configuration without mutation for all further experiments. The death by size bloat control method doesn’t work well in my analysis. It kills all the long genetic programs immediately and at the same time the entire gene pool. At the end a couple of very small genetic programs survive with a very bad performance. The execution time is extremely short. The depth limiting bloat control method performs in most cases equally well as the parsimony pressure method, but it takes on average twice as much time. Therefore the Penalty factor has been set to low to allow a suitable judgement. I will use both methods in my further experiments. Death by size will be discarded, due to its poor performance. The usage of the Student-t or the normal cumulative distribution function as function in the Genetic Programming algorithm doesn’t lead to significantly different results in all cases. This might be because the normal distribution is a special case of the Student-t distribution. The additional properties of the Student-t distribution do not lead to better results. Usually the execution time is slightly higher with the Student-t distribution. 7.1.3 Utilization of the ADFs and the hybrid approaches In order to identify which approach (compare with chapter 5.2.4) is the best one, all approaches have been tested with the best configurations. The standard with ADF approach is even tried with all configurations. In the case of significantly different results, this would show that there are some interdependencies. <xref id="XR376" ref-type="table" rid="T7.4">Table 7.4</xref> shows the performance of ten runs for each configuration with the ADF approach. It is worse than the average of the standard configuration in all cases. I conclude therefore that the approach with ADF does not lead to better results. This might be because it is not possible to divide the problem into easily solvable subproblems. Another conclusion is that the different configurations lead to comparable results as before. I assume that this is a general pattern. The hybrid approach was not successful. In both cases with and without ADFs it has not worked in the way that I expected. In all cases results are worse than with the simpler methods. Another drawback was the usage of the Paretian stable distribution function. It is complicated to calculate (with numerical integrals), which takes a lot of time (20 times longer than with a normal distribution function), but has not led to</p>
         <table-wrap id="Tx379">
            <caption>
               <p>Table 7.4: Fitness values of the ADF approach</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> No.</td>
                     <td> Mean</td>
                     <td> Deviation Average</td>
                     <td> time</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> 1</td>
                     <td> 0.02183885</td>
                     <td> 0.00383879</td>
                     <td> 131</td>
                  </tr>
                  <tr>
                     <td> 2</td>
                     <td> 0.02224098</td>
                     <td> 0.00477594</td>
                     <td> 144</td>
                  </tr>
                  <tr>
                     <td> 3</td>
                     <td> 0.02579130</td>
                     <td> 0.00565985</td>
                     <td> 131</td>
                  </tr>
                  <tr>
                     <td> 4</td>
                     <td> 0.02666881</td>
                     <td> 0.00390301</td>
                     <td> 142</td>
                  </tr>
                  <tr>
                     <td> 5</td>
                     <td> 0.04172123</td>
                     <td> 0.00467133</td>
                     <td> 63</td>
                  </tr>
                  <tr>
                     <td> 6</td>
                     <td> 0.04438526</td>
                     <td> 0.00412538</td>
                     <td> 87</td>
                  </tr>
                  <tr>
                     <td> 7</td>
                     <td> 0.02979943</td>
                     <td> 0.01253381</td>
                     <td> 288</td>
                  </tr>
                  <tr>
                     <td> 8</td>
                     <td> 0.03159794</td>
                     <td> 0.01802966</td>
                     <td> 258</td>
                  </tr>
                  <tr>
                     <td> 9</td>
                     <td> 0.04453466</td>
                     <td> 0.01503629</td>
                     <td> 56</td>
                  </tr>
                  <tr>
                     <td> 10</td>
                     <td> 0.03586901</td>
                     <td> 0.00740740</td>
                     <td> 60</td>
                  </tr>
                  <tr>
                     <td> 11</td>
                     <td> 0.06872159</td>
                     <td> 0.00799661</td>
                     <td> 9</td>
                  </tr>
                  <tr>
                     <td> 12</td>
                     <td> 0.06238697</td>
                     <td> 0.01195662</td>
                     <td> 11</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>better results (not even results of equal quality).</p>
         <p>7.2 Comparison of the best equation found with the original process 7.2.1 Setting of the Genetic Algorithm To get the best possible results, the most promising configurations have been tested with all approaches. Additionally, the control parameters are set to the maximum values, where preliminary tests have indicated that they will lead to best results. 1. This leads to a maximum population size of 50000, 2. the number of generations is still set to 50, 3. the maximum depth in the depth limiting bloat control method is set to 10 4. and the penalty factor in the parsimony pressure bloat control method is set to 200000. This configuration does not overflow my memory with 512 MByte RAM and only takes reasonable time (around 10 hours) on the average.  7.2.2 The result The best equation has been found after months of exhaustive testing with the most promising configurations. It has been discovered with the depth limiting configuration without mutation and the simple approach without ADFs. The best found equation is (with some simplifications): f 1 = max((max(NORMAL(min(ln( X S ); dt · r )); X S ) − (max(min( a 1 · b 1 ; a dt 1 · σ 2 ) + a r 1 + h σ t · ( dt · σ 2 + dt · σ 2 ); max(ln( X S )+ min( dt · σ 2 ; pi + r ); dt · σ 2 · ( dt · σ 2 + dt · σ 2 ))))) · (min( dt · σ 2 ; ( dt + dt · σ 2 ) · X S · σ 2 · X S ) + max(ln( X S ); min(min( b 1 ; dt · σ 2 ); dt · r ))) + min(ln( X S ); min(ln( X S ); min(min(( dt + b 1 + e ) · max( X S ; 1) · σ 2 ; dt · r ); NORMAL(1 − ( S ))))); max((max(max(ln( S ); min( dt + max( S ; 1); dt · r )); S ) − X X X X (max( a r 1 + ht σ · ( dt · σ 2 + dt · σ 2 ) + a r 1 + ht σ a 1 b 1 ; max( dt · σ 2 ; a 1 r + ht σ ( dt · σ 2 + dt · σ 2 ))))) (min(((ln( X S )) · X S + dt ) · σ 2 ; ( dt + ln( X S )) · X S · σ 2 · X S ) + max(( ( r + ln ht ( X ) S )) · σ 2 ; min( a 1 r + ht σ · σ ( dt · σ 2 + dt · σ 2 ); dt · r ))); S − (( dt · σ 2 + dt · σ 2 ) dt · σ 2 ) X − (max( min(ln( X S ); Lambda + X S )+ a 1 r + ht σ · ( dt · σ 2 + dt · σ 2 ) ; min( dt · σ 2 ; ln( S )))))) b 1 + e X The complete equation in Microsoft EXCEL style: max((max(STANDNORMVERT(min(min(ln(S/X);ln(S/X));dt*r));S/X)- (max(min(a1*b1;a1^(dt*Sigma2))+a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2); max(min(ln(S/X);ln(S/X))+min(dt*Sigma2;pi+r);dt*Sigma2* (dt*Sigma2+dt*Sigma2)))))*(min(dt*Sigma2;((dt+dt*Sigma2)* (S/X-0)*Sigma2)/(1/S/X))+max(ln(S/X);min(min(b1;dt*Sigma2);dt*r)))+ min(ln(S/X);min(ln(S/X);min(min((dt+b1+e)*max(S/X;1)*Sigma2;dt*r); STANDNORMVERT(1-(max(S/X-0;S/X))))));max((max(max(ln(S/X); min(dt+max(S/X;1);dt*r));S/X)-(max(a1^(r+ht/Sigma)* (dt*Sigma2+dt*Sigma2)+a1^(r+ht/Sigma)*a1*b1;max(dt*Sigma2; a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2)))))*(min(((ln(S/X))/(1/S/X)+dt)* Sigma2;((dt+ln(S/X))*(S/X-0)*Sigma2)/(1/S/X))+max((ln(S/X))/ (r+ht/Sigma)*Sigma2;min(a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2);dt*r))); max(S/X-0;S/X)-((dt*Sigma2+dt*Sigma2)^(dt*Sigma2))-(max((min(ln(S/X); Lambda+S/X)+a1^(r+ht/Sigma)*(dt*Sigma2+dt*Sigma2))/(b1+e); min(dt*Sigma2;ln(S/X)))))) The quality of the result in relation to different numbers of data points is listed in <xref id="XR386" ref-type="table" rid="T7">table 7.5</xref>. With more data points, the RMSE even gets better. This is a sign that no over-fitting has occurred. Under the assumption that the underlying follows in reality a GARCH process and the prices of the options are calculated (wrongly) according to the Black-Scholes model, <xref id="XR387" ref-type="table" rid="T7.5">table 7.5</xref> also shows the RM SE of the Black-Scholes formula. The newly found equation is therefore about 25% better suited to find the price of a European option.</p>
         <p>Number of data points RMSE of best RMSE of Black- Improvement equation Scholes 1000 0.010656375 0.014230704 25.12 % 10000 0.010115501 0.013133606 22.98 %</p>
         <table-wrap id="T7.5">
            <caption>
               <p>Table 7.5: Results of the best found equation</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> Name dt in</td>
                     <td> days</td>
                     <td> S/X</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> data-095-30</td>
                     <td> 30</td>
                     <td> 0 . 95</td>
                  </tr>
                  <tr>
                     <td> data-100-30</td>
                     <td> 30</td>
                     <td> 1 . 00</td>
                  </tr>
                  <tr>
                     <td> data-105-30</td>
                     <td> 30</td>
                     <td> 1 . 05</td>
                  </tr>
                  <tr>
                     <td> data-095-60</td>
                     <td> 60</td>
                     <td> 0 . 95</td>
                  </tr>
                  <tr>
                     <td> data-100-60</td>
                     <td> 60</td>
                     <td> 1 . 00</td>
                  </tr>
                  <tr>
                     <td> data-105-60</td>
                     <td> 60</td>
                     <td> 1 . 05</td>
                  </tr>
                  <tr>
                     <td> data-095-90</td>
                     <td> 90</td>
                     <td> 0 . 95</td>
                  </tr>
                  <tr>
                     <td> data-100-90</td>
                     <td> 90</td>
                     <td> 1 . 00</td>
                  </tr>
                  <tr>
                     <td> data-105-90</td>
                     <td> 90</td>
                     <td> 1 . 05</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <table-wrap id="T7.6">
            <caption>
               <p>Table 7.6: Simulation of the process</p>
            </caption>
         </table-wrap>
         <p>7.2.3 The original process To get some idea about the original GARCH process, I have simulated the option prices 100 times with 9 different settings. The values for S/X and dt varies according to <xref id="XR394" ref-type="table" rid="T7.6">table 7.6</xref> and the values for r , σ 2 , h t /σ , a 1, b 1 and λ have been set to 0 . 05, 0 . 5, 1 . 0, 0 . 8, 0 . 15 and 0 . 001, respectively. In <xref id="XR395" ref-type="table" rid="T7.7">table 7.7</xref>, the standard deviation of the original process, the RMSE of the best equation and the RMSE of the Black-Scholes formula are shown with respect to the simulated data described above. The average standard deviation is 0 . 00085 and the RMSE is an order of magnitude higher. This seems to be realistic, because it is not possible to construct a formula which reaches a value that is lower than the standard deviation of a constant data set. In this case, the RMSE of the Black-Scholes formula is three times inferior on average. Depending on the value of S/X and dt , the RMSE varies between 0.00290 and 0.02019. This indicates that better results are still possible. <xref id="XR396" ref-type="fig" rid="F7.1">Figure 7.1</xref> shows that the RMSE of the best equation found behaves regularly in comparison to the RMSE of the Black-Scholes formula (compare with <xref id="XR397" ref-type="fig" rid="F7.2">figure 7.2</xref>). The best found equation has therefore no significant bad properties at a specific point. A different error measure which may be of economical interest is the Mean Absolute Percentage Error (MAPE) which is defined as follows:</p>
         <table-wrap id="Tx402">
            <caption>
               <p>Table 7.7: Standard deviation and RMSE</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> Name Std.</td>
                     <td> deviation</td>
                     <td> RMSE RMSE</td>
                     <td> Black-Scholes</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> data-095-30</td>
                     <td> 0.00079</td>
                     <td> 0.00995</td>
                     <td> 0.02955</td>
                  </tr>
                  <tr>
                     <td> data-095-60</td>
                     <td> 0.00100</td>
                     <td> 0.00919</td>
                     <td> 0.04411</td>
                  </tr>
                  <tr>
                     <td> data-095-90</td>
                     <td> 0.00094</td>
                     <td> 0.01070</td>
                     <td> 0.05394</td>
                  </tr>
                  <tr>
                     <td> data-100-30</td>
                     <td> 0.00074</td>
                     <td> 0.01842</td>
                     <td> 0.03168</td>
                  </tr>
                  <tr>
                     <td> data-100-60</td>
                     <td> 0.00097</td>
                     <td> 0.00290</td>
                     <td> 0.04587</td>
                  </tr>
                  <tr>
                     <td> data-100-90</td>
                     <td> 0.00090</td>
                     <td> 0.00298</td>
                     <td> 0.05554</td>
                  </tr>
                  <tr>
                     <td> data-105-30</td>
                     <td> 0.00068</td>
                     <td> 0.02019</td>
                     <td> 0.03032</td>
                  </tr>
                  <tr>
                     <td> data-105-60</td>
                     <td> 0.00091</td>
                     <td> 0.00885</td>
                     <td> 0.04524</td>
                  </tr>
                  <tr>
                     <td> data-105-90</td>
                     <td> 0.00070</td>
                     <td> 0.01456</td>
                     <td> 0.00460</td>
                  </tr>
                  <tr>
                     <td> Average</td>
                     <td> 0.00085</td>
                     <td> 0.01086</td>
                     <td> 0.03787</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>0.05000 0.04000 0.03000 RMSE 0.02000 0.01000 30 60 Maturity 0.00000 0.95 90 1.00 Moneyness ratio 1.05</p>
         <fig id="F7.1">
            <caption>
               <p>Figure 7.1: RMSE - best equation found</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>0.05000 0.04000 0.03000 RMSE 0.02000 0.01000 30 60 Maturity 0.00000 0.95 90 1.00 Moneyness ratio 1.05</p>
         <fig id="F7.2">
            <caption>
               <p>Figure 7.2: RMSE - Black-Scholes</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>where N is the number of data points, e is the error term and y is the Genetic Programming result. <xref id="XR410" ref-type="table" rid="T7.8">Table 7.8</xref> shows the different option prices the three methods get with the 9 constant data sets. In all cases the newly found equation leads to better results than the Black- Scholes formula. Still the MAPE is between 2 . 43% (which seems to be acceptable) and 27 . 66% (which seems to be too high). In <xref id="XR411" ref-type="fig" rid="F7.3">figure 7.3</xref> one can also observe the much higher relative differences at an expiration time of 30 days than at 90 days in all cases. The RMSE (compare with <xref id="XR412" ref-type="fig" rid="F7.1">figure 7.1</xref> is much better behaved than the MAPE, which is logical, because the driving force (the fitness function) is in my case the RMSE. To get better relative differences I should have used the MAPE as fitness function or maybe a combination of both. But this would increase the calculation complexity. With the Black-Scholes formula such a relation is not observable. <xref id="XR413" ref-type="fig" rid="F7.4">Figure 7.4</xref> shows that the Black-Scholes formula seems to have a significantly higher MAPE around the at the money point (where S/X equals 1 . 0). This section compares the equation generated via Genetic Programming with the three existing approaches described in chapter 4. 7.3.1 Comparison of the result with [Han98] In [Han98] the best found neural network has a RM SE of 5 . 63 ∗ 10 − 4 which is much better than the 101 . 16 ∗ 10 − 4 I get in my result equation. The analysis of the simulated price paths (compare with <xref id="XR426" ref-type="table" rid="T7.7">table 7.7</xref>) shows that even the standard deviation is higher with a value of 8 . 5 ∗ 10 − 4 . Therefore I conclude that a result with this accuracy is not possible in my setting. Another difference is that I have simulated the data in a much wider range. In [<xref id="XR427" ref-type="bibr" rid="R16">Han98</xref>] the expiration time has been simulated between 1 and 30 days and the annualized unconditional variance between 0 . 01 and 0 . 16. In comparison, I have used the range [1 , 90] for the maturity and [0 . 01 , 1 . 00] for the unconditional annualized variance, respectively. These data simulate a higher number of options and offer a broader ap- plication, but lead at the same time to a higher variance of the original Monte Carlo simulation. 7.3.2 Comparison of the result with [DS01] [DS01] price options where the underlying follows a GARCH process via a Markov chain approximation. They use fixed values for all variables except for the expiration time and the moneyness ratio. This leads to a lower variance of the original process than in my analysis. What is more complex in [DS01] is the usage of the NGARCH(1,1) model, where the leverage effect is considered too. Still the results can be compared. At different maturities they get an error between 6 ∗ 10 − 3 and 12 ∗ 10 − 3 which is as good than my average value of 10 . 116 − 3 . It seems that the approach of [DS01] and my new approach are equally suitable to price options in a GARCH framework. I think that my result of using only a single formula is easier than solving a 3 dimensional Markov chain. Therefore it is more likely to be used in practise. 7.3.3 Comparison of the result with [Keb99] The quality of the results is not comparable because Keber uses a different type of option with a different model for the underlying. In my case it is not possible to analyze the best equation found theoretically, because it is just an equation which fits best according to the fitness function. I think in general one should not expect, to get a short equation via the Genetic Programming approach which lends itself well to economic interpretation. Maybe [Keb99] was only lucky, or he restricted the problem domain so that no other type of equation was able to emerge. Still this thesis has shown that Genetic Programming is also suitable for a complex type of model (GARCH) and with a broad range of input parameters. [Keb99] has shown that this approach is also suitable for American options.</p>
         <p>7.3 Comparison of the results with other approaches</p>
         <table-wrap id="Tx418">
            <caption>
               <p>Table 7.8: Average results of the process</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> Name</td>
                     <td> Average</td>
                     <td> Result</td>
                     <td> MAPE</td>
                     <td> Result</td>
                     <td> MAPE</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td/>
                     <td> Result</td>
                     <td> Equation</td>
                     <td/>
                     <td> Black-</td>
                     <td/>
                  </tr>
                  <tr>
                     <td/>
                     <td> GARCH</td>
                     <td/>
                     <td/>
                     <td> Scholes</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> data-095-30</td>
                     <td> 0.04292</td>
                     <td> 0.05284</td>
                     <td> 23.12 %</td>
                     <td> 0.07246</td>
                     <td> 12.78 %</td>
                  </tr>
                  <tr>
                     <td> data-095-60</td>
                     <td> 0.06824</td>
                     <td> 0.07737</td>
                     <td> 13.38 %</td>
                     <td> 0.11234</td>
                     <td> 32.96 %</td>
                  </tr>
                  <tr>
                     <td> data-095-90</td>
                     <td> 0.08942</td>
                     <td> 0.10008</td>
                     <td> 11.92 %</td>
                     <td> 0.14335</td>
                     <td> 45.24 %</td>
                  </tr>
                  <tr>
                     <td> data-100-30</td>
                     <td> 0.06655</td>
                     <td> 0.08496</td>
                     <td> 27.66 %</td>
                     <td> 0.09822</td>
                     <td> 11.45 %</td>
                  </tr>
                  <tr>
                     <td> data-100-60</td>
                     <td> 0.09404</td>
                     <td> 0.09131</td>
                     <td> 2.91 %</td>
                     <td> 0.13990</td>
                     <td> 157.67 %</td>
                  </tr>
                  <tr>
                     <td> data-100-90</td>
                     <td> 0.11655</td>
                     <td> 0.11939</td>
                     <td> 2.43 %</td>
                     <td> 0.17209</td>
                     <td> 228.22 %</td>
                  </tr>
                  <tr>
                     <td> data-105-30</td>
                     <td> 0.09777</td>
                     <td> 0.11795</td>
                     <td> 20.64 %</td>
                     <td> 0.12808</td>
                     <td> 14.69 %</td>
                  </tr>
                  <tr>
                     <td> data-105-60</td>
                     <td> 0.12511</td>
                     <td> 0.13391</td>
                     <td> 7.04 %</td>
                     <td> 0.17034</td>
                     <td> 64.29 %</td>
                  </tr>
                  <tr>
                     <td> data-105-90</td>
                     <td> 0.19860</td>
                     <td> 0.18406</td>
                     <td> 7.32 %</td>
                     <td> 0.20314</td>
                     <td> 6.21 %</td>
                  </tr>
                  <tr>
                     <td> Average</td>
                     <td> 0.09991</td>
                     <td> 0.10687</td>
                     <td> 12.94 %</td>
                     <td> 0.13777</td>
                     <td> 29.27 %</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>30.00% 25.00% 20.00% MAPE 15.00% 10.00% 5.00% 30 60 Maturity 0.00% 0.95 90 1.00 Moneyness ratio 1.05</p>
         <fig id="F7.3">
            <caption>
               <p>Figure 7.3: MAPE - best equation found</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>250.00% 200.00% 150.00% MAPE 100.00% 50.00% 30 60 Maturity 0.00% 0.95 90 1.00 Moneyness ratio 1.05</p>
         <fig id="F7.4">
            <caption>
               <p>Figure 7.4: MAPE - Black-Scholes</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
      </sec>
      <sec>
         <title>Chapter 8 Conclusion</title>
         <p>8.1 New approaches</p>
         <p>This master thesis uses for the first time the Genetic Programming approach to price options which follow a GARCH process. The data sample is produced via the well known Monte Carlo simulation method. The range of the simulated data is much higher than in other existing approaches. This leads to the situation that all European call options with an expiration time of up to 90 trading days are covered. The only additional assumption is that the underlying follows a GARCH(1,1) process, where one can find a lot of empirical evidence that this assumption is realistic. Also new is the usage of different settings for the Genetic Programming approach in the area of option pricing. A configuration with and without mutation is tested with different bloat control methods. Additionally three different distribution functions are used. As a state-of-the-art feature, the new approach of Automatic Defined Functions is utilized. A hybrid model with a Black-Scholes analog function is tried, too. It was expected that this hybrid model would harmonize well with the Automatic Defined Functions.  The experiments lead to the conclusion that the easier settings are more successful than the complicated ones. Mutation does not work well and the simplest bloat control methods (depth limiting and parsimony pressure) are successful. At the same time the use of a normal distribution function seems sufficient, because the use of others does not lead to better results. Even the use of Automatic Defined Functions and the hybrid approach, respectively does not improve the results. The best equation found is about 25% better (in term of RMSE) suited to price European call options following a GARCH process than the Black-Scholes formula. Over-fitting was avoided and the behavior of the equation is regular. It does not have any specific area where the quality of the equation is low. It offers therefore reasonable prices for all European call options which are traded at exchanges. The conclusion is therefore that Genetic Programming is well suited to find pricing equations in this environment. The Genetic Programming approach has the property that with higher computer power, the results tend to get better. Therefore, in a few years a repetition of my tests with a more powerful computer might lead to better results. The field of Genetic Programming is still an active area of research. New results may show new configuration settings which are especially beneficial in the environment of option pricing. Additionally, there are still many more configurations possible with the Automatic Defined Function approach which I could not test in this master thesis due to limited time. Especially the evolutionary finding of the best architecture seems to be promising, but resource expensive at the same time. The field of option pricing is also an area of intensive research. New models emerge, like the NGARCH and the EGARCH to name just a few. These models also capture the leverage effect (compare with [DS01]). The more complicated the models will become, the less likely it is that a closed formula can be derived. I conclude therefore that in the future there will be increasing necessity for guided empirical model finding methods like Genetic Programming.</p>
         <p>8.2 Summary of the result</p>
         <p>8.3 Future issues</p>
      </sec>
      <sec>
         <title>List of Figures</title>
         <p>3.1 Flowchart of a simple genetic algorithm. Source: [Koz92] . . . . . . . . 17 3.2 An example of a genetic program . . . . . . . . . . . . . . . . . . . . . 20 3.3 An example of a crossover operation . . . . . . . . . . . . . . . . . . . 22 6.1 UML diagram of the Genetic Programming kernel. Source: [Wei97] . . 37 6.2 UML diagram of Newran02B. Source: [Dav02] . . . . . . . . . . . . . . 39 6.3 UML diagram of GPOPdata . . . . . . . . . . . . . . . . . . . . . . . . 42 6.4 UML diagram of the whole program . . . . . . . . . . . . . . . . . . . . 45 7.1 RMSE - best equation found . . . . . . . . . . . . . . . . . . . . . . . . 53 7.2 RMSE - Black-Scholes . . . . . . . . . . . . . . . . . . . . . . . . . . . 54 7.3 MAPE - best equation found . . . . . . . . . . . . . . . . . . . . . . . . 55 7.4 MAPE - Black-Scholes . . . . . . . . . . . . . . . . . . . . . . . . . . . 56</p>
      </sec>
      <sec>
         <title>List of Tables</title>
         <p>2.1 Input data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 3.1 Control parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 4.1 Input data ranges in [Han98] . . . . . . . . . . . . . . . . . . . . . . . . 28 4.2 Parameter values in [DS01] . . . . . . . . . . . . . . . . . . . . . . . . . 29 4.3 Parameter range in [Keb99] . . . . . . . . . . . . . . . . . . . . . . . . 29 5.1 Input data and ranges . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 5.2 Terminal set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.3 Function set . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 5.4 Different approaches used . . . . . . . . . . . . . . . . . . . . . . . . . 34 6.1 Properties of GPVariable. Source: [Wei97] . . . . . . . . . . . . . . . . 38 6.2 Some functions of the GNU Scientific Library . . . . . . . . . . . . . . 40 6.3 Additional functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 6.4 Properties of GPVariable. Source: [Wei97] . . . . . . . . . . . . . . . . 42 6.5 Methods of MyGene . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.6 Methods of MyGP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43 6.7 Methods of MyPopulation . . . . . . . . . . . . . . . . . . . . . . . . . 44 6.8 Executables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 7.1 Test cases for configuration identification . . . . . . . . . . . . . . . . . 47 7.2 Results of configuration identification . . . . . . . . . . . . . . . . . . . 48 7.3 Results of the t-statistic in percent . . . . . . . . . . . . . . . . . . . . 48 7.4 Fitness values of the ADF approach . . . . . . . . . . . . . . . . . . . . 50 7.5 Results of the best found equation . . . . . . . . . . . . . . . . . . . . . 52 7.6 Simulation of the process . . . . . . . . . . . . . . . . . . . . . . . . . . 52 7.7 Standard deviation and RMSE . . . . . . . . . . . . . . . . . . . . . . . 53 7.8 Average results of the process . . . . . . . . . . . . . . . . . . . . . . . 55</p>
      </sec>
      <sec>
         <title>Bibliography</title>
      </sec>
   </body>
   <back>
      <ref-list>
         <ref id="R1">
            <mixed-citation>[BBG97] Phelim Boyle, Mark Broadie, and Paul Glasserman. Monte carlo methods for security pricing. Journal of Economic Dynamics and Control , pages 1267–1321, 1997.</mixed-citation>
         </ref>
         <ref id="R2">
            <mixed-citation>[BCK92] Tim Bollerslev, Ray Y. Chou, and Kenneth F. Kroner. ARCH modeling in finance: a review of the theory and empirical evidence. Journal of Econometrics , 52:5–95, 1992.</mixed-citation>
         </ref>
         <ref id="R3">
            <mixed-citation>[BFM97] Thomas Bäck, David B. Fogel, and Zbigniew Michalewicz. Handbook of Evolutionary Computation . Oxford University Press, New York, 1997.</mixed-citation>
         </ref>
         <ref id="R4">
            <mixed-citation>[BNKF98] Wolfgang Banzhaf, Peter Nordin, Robert E. Keller, and Frank D. Fran- cone. Genetic Programming - An Introduction . Morgan Kaufmann, San Francisco, California, USA, 1998.</mixed-citation>
         </ref>
         <ref id="R5">
            <mixed-citation>[Bol86] Tim Bollerslev. Generalized autoregressive conditional heteroskedasticity. Journal of Econometrics , 31:307–327, 1986.</mixed-citation>
         </ref>
         <ref id="R6">
            <mixed-citation>[BS73] Fischer Black and Myron Scholes. The pricing of options and corporate liabilities. Journal of Political Economy , 81:637–659, 1973.</mixed-citation>
         </ref>
         <ref id="R7">
            <mixed-citation>[Dav02] Robert B. Davis. Newran02b - a random number generator library. Technical report, Statistics Research Associates Limited, Wellington, New Zealand, 2002.</mixed-citation>
         </ref>
         <ref id="R8">
            <mixed-citation>[DS95] Jin-Chuan Duan and Jean-Guy Simonato. Empirical Martingale Simulation for Asset Prices. CIRANO Working Papers , 95s-43, 1995.</mixed-citation>
         </ref>
         <ref id="R9">
            <mixed-citation>[DS01] Jin-Chuan Duan and Jean-Guy Simonato. American option pricing under GARCH by a markov chain approximation. Journal of Economic Dynamics &amp; Control , 25:1689–1718, 2001.</mixed-citation>
         </ref>
         <ref id="R10">
            <mixed-citation>[Dua95] Jin-Chuan Duan. The GARCH option pricing model. Mathematical Finance , 5(1):13–32, 1995.</mixed-citation>
         </ref>
         <ref id="R11">
            <mixed-citation>[Eng82] Robert F. Engle. Autoregressive conditional heteroskedasticity with estimates of the variance of u.k. inflation. Econometrica , 50:987–1008, 1982.</mixed-citation>
         </ref>
         <ref id="R12">
            <mixed-citation>[Fra94] Adam P. Fraser. Genetic Programming in C++. Technical Report 040, University of Salford, Cybernetics Research Institute, 1994.</mixed-citation>
         </ref>
         <ref id="R13">
            <mixed-citation>[G + 04] M. Galassi et al. GNU Scientific Library Reference Manual . Network The- orie Ltd., Bristol, United Kingdom, 2 edition, 2004.</mixed-citation>
         </ref>
         <ref id="R14">
            <mixed-citation>[GS96] Alois L. J. Geyer and Walter S. A. Schwaiger. GARCH Effekte in der Optionsbewertung. Zeitschrift für Betriebswirtschaft , 65(5):534–540, 1996.</mixed-citation>
         </ref>
         <ref id="R15">
            <mixed-citation>[Han97] Michael Hanke. Neural Network Approximation of Option Pricing Formulas for Analytically Intractable Option Pricing Models. Journal of Computational Intelligence in Finance , 5(5):20–27, Sep 1997.</mixed-citation>
         </ref>
         <ref id="R16">
            <mixed-citation>[Han98] Michael Hanke. Optionsbewertung mit neuronalen Netzen . Dissertation, Wirtschaftsuniversität Wien, 1998.</mixed-citation>
         </ref>
         <ref id="R17">
            <mixed-citation>[Hol75] John H. Holland. Adaption in Natural and Artificial Systems . University of Michigan Press, 1975.</mixed-citation>
         </ref>
         <ref id="R18">
            <mixed-citation>[Hul02] John C. Hull. Options, futures, and other derivatives . Prentice Hall Inter- national, Inc., Upper Saddle River, New Jersey, USA, fifth edition, 2002.</mixed-citation>
         </ref>
         <ref id="R19">
            <mixed-citation>[K + 03] John R. Koza et al. Genetic Programming IV: Routine Human-Competitive Machine Intelligence . Kluwer Acadamic Publishers, 2003.</mixed-citation>
         </ref>
         <ref id="R20">
            <mixed-citation>[KBAK99] John R. Koza, Forrest H. Bennett III, David Andre, and Martin A. Keane. Genetic Programming III, Darwinian Invention and Problem Solving . Morgan Kaufmann Publishers, San Francisco, California, USA, 1999.</mixed-citation>
         </ref>
         <ref id="R21">
            <mixed-citation>[Keb99] Christian Keber. Option Pricing with the Genetic Programming Approach. Journal of Computational Intelligence in Finance , 7(6):26–36, 1999.</mixed-citation>
         </ref>
         <ref id="R22">
            <mixed-citation>[Koz92] John R. Koza. Genetic Programming . The MIT Press, Cambridge, Massachusetts, USA, 1992.</mixed-citation>
         </ref>
         <ref id="R23">
            <mixed-citation>[Koz94] John R. Koza. Genetic Programming II, Automatic Discovery of Reuseable Programs . The MIT Press, Cambridge, Massachusetts, USA, 1994.</mixed-citation>
         </ref>
         <ref id="R24">
            <mixed-citation>[Mic92] Zbigniew Michalewicz. Genetic Algorithms + Data Structures = Evolution Programs . Springer, Berlin, Germany, 1992.</mixed-citation>
         </ref>
         <ref id="R25">
            <mixed-citation>[Nef00] Salih N. Neftci. An Introduction to the Mathematics of Financial Deriva- tives . Acadamic Press, San Diego, California, USA, second edition, 2000.</mixed-citation>
         </ref>
         <ref id="R26">
            <mixed-citation>[Nol97] John P. Nolan. Numerical calculation of stable densities and distribution functions. Commun. Statist. - Stochastic Models , 13(4):759–774, 1997.</mixed-citation>
         </ref>
         <ref id="R27">
            <mixed-citation>[Obj03] Object Management Group, Inc. OMG Unified Modeling Language Speci- fication, Ver. 1.5 , March 2003.</mixed-citation>
         </ref>
         <ref id="R28">
            <mixed-citation>[PL04] Liviu Panait and Sean Luke. Alternative Bloat Control Methods. In Lecture Nodes in Computer Science 3103 , pages 630–641. Springer-Verlag, 2004.</mixed-citation>
         </ref>
         <ref id="R29">
            <mixed-citation>[Rey92] Craig W. Reynolds. An evolved, vision-based behavioral model of coor- dinated group motion. In Meyer and Wilson, editors, From Animals to Animats (Proceedings of Simulation of Adaptive Behaviour) . MIT Press, 1992.</mixed-citation>
         </ref>
         <ref id="R30">
            <mixed-citation>[Sin94] Andy Singleton. Genetic Programming with C++. BYTE Magazin , Febru- ary 1994.</mixed-citation>
         </ref>
         <ref id="R31">
            <mixed-citation>[Str98] Bjarne Stroustrup. The C++ Programming Language . Addison Wesley Longman, Reading Mass, USA, third edition, 1998.</mixed-citation>
         </ref>
         <ref id="R32">
            <mixed-citation>[Vie97] Reinhard K. Viertl. Einführung in die Stochastick . Springer-Verlag, Wien, second edition, 1997.</mixed-citation>
         </ref>
         <ref id="R33">
            <mixed-citation>[Wei97] Thomas Weinbrenner. The Genetic Programming Kernel. Technical report, Institute for Mechatronics, Technical University of Darmstadt, 1997.</mixed-citation>
         </ref>
         <ref id="R34">
            <mixed-citation>[Zol86] V. M. Zolotarev. One-dimensional Stable Distributions. Amer. Math. Soc. Transl. of Math. Monographs , 65, 1986.</mixed-citation>
         </ref>
      </ref-list>
   </back>
</article>