<Publication>
  <id>TUW-247741</id>
  <title>A FORMAL METHOD FOR SELECTING EVALUATION METRICS FOR IMAGE SEGMENTATION.</title>
  <abstractText>Evaluating the quality of segmentations is an important process in image processing, especially in the medical domain. Many evaluation metrics have been used in evaluating segmentation. There exists no formal way to choose the most suitable metric(s) for a particular segmentation task and/or particular data. In this paper we propose a formal method for choosing the most suitable metrics for evaluating the quality of segmentations with respect to ground truth segmentations. The proposed method depends on measuring the bias of metrics towards/against the properties of the the segmentations being evaluated. We firstly demonstrate how metrics can have bias towards/against particular properties and then we propose a general method for ranking metrics according to their overall bias. We finally demonstrate for 3D medical image segmentations that ranking produced using metrics with low overall bias strongly correlate with manual rankings done by an expert. Index Terms — image segmentation; evaluation metrics; selection</abstractText>
  <keywords/>
  <authors/>
  <affiliations/>
  <sections>
    <Section>
      <title>1 Introduction</title>
      <type>deo:Introduction</type>
      <typeEnum>INTRODUCTION</typeEnum>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>2 Related Work</title>
      <type>deo:RelatedWork</type>
      <typeEnum>RELATEDWORK</typeEnum>
      <referenceIds>
        <string>12</string>
        <string>13</string>
        <string>14</string>
        <string>15</string>
        <string>11</string>
        <string>2</string>
        <string>16</string>
        <string>17</string>
      </referenceIds>
      <referenceCitations/>
    </Section>
    <Section>
      <title>3 Proposed Methods</title>
      <type>deo:Methods</type>
      <typeEnum>METHOD</typeEnum>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>4 Experiments</title>
      <type>DoCO:Section</type>
      <typeEnum>METHOD</typeEnum>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>5 Conclusion and future work</title>
      <type>deo:Conclusion</type>
      <typeEnum>CONCLUSIONS</typeEnum>
      <referenceIds/>
      <referenceCitations/>
    </Section>
    <Section>
      <title>6 Acknowledgments</title>
      <type>deo:Acknowledgements</type>
      <typeEnum>ACKNOWLEDGEMENTS</typeEnum>
      <referenceIds/>
      <referenceCitations/>
    </Section>
  </sections>
  <citationContexts/>
  <references>
    <Reference>
      <id>ref93</id>
      <referenceIdString>93</referenceIdString>
      <authors/>
      <referenceText>[1] T.H.J.M. Peeters, P.R. Rodrigues, A. Vilanova, and B.M ter Haar Romeny, “Analysis of dis- tance/similarity measures for diffusion tensor imaging,” in Visualization and Processing of Tensor Fields: Advances and Perspectives . Springer, Berlin, 2008.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref94</id>
      <referenceIdString>94</referenceIdString>
      <authors/>
      <referenceText>[2] Mehrdad Fatourechi, Rabab K. Ward, Steven G. Mason, Jane Huggins, Alois Schloegl, and Gary E. Birch, “Comparison of evaluation metrics in classification applications with imbalanced datasets,” in ICMLA , 2009, pp. 777–782.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref95</id>
      <referenceIdString>95</referenceIdString>
      <authors/>
      <referenceText>[3] Guido Gerig, Matthieu Jomier, and Miranda Chakos, “Valmet: A new validation tool for as- sessing and improving 3D object segmentation,” in Proceedings of the 4th International Conference on Medical Image Computing and Computer-Assisted In- tervention , 2001, pp. 516–523.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref96</id>
      <referenceIdString>96</referenceIdString>
      <authors/>
      <referenceText>[4] Daniel B. Russakoff, Carlo Tomasi, Torsten Rohlf- ing, Calvin R. Maurer, and Jr., “Image similarity using mutual information of regions,” in 8th European Conference on Computer Vision, ECCV , 2004, pp. 596–607.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref97</id>
      <referenceIdString>97</referenceIdString>
      <authors/>
      <referenceText>[5] Nguyen Xuan Vinh, Julien Epps, and James Bai- ley, “Information theoretic measures for cluster- ings comparison: is a correction for chance nec- essary?,” in Proceedings of the 26th Annual International Conference on Machine Learning . 2009, pp. 1073–1080, ACM.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref98</id>
      <referenceIdString>98</referenceIdString>
      <authors/>
      <referenceText>[6] David M. W. Powers, “Evaluation: From precision, recall and F-factor to ROC, informedness, marked- ness correlation,” Journal of Machine Learning Tech- nologies , vol. 2, pp. 37–63, 2011.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref99</id>
      <referenceIdString>99</referenceIdString>
      <authors/>
      <referenceText>[7] Chris Buckley and Ellen M. Voorhees, “Evaluating evaluation measure stability,” in Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval . 2000, pp. 33–40, ACM.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref100</id>
      <referenceIdString>100</referenceIdString>
      <authors/>
      <referenceText>[8] Halim Benhabiles, Guillaume Lavoue, Jean Phillipe Vandeborre, and Mohamed Daoudi, “A subjective experiment for 3d-mesh segmentation evaluation,” in IEEE International Workshop on Multimedia Signal Processing (MMSP) , 2010.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref101</id>
      <referenceIdString>101</referenceIdString>
      <authors/>
      <referenceText>[9] Filip Radlinski and Nick Craswell, “Comparing the sensitivity of information retrieval metrics,” in Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval , 2010.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref102</id>
      <referenceIdString>102</referenceIdString>
      <authors/>
      <referenceText>[10] R. Blanco and H. Zaragoza, “Beware of relatively large but meaningless improvements,” Tech. Rep., Yahoo! Research 2011-001, 2011.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref103</id>
      <referenceIdString>103</referenceIdString>
      <authors/>
      <referenceText>[11] Tetsuya Sakai, “Evaluating evaluation metrics based on the bootstrap,” in Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval . 2006, pp. 525–532, ACM.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref104</id>
      <referenceIdString>104</referenceIdString>
      <authors/>
      <referenceText>[12] Jin Huang and Charles X. Ling, “Using AUC and accuracy in evaluating learning algorithms,” IEEE Transactions on Knowledge and Data Engineering , vol. 17, pp. 299–310, 2005.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref105</id>
      <referenceIdString>105</referenceIdString>
      <authors/>
      <referenceText>[13] Enrique Amigo, Julio Gonzalo, Javier Artiles, and Felisa Verdejo, “A comparison of extrinsic clus- tering evaluation metrics based on formal con- straints,” Inf. Retr , vol. 12, no. 4, pp. 461–486, Au- gust 2009.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref106</id>
      <referenceIdString>106</referenceIdString>
      <authors/>
      <referenceText>[14] Nguyen Xuan Vinh, Julien Epps, and James Bai- ley, “Information theoretic measures for cluster- ings comparison: Variants, properties, normaliza- tion and correction for chance,” J. Mach. Learn. Res. , vol. 9999, pp. 2837–2854, December 2010.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref107</id>
      <referenceIdString>107</referenceIdString>
      <authors/>
      <referenceText>[15] Luca Busin and Stefano Mizzaro, “Axiometrics: An axiomatic approach to information retrieval effectiveness metrics,” in Proceedings of the 2013 Conference on the Theory of Information Retrieval , New York, NY, USA, 2013, pp. 8:22–8:29.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref108</id>
      <referenceIdString>108</referenceIdString>
      <authors/>
      <referenceText>[16] Tetsuya Sakai, “On the reliability of information retrieval metrics based on graded relevance,” Information Processing Management , 2007.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref109</id>
      <referenceIdString>109</referenceIdString>
      <authors/>
      <referenceText>[17] Ellen M. Voorhees and Chris Buckley, “The effect of topic set size on retrieval experiment error,” in Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval , 2002, pp. 316–323.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref110</id>
      <referenceIdString>110</referenceIdString>
      <authors/>
      <referenceText>[18] H. B. Mann and D. R. Whitney, “On a test of whether one of two random variables is stochas- tically larger than the other,” The Annals of Mathe- matical Statistics , vol. 18, no. 1, pp. 50–60, 1947.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref111</id>
      <referenceIdString>111</referenceIdString>
      <authors/>
      <referenceText>[19] Janez Demsar, “Statistical comparisons of classifiers over multiple data sets,” J. Mach. Learn. Res. , vol. 17, pp. 30, 2006.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
    <Reference>
      <id>ref113</id>
      <referenceIdString>113</referenceIdString>
      <authors/>
      <referenceText> PubDat 229008.pdf, 2014.</referenceText>
      <publication reference="/Publication[1]"/>
    </Reference>
  </references>
</Publication>