<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  SYSTEM "http://dtd.nlm.nih.gov/archiving/3.0/archivearticle3.dtd">
<article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns:mml="http://www.w3.org/1998/Math/MathML"
         xmlns:xlink="http://www.w3.org/1999/xlink">
   <front>
      <journal-meta>
         <journal-id/>
         <journal-title-group>
            <journal-title/>
         </journal-title-group>
         <issn/>
         <publisher>
            <publisher-name/>
         </publisher>
      </journal-meta>
      <article-meta>
         <title-group>
            <article-title>Dialogue Games for Fuzzy Logics</article-title>
         </title-group>
         <supplement>
            <p>
               <fig id="Fx1">
                  <caption>
                     <p/>
                  </caption>
                  <graphic xlink:href=""/>
               </fig>
            </p>
            <p>DIPLOMARBEIT zur Erlangung des akademischen Grades Diplom-Ingenieur im Rahmen des Studiums Computational Intelligence eingereicht von Christoph Roschger, Bakk.techn. Matrikelnummer 0126178 an der Fakultät für Informatik der Technischen Universität Wien Betreuer: Ao.Prof.Dipl-Ing.Dr.techn. Christian G. Fermüller Wien, 21.10.2008 _______________________ ______________________ (Unterschrift Verfasser) (Unterschrift Betreuer)</p>
            <p>Master Thesis Dialogue Games for Fuzzy Logics Performed at the Department of Computer Languages Vienna University of Technology advised by Ao.Prof.Dipl.-Ing.Dr.techn. Christian G. Fermüller by Christoph Roschger, Bakk.techn. Erlgasse 40/15 1120 Wien</p>
            <p>Vienna, October 2008</p>
         </supplement>
      </article-meta>
   </front>
   <body>
      <sec>
         <title>Zusammenfassung</title>
         <p>Formale Dialogspiele werden schon seit langem dazu verwendet, die Semantik verschiedener Logiken zu charakterisieren. In den 70er Jahren präsentierte Robin Giles seinen Versuch, eine operationale Grundlage für formales Schließen zu definieren, basierend auf atomaren Exper- imenten, welche Dispersion aufweisen können. Diese Masterarbeit motiviert und beschreibt seinen Ansatz und die Verbindung zu t-Norm-basierten Fuzzy-Logiken. Wir geben eine kurze Einführung in t-Normen und mehrwertige Fuzzy-Logiken, die auf diese Bezug nehmen. Im Speziellen liegt der Schwerpunkt auf drei solchen fundamen- talen Fuzzy-Logiken: Lukasiewicz-Logik, Gödel-Logik und Produkt-Logik. Verschiedene Möglichkeiten, die Spielregeln von Giles’ Spiel zu ändern, um dieses adäquat für Gödel- und Produkt-Logik zu machen, werden präsentiert und diskutiert. Darüber hinaus beschreiben wir die starke Verbindung zwischen Gewinnstrategien im Spiel und Ableitungen in einem analytischen Kalkül, der auf relationalen Hypersequenten basiert. Eine andere Art von Dialogspielen sind sogenannte “Truth Comparison Games”. Diese sind besonders geeignet für Gödel-Logik, da sie der gradbasierten Semantik der Gödel-Logik mehr entsprechen als Giles’ Spiel. Wir präsentieren das Spiel und diskutieren Gewinnstrategien für beide Spieler, welche als Beweis für die Gültigkeit oder Widerlegbarkeit einer Formel gesehen werden können. Zusätzlich werden mehrere Hilfsprogramme vorgestellt, die im Kontext dieser Masterarbeit entwickelt wurden. Darunter befindet sich auch eine webbasierte Anwendung zur interaktiven Exploration von Giles’ Spiel und dessen Erweiterungen.  Formal dialogue games are a traditional approach to characterize the semantics of logics. In the 1970s Robin Giles attempted to provide an operational foundation for formal reasoning in physical theories by dialogue games based on atomic experiments that may show dispersion. This thesis motivates, describes and analyzes his approach and the connection to t-norm based fuzzy logics. We give a short introduction into t-norms and many-valued logics based on t-norms. In particular we focus on three fundamental t-norm based fuzzy logics: Lukasiewicz Logic, Gödel Logic, and Product Logic. We present and discuss several approaches for extending the game rules of Giles’s Game in order to make it adequate for Gödel Logic and Product Logic. Moreover, we give hints at a strong correspondence between winning strategies in the game and derivations in an analytic proof system based on relational hypersequents. Another type of dialogue games are truth comparison games. This type is suitable for Gödel Logic and relates more to the degree based semantics of that logic than Giles’s Game. We present the game and discuss winning strategies for both players indicating the validity or refutability of a formula. Additionally, several utilities implemented in the context of this thesis are presented. Amongst these is a web-based application which allows for the interactive exploration of Giles’s Game and its extensions.</p>
         <p>Abstract</p>
      </sec>
      <sec>
         <title>Table of Contents</title>
      </sec>
      <sec>
         <title>1 Introduction 2 T-Norm Based Fuzzy Logics</title>
      </sec>
      <sec>
         <title>1 3</title>
         <p>2.1 Design Choices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 2.2 T-Norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5 2.3 Lukasiewicz Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.4 Gödel Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2.5 Product Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.6 A Uniform Hypersequent System . . . . . . . . . . . . . . . . . . . . . . . . . . 12</p>
      </sec>
      <sec>
         <title>3 Giles’s Game</title>
      </sec>
      <sec>
         <title>16</title>
         <p>3.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 3.2 Betting on Positive Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.3 Decomposing Propositions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 3.4 Analyzing Giles’s Game . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 3.4.1 Risk Values and Valuations . . . . . . . . . . . . . . . . . . . . . . . . . 26 3.4.2 Stability of Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 3.5 Rules for Other Connectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 3.6 Logical Equivalences as Game Equivalencies . . . . . . . . . . . . . . . . . . . 35 3.7 Remarks on Quantifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37</p>
      </sec>
      <sec>
         <title>4 Extending Giles’s Game to Other Logics</title>
      </sec>
      <sec>
         <title>43</title>
         <p>4.1 Different Ways of Combining Bets . . . . . . . . . . . . . . . . . . . . . . . . . 44 4.1.1 Summing Up Bets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 4.1.2 Joint Bets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44 4.1.3 Selecting Representative Bets . . . . . . . . . . . . . . . . . . . . . . . 45 4.1.4 Winning conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45 4.2 Decomposing Complex Assertions . . . . . . . . . . . . . . . . . . . . . . . . . 46 4.3 Adequateness of the Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 4.4 Alternative Rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 4.5 Rules for Other Connectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61</p>
      </sec>
      <sec>
         <title>5 Truth Comparison Games</title>
      </sec>
      <sec>
         <title>63</title>
         <p>5.1 Extending G by Additional Operators . . . . . . . . . . . . . . . . . . . . . . . 66</p>
      </sec>
      <sec>
         <title>6 Implementation of Giles’s Game</title>
      </sec>
      <sec>
         <title>69</title>
         <p>6.1 Webgame . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69 6.2 Giles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 6.3 Hypseq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75 6.4 TCGame . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75</p>
      </sec>
      <sec>
         <title>Notation used Bibliography List of Figures List of Tables Index</title>
      </sec>
      <sec>
         <title>77 79 82 83 84</title>
         <p>“Everything is vague to a degree you do not realize till you have tried to make it precise.” Bertrand Russell</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>1</p>
      </sec>
      <sec>
         <title>Introduction</title>
         <p>Vagueness is a ubiquitous and pervasive phenomenon in information processing. Modelling vagueness is often accomplished by assigning degrees of truth to propositions. Fuzzy logics, taken here in Zadeh’s “narrow sense” [Zad96], are based on the extension of the two classical truth values by infinitely many intermediary degrees of truth. Degrees of truth should strictly be distinguished from degrees of belief, and therefore require methods different from probability theory. In particular, in fuzzy logics the semantics of the logical connectives is required to be truth functional. In the 1970s Robin Giles attempted to provide an operational foundation for formal reasoning in physical theories based on atomic experiments that may show dispersion. A formula is interpreted by a strategic game, where two players bet on the combined results of atomic experiments, that may show different outcomes when repeated. The degree of truth is then related to the expected loss of the player initially asserting the formula. Giles proved that the propositions that a player can bet on without expecting loss coincide with those that are valid in Lukasiewicz Logic, one of three fundamental, so-called t-norm based fuzzy logics. Giles’s remarkable result can, with hindsight, be seen as one of the few attempts to solve a fundamental problem in approximate reasoning: how to derive a fuzzy logic from first principles, in this case from dialogue rules combined with a betting scheme.  In Chapter 2 we motivate fuzzy logics based on so-called t-norms. We present the three fundamental t-norm based fuzzy logics Lukasiewicz Logic L , Product Logic Π , and Gödel Logic G . An analytic proof system for these three logics based on relational hypersequents is described which is of special interest in the context of Giles’s Game. Chapter 3 presents Giles’s Game itself. Giles’s approach of reasoning in physical theories by assigning a “tangible meaning” to propositions is motivated and discussed. The dialogue game rules for subsequently decomposing compound propositions as well as an adequate betting scheme for atomic propositions are given. This chapter also includes a version of Giles’s proof which relates the game to Lukasiewicz Logic. Moreover, we provide hints at an extension of Giles’s Game adequate for first order Lukasiewicz Logic. Chapter 4 shows that variants of Giles’s Game are adequate for Product Logic and Gödel Logic. This is accomplished in the first place by changing the underlying betting scheme. We also have to modify the game rules for decomposing implications. Several ways of doing so are presented. Chapter 5 presents so-called truth comparison games. This type of game is a dialogue game adequate for Gödel Logic G which, in contrast to L and Π , only requires the comparison of different degrees of truth and no arithmetical operations on these. We also show how to model strategies for both players in this framework. These strategies can be used for characterizing validity and refutability of formulas in Gödel Logic. In the context of this thesis four small tools have been implemented. The applications and their usage are subject of Chapter 6:</p>
      </sec>
      <sec>
         <title>Webgame:</title>
         <p>A web-based application which enables the interactive exploration of Giles’s Game and its variants for Product Logic and Gödel Logic. After playing the game and having reached a final game state, one can simulate the evaluation of atomic propositions based on (dispersive) experiments using the respective betting scheme.</p>
      </sec>
      <sec>
         <title>Giles:</title>
         <p>A utility which creates and visualizes game trees of Giles’s Game. Most illustrations of game trees in this thesis are generated using giles .</p>
      </sec>
      <sec>
         <title>Hypseq:</title>
         <p>A tool which constructs and displays derivations of hypersequents in the hypersequent calculus rH presented in Section 2.6.</p>
      </sec>
      <sec>
         <title>TCGame:</title>
         <p>A tool which searches for winning strategies for the proponent in the truth comparison game presented in Chapter 5. Such a strategy can be displayed as a tree and can be seen as a proof of the initial proposition of the game.</p>
         <p>“There is nothing worse than a sharp image of a fuzzy concept.” Anselm Adams</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>2</p>
      </sec>
      <sec>
         <title>T-Norm Based Fuzzy Logics</title>
         <p>In this chapter we concretize the notion of a fuzzy logic by choosing so called t-norms as a starting point for defining a logic. We then describe three important t-norms and corresponding logics in more detail, which are of special relevance when dealing with dialogue games later on. This chapter also includes a brief description of a proof system using relational hypersequents and uniform rules for those three logics.  Fuzzy logics are commonly understood as many valued logics that allow to model reasoning in presence of different degrees of truth. In order to achieve this, we follow Petr Hájek ([Há02] and [Háj02]) in making the following fundamental “design choices”:</p>
         <p>2.1 Design Choices</p>
         <p>1. The real unit interval [ 0, 1 ] is taken as our set of truth values, 0 meaning absolute falsity, 1 standing for absolute truth. The truth values are linearly ordered using the usual ordering . An important implication of this choice is that we always can compare the truth values of two propositions. For example, we can say, the proposition “I am tall” is true to a higher degree than the proposition “the weather is good today”.</p>
         <p>2. The truth value of a formula ( A, B ) shall solely be determined by the truth values of the formulas A and B . This notion is called truth functionality and is formalized as follows: Each binary connective shall have a truth function f : [ 0, 1 ] 2 → [ 0, 1 ] determining for any pair of formulas the truth degree of the compound formula and similarly for unary connectives. This requirement, for example, hinders us to simply regard truth values as probabilities of arbitrary events; the resulting logic would not be truth functional: The probability value of the proposition “ A and B ” then is not composable into the truth values of A and B alone, but depends on how these events are related to each other. In general one cannot assume that arbitrary experiments are independent of each other. The same applies to propositions of the form “ A or B ” as the probability P ( A or B ) can be calculated as P ( A or B ) = P ( A )+ P ( B )− P ( A and B ) . Nevertheless, there are approaches to probabilistic reasoning in a logical framework; see e.g. [HGE95]. 3. When choosing truth functions for connectives each fuzzy logic shall be a generalization of classical logic. So, for the truth values 0 and 1 the truth functions must behave classically. For example, if we call a connective “ → ” implication, its truth function f → : [ 0, 1 ] 2 → [ 0, 1 ] must satisfy the equalities f → ( 0, 1 ) = 1, f → ( 0, 0 ) = 1, f → ( 1, 0 ) = 0 and f → ( 1, 1 ) = 1 . Hence, all tautologies (formulas that always evaluate to the truth value 1 regardless of the truth values of their atoms) in our fuzzy logic are also classical tautologies, while the other way round this does not need to be true. 4. We start with formulating requirements for the conjunction. These requirements are described using the notion of a t-norm (see the next section). Based on the truth function for conjunction a “reasonable” definition for implication can be formulated; we then will see that having defined truth functions for conjunction and implication the truth functions for the other connectives are determined as well. 5. The truth function f ¬ for the negation is defined by f ¬ ( a ) := f → ( f ( a ) , 0 ) where f ( a ) is the truth value of a and f → is the truth function for the implication. In other words: The truth value for the negation of a proposition states to which degree we can conclude an absolutely false statement from this proposition.</p>
         <p>This view of fuzzy logics also corresponds to what Lotfi A. Zadeh, the inventor of fuzzy sets, describes as fuzzy logics in a narrow sense , [Zad96],[RJM94]. Moreover, we will restrict ourselves to propositional fuzzy logics ; a short treatment of predicate fuzzy logics and their relation to dialogue games will be in Section 3.7.  As mentioned above we start defining a fuzzy logic by looking for suitable truth functions for conjunction. Possible candidate functions must adhere to the following rather intuitive requirements: Asserting the statement “ A and B ” shall be equivalent to asserting the statement “ B and A ”. Although, in natural language this is not necessarily the case (because the emphasis is rather placed on A respectively B ) we require this in analogy to classical logic. Let “ A and B ” be a proposition with truth value v . Then, if we replace A by another statement which has a higher truth value than A , the truth value of the new conjunction shall not be smaller than v and similarly for B . Moreover, a small change in the truth value of A should only result in a small change in the truth value of the statement “ A and B ”, and the same for B . Thus, we require continuity of our truth function 1 . Finally, in order to ensure that classical logic remains a special case we will further require that 1 is the unit element and 0 the zero element. Thus we arrive at the notion of a t-norm:</p>
         <p>2.2 T-Norms</p>
         <p>Definition 1. A function ∗ : [ 0, 1 ] 2 → [ 0, 1 ] is called a t-norm if it is commutative and associative: x ∗ y = y ∗ x ( x ∗ y ) ∗ z = x ∗ ( y ∗ z ) , 1 ∗ x = x and 0 ∗ x = 0 . non-decreasing in both arguments: x x implies x ∗ y x ∗ y, y y implies x ∗ y x ∗ y , 1 Following this argument, it would suffice to require the t-norm to be continuous in each of its variables, which is in general weaker than calling for continuity of the function itself. However, it can be proved that because of the non-decreasingness of t-norms, these two properties are equivalent. (See [KMP00], Chapter 1, Proposition 1.19 )</p>
         <p>A t-norm is continuous if the functions ∗ x ( y ) : [ 0, 1 ] → [ 0, 1 ] , ∗ x ( y ) := x ∗ y and ∗ y ( x ) : [ 0, 1 ] → [ 0, 1 ] , ∗ y ( x ) := x ∗ y are continuous. There exist infinitely many different t-norms, but we will only deal with three of them: 1. Lukasiewicz t-norm ∗ L : x ∗ L y = max ( 0, x + y − 1 ) , 2. Gödel t-norm ∗ G : x ∗ G y = min ( x, y ) , 3. Product t-norm ∗ Π : x ∗ Π y = x · y</p>
         <p>These are considered to be the most important ones. All other continuous t-norms can be obtained from them using a so-called ordinal sum construction. (See [Há02] for a precise description and proof.) For defining a truth function for implication for a given t-norm, we will make use of the residuum of a given t-norm:</p>
         <p>Definition 2. Let ∗ be a continuous t-norm. Then the operation x ⇒ ∗ y 2 is defined as x ⇒ ∗ y := sup { z | x ∗ z y } . It is called the residuum of ∗ . Lemma 1. Let ∗ be a continuous t-norm and ⇒ ∗ its residuum. Then x ∗ ( x ⇒ ∗ y ) y holds. Proof. x ∗ ( x ⇒ ∗ y ) = x ∗ sup { z | x ∗ z y } = sup { x ∗ z | x ∗ z y } y Here we make use of the fact that the t-norm ∗ is non-decreasing and continuous in its second argument. Instead of x ∗ ( x ⇒ ∗ y ) y we could also write ( x ⇒ ∗ y ) ∈ { z | x ∗ z y } or sup { z | x ∗ z y } ∈ { z | x ∗ z y } . As we see, we could have defined x ⇒ ∗ y as max { z | x ∗ z y } as well. The residuum, as it is defined here, is uniquely determined by the property ∀ x, y, z ∈ [ 0, 1 ] : z ∗ x y if and only if z x ⇒ ∗ y</p>
         <p>In fact, ∗ does not even have to be continuous. The condition already holds for all left- continuous t-norms. The logic based on all left-continuous t-norms is called monoidal t-norm logic or short MTL (see [EG01]). 2 Instead of e.g. ⇒ ∗ L we will just write ⇒ L .  There are several reasons suggesting to use the residuum as the truth function for implication:</p>
         <p>The residuum x ⇒ ∗ y is non-increasing in x and non-decreasing in y . This means that the implication gets less true as we make the antecedent x more true. Vice versa, the implication gets more true as we make the succedent more true. Knowing the truth values x and x ⇒ ∗ y one can compute the truth value y (a lower bound of y , respectively) using the term x ∗ ( x ⇒ ∗ y ) . Moreover, if x y we can show that x ∗ ( x ⇒ ∗ y ) = y . This follows from the last step of the proof of the lemma together with the consideration that f x ( y ) := x ∗ y is continuous ( x ∗ 1 = f x ( 1 ) = x and x ∗ 0 = f x ( 0 ) = 0 , thus there must exist a z such that f x ( z ) = x ∗ z = y ): x ∗ ( x ⇒ ∗ y ) = sup { x ∗ z | x ∗ z y } = y This can be regarded as a fuzzy version of the modus ponens inference rule. In analogy to classical logic, where we can conclude everything from a false antecedent (quodlibet ex falso), x ⇒ ∗ y evaluates to 1 if x is smaller than y .</p>
         <p>So, the expression x ∗ ( x ⇒ ∗ y ) evaluates to y if y x and to x if x y ; thus, it gives us the minimum of x and y . Similarly, it is possible to express the maximum in terms of ∗ and ⇒ ∗ using the following lemma:</p>
         <p>Lemma 2. For each continuous t-norm ∗ and its residuum ⇒ ∗ the following two equalities hold: (i) min ( x, y ) = x ∗ ( x ⇒ ∗ y ) (ii) max ( x, y ) = min (( x ⇒ ∗ y ) ⇒ ∗ y, ( y ⇒ ∗ x ) ⇒ ∗ x )</p>
         <p>Proof. (i) we have just seen. (ii): Let x y . Then x ⇒ ∗ y = 1 and ( x ⇒ ∗ y ) ⇒ ∗ y = 1 ⇒ ∗ y = y . On the other hand, we know y ∗ ( y ⇒ ∗ x ) x and using the definition of the residuum we can conclude that y ( y ⇒ ∗ x ) ⇒ ∗ x . Thus, min ((( x ⇒ ∗ y ) ⇒ ∗ y ) , (( y ⇒ ∗ x ) ⇒ ∗ x )) = y ; the case y x is symmetric.  For the three t-norms mentioned above it is possible to compute their residua directly: 3 Note that, although we only use continuous t-norms, their residua do not need to be contin- 3 The residuum of product conjunction is also often called Goguen implication in literature.</p>
         <p>uous. In fact, it is possible to show that the residuum ⇒ L of Lukasiewicz Logic is the only continuous one. t-norm residuum Lukasiewicz x ∗ y = max ( 0, x + y − 1 ) x ⇒ L y = min ( 1, 1 − x + y ) 1 if x y Gödel x ∗ y = min ( x, y ) x ⇒ G y = y otherwise 1 if x y Product x ∗ y = x · y x ⇒ Π y = y/x otherwise</p>
         <table-wrap id="T2.1">
            <caption>
               <p>Table 2.1: T-Norms and Their Residua</p>
            </caption>
         </table-wrap>
         <p>Given a continuous t-norm and its residuum we are now ready to define a propositional logic. To denote atomic propositions we use lower letters a, b, . . . , for arbitrary propositions we use the upper letters A, B, . . . .</p>
         <p>Definition 3. Let ∗ be a continuous t-norm and ⇒ ∗ its residuum. We define a logic L ∗ based on a language with binary connectives → , &amp; and constant ⊥ . A valuation or interpretation for L ∗ is a function v assigning to each propositional variable a truth value from the real unit interval [ 0, 1 ] , uniquely extended to v ∗ for formulas by: v ∗ ( A &amp; B ) = v ∗ ( A ) ∗ v ∗ ( B ) v ∗ ( A → B ) = v ( A ) ⇒ ∗ v ( B ) v ∗ ( ⊥ ) = 0 Furthermore, based on these three ones we define the following connectives: ¬ A := A → ⊥ A ∧ B := A &amp; ( A → B ) A ∨ B := (( A → B ) → B ) ∧ (( B → A ) → A ) Definition 4. Let ∗ be a continuous t-norm. Then two formulas A and B are equivalent in L ∗ , denoted A ≡ B , if and only if for all valuations v , the equality v ∗ ( A ) = v ∗ ( B ) holds.</p>
         <p>To distinguish between &amp; and ∧ , which represent different forms of conjunction, we call &amp; strong conjunction and ∧ min-conjunction . Note that, by Lemma 2 min-conjunction and disjunction just select the minimum, respectively the maximum, of the truth values of its two arguments. We call the logics L ∗ L , L ∗ G and L ∗ Π , Lukasiewicz Logic L , Gödel Logic G and Product Logic Π , respectively. Finally, the notion of a valid formula is defined as expected:</p>
         <p>Definition 5. Let L ∗ be the logic based on the t-norm ∗ . A formula A is valid in L ∗ , written = L ∗ A , iff v ∗ ( A ) = 1 for all valuations v for L ∗ . 2.3 Lukasiewicz Logic Lukasiewicz Logic L is the fuzzy logic based on the Lukasiewicz t-norm x ∗ L y = max ( 0, x + y − 1 ) . In the 1920s Jan Lukasiewicz introduced a family of many-valued logics [Luk20]. L is the infinite-valued member of this family. x*y x =&gt; * y 1 1 0.8 0.8 0.6 0.6 0.4 0.4 0.2 0.2 1 1 0 0 0.8 0 0 0.8 0.2 0.6 0.2 0.6 0.4 0.6 0.4 y 0.4 0.6 0.4 y x 0.8 0.2 x 0.8 0.2 1 0 1 0 (a) The Lukasiewicz T-Norm (b) Residuum of the Lukasiewicz T- Norm</p>
         <fig id="F2.1">
            <caption>
               <p>Figure 2.1: Lukasiewicz T-Norm</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Theorem 1. Lukasiewicz Logic L is the only logic based on a continuous t-norm where ⇒ ∗ is continuous. For a proof of Theorem 1 we refer to [FK06].</p>
         <p>Another property of L is that all connectives are definable by the implication → and the constant ⊥ . Since the connectives ∨ , ∧ , and ¬ are derived from → , &amp; and ⊥ in Definition 3, the only relevant connective here is &amp;:</p>
         <p>Lemma 3. Strong conjunction &amp; can be defined as A &amp; B := ¬ ( A → ¬ B ) . Proof. According to Definition 3 the valuation of the formulas ¬ ( A → ¬ B ) is calculated as 1 − v L ( A ) ⇒ L ( 1 − v L ( B )) . We see that v L ( ¬ ( A → ¬ B )) equals 0 if v L ( A ) + v L ( B ) 1 holds and equals v L ( A ) + v L ( B ) − 1 otherwise which is equivalent to ∗ L .</p>
         <p>Moreover, the maximum of two truth values can be expressed as follows: max ( x, y ) = (( x ⇒ L y ) ⇒ L y ) yielding a simpler definition for ∨ , namely A ∨ B := (( A → B ) → B ) . Lukasiewicz also gave an axiomatic characterization of L : (L1) A → ( B → A ) (L2) ( A → B ) → (( B → C ) → ( A → C )) (L3) ( ¬ A → ¬ B ) → ( B → A ) (L4) (( A → B ) → B ) → (( B → A ) → A )</p>
         <p>A formula A is derivable from this four axioms by modus ponens if and only if = L A holds, i.e. if and only if v L ( A ) = 1 for all valuations v for L . A proof of this is presented in [HGE95]. Note that negation is involutive in L , i.e. ¬ = A ≡ A holds for all formulas A .  Gödel Logic G is based on the t-norm x ∗ G y = min ( x, y ) . Thus, the same truth value is assigned to both formulas A and A &amp; A . Moreover, the connectives ∧ and &amp; coincide. Kurt Gödel defined a family of finite-valued logics in [Göd32]. G was introduced 1959 by Dummet [Dum59] as the infinite-valued version of these logics. Note that G does not enjoy double negation. Instead, it is easy to see that   1 if v G ( A ) = 0 v G ( ¬ A ) =  0 otherwise As for Lukasiewicz Logic, there exist also axiomatizations for Gödel Logic. One of particular interest is obtained when taking an axiomatization of Intuitionistic Logic and adding the following axiom: (( A → B ) → C ) → ((( B → A ) → C ) → C ) (For a proof that this axiomatization is indeed adequate for G we refer to [Há02].) Therefore, G is often called an intermediary logic between Intuitionistic Logic and Classical Logic or, sometimes as well, “Intuitionistic Fuzzy Logic”. Product Logic Π is based on the product t-norm x ∗ Π y = x · y . It was introduced in 1996 [HGE96]. The residuum, x ⇒ Π y = 1 for x y and x ⇒ Π y = y/x otherwise, however was already defined by Goguen in 1969 [Gog69]. The truth function for negation is exactly the same one as for Gödel Logic. Note that the ⇒ Π is not continuous at the point x = 0, y = 0 : There the residuum 0 ⇒ Π 0 is 1 , but the limit lim t → 0 ( t ⇒ Π 0 ) is 0 . As well as for L and G it is possible to give axiomatizations for Π , see [Há02] as an example. In this section we present a uniform and analytic proof system for L , G , and Π following A. Ciabattoni, C.G. Fermüller and G. Metcalfe in [CFM04]; we will refer to it as rH . This proof system is based on so-called relational hypersequents or, short, r-hypersequents and features uniform logical rules for L , G , and Π which are invertible. In spite of the existence of several other calculi for fuzzy logics, this one is of special interest concerning dialogue games. We will see later in Chapter 3 that there is a close correspondence between the game rules of Giles’s Game and the logical rules of rH . Ordinary sequent systems feature rules with the premises as well as the conclusion being a sequent, that is, two (possibly empty) multisets of formulas divided by Gentzen’s sequent arrow , [Gen69]. Hypersequent systems can be seen as an extension to sequent systems where the premises and conclusions do not consist of sequents but of finite sets of sequents. There are calculi for many fuzzy logics presented in a framework of hypersequent systems, see, as an example [MOG05], [Avr91], and [MOG04] for hypersequent calculi for L , G , and Π . On the other hand, relational sequents can be seen as a variant of ordinary Gentzen sequents where Gentzen’s sequent arrow is replaced by other symbols. A relational sequent then may contain one of these symbols instead of the sequent arrow . In [BF99] such sequents are used in a calculus for G which has, in contrast to the respective hypersequent calculus, invertible rules. In the case of rH , we have two types of sequents where in one Gentzen’s sequent arrow is replaced by &lt; and in the other by . When make a statement about relational sequents where that symbol is not important, we will use the variable to denote either or &lt; consistently for the whole statement. Relational hypersequents are the combination of these two concepts. For rH they are formally defined as follows:</p>
         <p>2.4 Gödel Logic</p>
         <p>x * y x =&gt; * y 1 1 0.8 0.8 0.6 0.6 0.4 0.4 0.2 0.2 1 1 0 0 0.8 0 0 0.8 0.2 0.6 0.2 0.6 0.4 0.6 0.4 y 0.4 0.6 0.4 y x 0.8 0.2 x 0.8 0.2 1 0 1 0 (a) The Gödel T-Norm (b) Residuum of the Gödel T-Norm</p>
         <fig id="F2.2">
            <caption>
               <p>Figure 2.2: Gödel T-Norm</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>2.5 Product Logic</p>
         <p>x*y x =&gt; * y 1 1 0.8 0.8 0.6 0.6 0.4 0.4 0.2 0.2 1 1 0 0 0.8 0 0 0.8 0.2 0.6 0.2 0.6 0.4 0.6 0.4 y 0.4 0.6 0.4 y x 0.8 0.2 x 0.8 0.2 1 0 1 0 (a) The Product T-Norm (b) Residuum of the Product T-Norm</p>
         <fig id="F2.3">
            <caption>
               <p>Figure 2.3: Product T-Norm</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>2.6 A Uniform Hypersequent System</p>
         <p>Definition 6. A relational hypersequent (r-hypersequent) is a finite multiset of the form: G = Γ 1 1 ∆ 1 | . . . | Γ n n ∆ n where i ∈ { &lt;, } and Γ i and ∆ i are finite multisets of formulas for i = 1, . . . , n . The r-hypersequent G is called atomic if all formulas in G are atomic. Next we define which r-hypersequents are regarded to be valid :</p>
         <p>Definition 7. An r-hypersequent G = Γ 1 1 ∆ 1 | . . . | Γ n n ∆ n is valid for L ∈ { L , G , Π } , written = L G , iff for all valuations v for L , # v L Γ i i # v L ∆ i for some i, 1 i n, where # L v ∅ = 1 for L ∈ { L , G , Π } and # v L ( Γ ) = 1 + { v ( A ) − 1 } # v G ( Γ ) = 1 + min { v ( A ) } # Π v ( Γ ) = 1 + { v ( A ) } A ∈ Γ A ∈ Γ A ∈ Γ</p>
         <p>Note that using this definition, for any formula A the hypersequent A is valid iff A is valid in the respective logic. Also note that the symbols &lt; and are used both semantically as relations and syntactically as symbols in sequents. Since an r-hypersequent is valid if one relational sequent occurring in it is valid (viewed as an r-hypersequent with one element), an r-hypersequent can be regarded as a disjunction of sequents at the meta-level. The logical rules of rH to decompose non-atomic r-hypersequents are defined as follows: ( G and H are used as metavariables to denote possibly empty r-hypersequents; Γ, A is short for Γ ∪ · { A } and Γ, ∆ for Γ ∪ · ∆ where ∪ · is the multiset union.</p>
         <p>Definition 8. We define the following uniform logical rules for ∈ { &lt;, } : G | Γ ∆ | Γ, B A, ∆ G | Γ ∆ | B&lt;A ( → , , l ) G | Γ, A → B ∆ G | Γ ∆ G | Γ, A B, ∆ | A B ( → , , r ) G | Γ A → B, ∆ G | Γ, A, B ∆ G | Γ, ⊥ ∆ G | Γ ⊥ , ∆ | Γ A, B, ∆ ( &amp; , , l ) ( &amp; , , r ) G | Γ, A &amp; B ∆ G | Γ A &amp; B, ∆ As an example the rule ( &amp; , , l ) can be read as: “If both r-hypersequents G | Γ, A, B ∆ and G | Γ, ⊥ ∆ are derivable, then the r-hypersequent G | Γ, A &amp; B ∆ is derivable as well.” Theorem 2. Soundness and Completeness of rH : Soundness : If an r-hypersequent G is derivable in rH from atomic r-hypersequents valid in L , G , or Π , then G is valid in L , G , or Π respectively. Completeness : If an r-hypersequent is valid in L , G , or Π then G is derivable in rH from atomic r-hypersequents valid in L , G , or Π respectively.</p>
         <p>For a proof of Theorem 2 we refer to [CFM04]. Note that by Theorem 2 a formula A is valid in L , G , or Π if and only if “ A ” is derivable in rH . From Theorem 2 it is easy to prove the following:</p>
         <p>Theorem 3. The rules of rH are invertible : E.g. if the r-hypersequent G | Γ, A &amp; B ∆ is valid, then both r-hypersequents G | Γ, A, B ∆ and G | Γ, ⊥ ∆ are valid as well.</p>
         <p>Another property of rH which is easy to observe is its analyticity: Every formula occuring in a premise also occurs in the conclusion. This implies that in a derivation of A only subformulas of A occur. Uniform rules for ∧ and ∨ are derivable using Definition 3 but we can also give more streamlined versions:  Obviously, repeatedly applying the uniform logical rules upwards to an r-hypersequent terminates with atomic r-hypersequents. Such a derivation can be seen as a tree with the starting r-hypersequent as root and atomic r-hypersequents as leaves. In order to decide if the r-hypersequent in the root of such a tree is valid, we have to decide this property for each leaf. Because of the soundness property of rH , if all of them are valid, then we can conclude that the r-hypersequent in the root is valid as well. As an example <xref id="XR142" ref-type="fig" rid="F2.4">Figure 2.4</xref> shows a proof tree starting with the r-hypersequent ( a ( a → b )) → b .</p>
         <p>G | Γ, A ∆ | Γ, B ∆ G | Γ A, ∆ G | Γ B, ∆ ( ∧ , , l ) ( ∧ , , r ) G | Γ, A ∧ B ∆ G | Γ A ∧ B, ∆ G | Γ, A ∆ G | Γ, B ∆ G | Γ A, ∆ | Γ B, ∆ ( ∨ , , l ) ( ∨ , , r ) G | Γ A ∨ B, ∆ G | Γ, A ∨ B ∆</p>
         <p>( Atomic ) ( Atomic ) a b | a, b a, b a b | b&lt;a ( Atomic ) ( → , , l ) ( Atomic ) a, a → b b ⊥ b (&amp; , , l ) a &amp; ( a → b ) b ( → , , r ) ( a &amp; ( a → b )) → b</p>
         <fig id="F2.4">
            <caption>
               <p>Figure 2.4: Sample proof for a &amp; ( a → b )</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>In [CFM04] it is shown that checking an atomic r-hypersequent for validity is polynomial. For Lukasiewicz Logic, for example, this can be done efficiently using linear programming. Checking the validity of an arbitrary r-hypersequent is not polynomial, of course. Moreover,  when applying the given rules upwards, the size of the r-hypersequents may grow exponen- tially. To overcome this problem it is possible to define new rules at the cost of introducing new propositional variables at each step. For the definition of these rules, as well as purely syntactic calculi for L , G , and Π together with proofs of soundness and completeness of these calculi (including the calculus defined here) we refer to [CFM04]. If we are only interested in Lukasiewicz Logic we can simplify the rules of rH for decomposing implications without affecting the soundness and the completeness of the calculus. In this case we can use the following two rules instead:</p>
         <p>G | Γ ∆ | Γ, B A, ∆ G | Γ ∆ G | Γ, A B, ∆ ( → , , l ) ( → , , r ) G | Γ, A → B ∆ G | Γ A → B, ∆ Here the relation “ &lt; ” is not needed.</p>
         <p>“Half this game is 90% mental.” Danny Ozark, manager of the Philadelphia Phillies</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>3</p>
      </sec>
      <sec>
         <title>Giles’s Game</title>
         <p>This chapter describes a way of modeling the semantics of fuzzy logics using dialogue games combined with bets, proposed by Robin Giles in the 1970s [Gil74]. We motivate this approach, present the game itself, and show the correspondence between the game and Lukasiewicz Logic.</p>
         <p>3.1 Motivation Robin Giles, a physicist and philosopher of science, presented his characterization of Lukasiewicz Logic by means of dialogue games in the 1970s while striving for a logic to describe reasoning about physical experiments. It is assumed that a physical experiment referring to a theory admits an unlimited number of trials. The reason for this is that a proposition in a physical theory must not predict an event in the future at an absolute date, but predict, what will happen if certain preconditions are satisfied. So, an experiment consists of a number of preconditions and descriptions of what the outcome should be; Giles calls these conditions of admissability . For example, the proposition</p>
         <p>“When there are dark 1 clouds, it will rain within the next hour” might be formulated as: 1. Look for a dark cloud. If it is not seen, the trial is inadmissable. 2. If a dark cloud is seen, wait for rain for one hour. 3. If it rains the outcome is ’yes’, otherwise it is ’no’ ”.</p>
         <p>The point is now, that the outcome of a trial does not always need to be the same. Giles calls such experiments dispersive and the ones which always yield the same outcome are dispersion-free . In some cases, it is possible to make a dispersive experiment dispersion-free or “less” dispersive by adding more conditions of admissability. In our (naive) example, we could add the precondition that the temperature has to be above zero degrees Celsius (because otherwise it would snow instead of rain). In some areas it is possible to use only dispersion-free propositions, for example geometry or classical mechanics, but in other areas this is just not possible, as in quantum mechanics. There it can occur that exactly the same experiment yields different results on a number of trials and there are no possible preconditions to add which would make the the experiment significantly less dispersive. This arguably calls for a non-classical logic, as there is no way to capture this phenomenon using classical logic directly. One way to remedy this situation is to use probabilities. For a dispersive experiment A , one could make an assertion such as “ the probability of obtaining the outcome ’yes’ when conducting A exceeds 1 ”. Giles now gives two different explanations 2 for what is meant by such a statement: the avowed meaning and the tangible meaning . The avowed meaning is the explanation which a physicist making an assertion would give to someone else. For the above example this might be that the limit of the ratio of “yes” outcomes to “no” outcomes in an infinite series of trials is larger than 1 . For dispersive 2 experiments such an assertion may be unverifiable, since verifying it would require infinitely many trials. Moreover, the probabilities two physicists assign to the very same dispersive experiment may differ, as these assignments are based on their experience and there is no effective way of deciding who is right. In contrast, the tangible meaning requires a different approach; it rather consists of an exact description of some obligation undertaken by the assertor. For example, a physicist stating our example assertion may act as follows: If challenged by an enquirer, he will pay ¿ 1 for every “no”-outcome of a trial of A when on the other hand he gets ¿ 1 for every “yes”- outcome. This sense of meaning relates better to actual communication than the avowed  meaning. Note that, in order to make such an assertion, the physicist will probably think about the success probability of his experiment as well as an enquirer will do (otherwise they would be squandering money), but none of them claims that his probability is the true objective probability value. The next question is how to deal with logical connectives. For example, if there are two assertions A and B and a physicist asserts “ A and B ” or “ A implies B ” how should a suitable tangible meaning be derived? In the dispersion-free case the answer is easy, one can use classical logic for this, but in the dispersive case this is not possible. Giles uses dialogue games for that purpose: Assume that the physicist and his enquirer are engaged in a debate following certain rules, until finally both end up only making assertions with all connectives eliminated on which they can bet. The resulting dialogue and the betting on the assertions together constitute the tangible meaning of the initial assertion. The game rules for decomposing compound propositions are taken from Paul Lorenzen’s [Lor60] who used these rules to define dialogue games for intuitionistic logic. This fact emphasizes a clear separation between the treatment of compound propositions and the evaluation of atomic ones. From a logician’s point of view, there are other advantages of using dialogue games to analyze fuzzy logics. The central point here is the fact the logic presented by Giles using dialogue games and bets coincides with Lukasiewicz logic (as proved in [Gil74]). Using dialogue games it is possible to define Lukasiewicz Logic not by a “volatile” axiomatic system but by a dialogue game with commonly avowed rules which seem “reasonable”. Another reason is to get a better insight into the meaning of logical connectives. (For example: What is the difference between strong conjunction and min-conjunction when used in a dialogue in “real life”?) Although Giles himself originally motivated his dialogue games by physical theories as shown here, in later publications (e.g. [Gil82]), he explicitly speaks of a logic to define grades of membership of fuzzy sets. Note that there is a difference between vague propositions used in fuzzy logics and dispersive physical experiments used by Giles. The former is about degrees of truth whereas the latter is about probabilities which are fundamentally different concepts. The relation between these two established by Giles’s Game is in no way self-evident and will be subject of a formal proof in this chapter. Let us assume that there are two players, called you and me , both of us asserting a finite multiset of atomic propositions. Each atomic proposition is assigned a (physical) experiment. For each experiment a trial can be conducted resulting either in the outcome “yes” or “no”. Note that experiments may be dispersive. For denoting the experiment associated with an atomic proposition we use the following convention:</p>
         <p>1 For the sake of simplicity, let us assume that it is clear to everyone, when a cloud is dark and when it is not.</p>
         <p>3.2 Betting on Positive Results</p>
         <p>Definition 9. Let a be an atomic proposition. Then the experiment associated with a is denoted as E a . Stating “The probability of E a amounts to p ” is short for “The probability that the experiment E a will yield the outcome ‘yes’ amounts to p ”.</p>
         <p>When evaluating the atomic propositions for each proposition a trial of the corresponding experiment is carried out and the following rule is applied:  If a proposition is asserted more than once, the according trial is conducted for each assertion separately. In consequence I can even lose money in such situations where you assert the same propositions as I do. If, for example, we both assert the atomic proposition a , with the probability of E a less than 1 , it is possible that “your” trial of E a yields the outcome “yes” and “my” trial yields the outcome “no”. Therefore I will lose ¿ 1.In contrast, in average you lose approximately as often as I do, so my expected loss is 0 . Another consequence is that we have to distinguish between asserting a proposition once and more than once, which is a difference to classical logic. Note that I can lose at most ¿ 1 for a single assertion of an atomic proposition. The dialogue rules below will ensure that this property remains satisfied also for compound propositions. This is called the principle of limited liability . Let us now introduce the connectives → , ¬ , ∧ , ∨ . We present a dialogue game for arbitrary propositions built up from atomic propositions using these four connectives. Again, there are two players, you and me . In the beginning I assert only one proposition while you assert none. During the game this initial proposition is subsequently decomposed until we both assert only atomic propositions. These can be evaluated by conducting trials as detailed in the previous section. The idea to use a dialogue game as well as the rules themselves refer to Paul Lorenzen’s characterization of intuitionistic logic (see [Lor60]). These rules are intended to specify the meaning of the connectives independently of the underlying evaluation scheme for atomic propositions. Lorenzen’s game uses so-called frame rules to determine which player may attack which of the other player’s assertions at which point and when he may defend his own assertions. In Giles’s Game this is not constrained. Any player who can move is allowed to do so immediately. Moves do not have to alternate and a player can always attack any of the other player’s compound assertions. The result of the game does not depend on the order in which the several assertions are being attacked as will be shown below. Lorenzen calls the one player who asserts the initial proposition the “proponent”, the other player “opponent”, whereas Giles calls the players “me” and “you” with “me” being the proponent; the latter nomenclature is used here. In general, one of the players picks one of the other player’s compound propositions. He can either attack it or grant it:</p>
         <p>Rule 1. Let a be an atomic proposition. He who asserts a agrees to pay his opponent 1 if a trial of E a yields outcome “no”.</p>
         <p>3.3 Decomposing Propositions</p>
         <p>Attacking: the game rules define for each connective how to attack an assertion and how the other player can defend it. Afterwards, the attacked assertion is deleted from the game. Thus, an assertion can only be attacked once. (If the assertion was not deleted after being attacked, it could get attacked by the other player several times, thus violating the principle of limited liability as mentioned in section 3.2.) Granting: the assertion is simply deleted from the game. A player will choose this move if he risks to lose more money by attacking an assertion than by granting it. As we will see, this case occurs only if the attacked compound proposition is an implication.</p>
         <p>Giles’s Game constitutes a pragmatic foundation for logics: asserting that a proposition is true means committing oneself to asserting also another proposition if attacked by the opponent and ultimately an obligation to pay some money according to the betting scheme being presented in the next section. The following game rules are taken directly from [Gil74]. Note that their formulation is rather informal. One has to keep in mind that each move consists of an attack and an answer to this attack, regardless of the context in the current game. Also note that all these rules obey to the principle of limited liability: For a game starting my assertion of a proposition, I always have a strategy guaranteeing that my expected loss in the end does not exceed ¿ 1.</p>
         <p>Implication The rule for implication given by Giles is as follows: Rule 2. He who asserts A → B agrees to assert B if his opponent will assert A .</p>
         <p>For atomic propositions a and b this rule can be motivated as follows: let us assume that I assert the proposition a → b . In classical logic this means that I believe a to be false or b to be true. Now, in the context of dispersive experiments, a does not have to be “completely false” nor does b have to be “absolutely true”; the point is that E b is more probable than E a . If I believe E b to be more probable than E a then I will willingly assert b if you assert a , because when conducting the experiments and then evaluating a → b classically, my assertion will get true more often than it will get false.  Assume that I assert an atomic proposition of the form ¬ a . I would do so, if I believed the probability of a to be rather small. The according dialogue rule should reflect that I am the better off the smaller the probability of a is. To achieve this, the idea is now to let you state a and I, in exchange, state something which is absolutely false. First, let us introduce the atomic proposition ⊥ and the corresponding experiment E ⊥ with probability zero: Using ⊥ , the according rule looks as follows (generalized from atomic experiments to arbitrary ones): Note that this amounts to an instance of the Implication Rule 2, where ¬ A is an abbre- viation for A → ⊥ . In this case, the opponent can safely attack the implication because by asserting A he is surely better off than the proponent who has to assert ⊥ .</p>
         <p>Negation</p>
         <p>Definition 10. Let E ⊥ be an experiment which always evaluates to “no”.</p>
         <p>Rule 3. He who asserts ¬ A agrees to assert ⊥ if his opponent will assert A .</p>
         <p>Disjunction For disjunction Giles gives the following rather natural rule: Rule 4. He who asserts A ∨ B commits himself to assert either A or B at his own choice.</p>
         <p>Note that this rule, in the strict sense, does not really include an attack, but merely consists of a defense. The reason is that an opponent acting rationally will not grant such an assertion, because an attack implies no disadvantages for him. As mentioned above, it does not matter at which point of the game an assertion is being attacked. It suffices to require that the assertion is defended at some point as indicated.</p>
         <p>Conjunction Finally, the rule for conjunction is: Rule 5. He who asserts A ∧ B commits himself to assert either A or B at his opponent’s choice.</p>
         <p>Note that a natural alternative is to stipulate that asserting a conjunction obliges one to assert both conjuncts. However, this requires to allow for admitting falsity in order to maintain the principle of limited liability. Giles motivated this rule in [Gil82] from another perspective.  As an example let me assert the proposition ( a ∧ b ) → ( ¬ b ∨ a ) and let you be the opponent playing against me. The multiset of assertions made by a player at some point in the game is called the player’s tenet . Thus, at the start of the game, my tenet consists in the assertion ( a ∧ b ) → ( ¬ b ∨ a ) and yours is empty. Both tenets together make up the game state . We denote these using the notation “ [ your tenet | my tenet ] ”. In this case the initial game state is [ | ( a ∧ b ) → ( ¬ b ∨ a )] . A game state is called atomic or final if all assertions are atomic. When an atomic game state is reached, the dialogue ends and the evaluation of the atomic assertions begins. At the beginning there is only one compound assertion with implication as its outmost connective. You now have the choice to admit it (in this case we would end up in the state [ | ] ) or to attack it. Let us assume, you do the latter. According to the rule, you must assert the premise a ∧ b , and I must assert the conclusion ¬ b ∨ a in reply. We arrive at the game state [ a ∧ b | ¬ b ∨ a ] . Now I could either challenge your assertion or I could defend mine. Assume I do the former by requiring you to assert a (I could as well have chosen b ); the resulting game state is [ a | ¬ b ∨ a ] . Next I have to defend my assertion, since there is no other compound assertion in the game; let me choose ¬ b . We get to the state [ a | ¬ b ] . Finally, you can choose whether to attack ¬ b . Since you are in any case better off by attacking it (not attacking would result in [ a | ] ) let us assume, you do so. Finally we have reached an atomic state, namely [ a, b | ⊥ ] . When evaluating this final game state we get as a result that I win the game if the sum of the probabilities of of E a and E b is not smaller than 1 . As this is just one example dialogue other choices of you and me might result in other atomic states. Note the correspondence between the dialogue game rules given here and the rules of the hypersequent calculus rH presented in Section 2.6. For example, the rules for an implication are: 2 G | Γ ∆ | Γ, B A, ∆ G | Γ ∆ G | Γ, A B, ∆ ( → , l ) ( → , r ) G | Γ, A → B ∆ G | Γ A → B, ∆ When interpreting the symbol “ | ” as a disjunction at the meta-level, one can read these rules directly as game rules: For ( → , l ) , in the case where you assert an implication A → B , I have the following choice (with Γ, A → B and ∆ representing our tenets): Either I grant your implication ( Γ ∆ ), or I attack it. In the latter case I assert the premisse A while you have to assert the conclusion B which is expressed by Γ, B A, ∆ . For ( → , r ) , in the case where I assert an implication A → B it is up to you which game state we reach next: you can grant my assertion ( Γ ∆ ) or you can attack it ( Γ, A B, ∆ ). Thus, in order to have a winning strategy I must have a winning strategy for both your choices. Having defined the rules for Giles’s Game, we now take a look at which formulas can be decided to be “subjectively true” by means of the game and which properties the resulting logic has got. We see that the game based characterization yields a language semantically richer than classical logic. Furthermore, we will see that this logic coincides with Lukasiewicz Logic.</p>
         <p>An example dialogue</p>
         <p>[ | ((a/\b)-&gt;((b-&gt;0)\/a))] You attack by asserting (a/\b) You grant ((a/\b)-&gt;((b-&gt;0)\/a)) I defend by asserting ((b-&gt;0)\/a) [ | ] [(a/\b) | ((b-&gt;0)\/a)] I choose a I choose b [a | ((b-&gt;0)\/a)] [b | ((b-&gt;0)\/a)] I choose (b-&gt;0) I choose a I choose (b-&gt;0) I choose a [a | (b-&gt;0)] [a | a] [b | (b-&gt;0)] [b | a] You attack by asserting b You attack by asserting b You grant (b-&gt;0) You grant (b-&gt;0) I defend by asserting 0 I defend by asserting 0 [a | ] [b,a | 0] [b | ] [b,b | 0]</p>
         <fig id="F3.1">
            <caption>
               <p>Figure 3.1: Game Tree for the Game Starting With ( a ∧ b ) → ( ¬ b ∨ a )</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>2 As mentioned in Section 2.6 the &lt; symbol is not necessary for Lukasiewicz Logic.</p>
         <p>3.4 Analyzing Giles’s Game</p>
         <p>Definition 11. A proposition is called subjectively true (for me) if I will willingly assert it and subjectively false if I will willingly assert its negation. I willingly assert any proposition if I have a strategy such that in each final state I do not expect any loss. Consider the following three propositions ( a , b and c stand for arbitrary atomic propositions for which an experiment can be carried out): (a) ( a ∧ b ) → c (b) a → ( b → c ) (c) c ∨ ¬ ( a ∧ b )</p>
         <p>These propositions are pairwise classically equivalent: they are all classically true if a is false or b is false or c is true, and are false otherwise. But, when using Giles’s Game there is a semantic difference between these three propositions. Let us consider the first one, “ ( a ∧ b ) → c ”; the according initial game state is [ | ( a ∧ b ) → c ] . You can attack my implication, reaching the state [ a ∧ b | c ] , now I can choose between a and b and the game will end up in either [ a | c ] or [ b | c ] (at my choice). So I will assert  this proposition, if and only if, for me, at least one of the elementary game states [ a | c ] and [ b | c ] is desirable. The game for the second proposition starts with [ | a → ( b → c )] , you can attack by asserting a reaching the state [ a | b → c ] and you can attack again reaching the final state [ a, b | c ] . Again, as for the previous proposition, I will engage in the game if [ a | c ] or [ b | c ] is acceptable for me, because then [ a, b | c ] surely is as well. But, in contrast, I will also engage in the game in other cases. If, for example, I assign a probability value of 0.3 to E a and E b , I expect to get ¿ 1.4 from you at average, but on the other hand I could never lose more than ¿ 1, no matter what the probability of E c was. So, if it was 0.1, neither the final state [ a | c ] nor [ b | c ] would be acceptable, but [ a, b | c ] would. Thus the proposition a → ( b → c ) l is “more general” than the first one. Finally, if I assert the third proposition, i.e. [ | c ∨ ¬ ( a ∧ b )] , I can can choose, according to the or-Rule between [ | c ] and [ | ¬ ( a ∧ b )] as successor states. If I choose the latter, you can safely attack reaching [ a ∧ b | ⊥ ] and at last I can choose between the two final states [ a | ⊥ ] and [ b | ⊥ ] . So, I will assert the proposition if I find at least one of the three final game states [ | c ] , [ a | ⊥ ] and [ b | ⊥ ] acceptable. This will only be the case if I believe E c always to return the outcome “yes”, or E a or E b always to return the outcome “no”. If I do so, I will also assert the other two propositions, but the other way round this is not the case. Thus the third proposition is “less general” than the two others. Another difference to classical logic arises when we take a look at classical tautologies. A tautology or logical identity is usually defined as a proposition which is true under any valuation and we can do the same in the context of Giles’s Game. Following Giles we assume that I, the proponent of the initial proposition, am always capable of assigning probability values to all experiments associated with atomic propositions.</p>
         <p>Definition 12. A (compound) proposition which I would willingly assert, regardless of the probabilities assigned to its atomic parts is called a logical identity .</p>
         <p>In contrast to classical logic this definition would be ambiguous without the assumption that I can assign probability values to all atomic propositions. Take as an example the following two propositions ( a and b being atomic propositions). Both are classical logical identities:</p>
         <p>(a) ( a → b ) → a (b) ( a → b ) ∨ ( b → a )</p>
         <p>For proposition (a) the game starts at [ | a → ( b → a )] ; if you attack the implication, we reach [ a | b → a ] . If you attack my assertion of b → a again we end up in [ a, b | a ] . Now regardless of the probability of E a , our losses from asserting a will cancel in the long run and depending on the results of E b I may gain some money, but I will surely not lose any. If you choose not to challenge both of the implications but to admit one of them, we end up in the game states [ | ] , respectively [ a | ] . In both these final states I will not lose any money in the long run either. Apparently, for example (a) it does not matter which probabilities I assign to the atomic propositions. But for (b) the game starts in [ | ( a → b ) ∨ ( b → a )] . It is my choice which disjunct to choose:</p>
         <p>If I believe E b to be more probable than E a , I will defend the left disjunct reaching [ | a → b ] . If you attack at this point, we will end up in [ a | b ] . Alternatively, if you admit the implication, we will get to [ | ] . In both cases, when repeating the evaluation of the final game state reached, I do not expect to lose any money in the long run. On the other hand, if I believe E a to be more probable than E b , I will defend the right disjunct reaching [ | b → a ] and ending up in either [ b | a ] or in [ | ] . Again, in both cases I do not expect to lose any money in the long run. If I believe a to be exactly as probable as b , it does not matter which part I choose as in every final state reachable I would neither lose (nor win) any money in the long run.</p>
         <p>We see that proposition (b) is subjectively true (for me) for every possible assignment of probabilities to the experiments E a and E b , but unlike proposition (a) I must have this knowledge in order to find an optimal strategy for me.  Giles’s Game can be interpreted as zero sum game with perfect information in terms of game theory: We stipulate that I am able to assign subjective probability values to all experiments associated with atomic propositions. If I want to analyze the game regardless of your strategy, then I can assume that you play according to the same subjective probability values as I do. Then your decisions, you playing rationally, will be in fact the “worst case” for me at the same time. This way we are able to use insights from game theory about zero sum games with perfect information during our analysis of Giles’s Game such as the existence of optimal strategies. As motivated by the last example as well as for further analyzing the game, we now assume, that I can assign a probability value π ( E a ) to each atomic proposition. A language where this is possible is called probability definite (as opposed to truth definite from classical logic). At the first glance this seems to contradict the motivation of Giles’s Game that calls for “tangible meanings” instead of “avowed meanings” which are employed when using probabilities classically. To overcome this, Giles gives a definition of subjective probabilities that provides a tangible meaning for them:</p>
         <p>3.4.1 Risk Values and Valuations</p>
         <p>Definition 13. Let a be an atomic proposition. Then the subjective probability of a , denoted π ( E a ) , with respect to a player P is the real value such that for any &gt; 0 , he is willing: (a) to assert a in return for a payment of ( 1 − π ( E a ) + ) and (b) to assert ¬ a in return for a payment of ¿ ( π ( E a ) + ).</p>
         <p>For example, if I assign the probability 0.2 to the experiment E a , I expect to lose ¿ 0.8 in average when asserting a . If I receive a payment of ¿ ( 1 − 0.2 + ) &gt; ¿ 0.8 for asserting a , it is rational for me to do so. On the other hand, asserting ¬ a corresponds to the final game state [ a | ⊥ ] where I lose ¿ 0.2 in average. Again, for a payment of ¿ ( 0.2 + ) I will willingly do so. The so-called risk values a of an atomic proposition a is defined as my expected loss when asserting a . a = 1 − π ( E a ) and denotes my expected loss when asserting a . So, for any atomic proposition a both 0 a 1 and ⊥ = 1 hold. Similarly, the risk value of a tenet containing only the atomic propositions a 1 , . . . , a n is denoted as n a 1 , . . . , a n L = a i i = 1 and the risk value of an atomic (final) game state [ a 1 , . . . , a n | b 1 , . . . , b m ] as  The aim is to determine a corresponding risk value also for compound propositions once risk values have been assigned to all atomic propositions. To do so, we define the risk value of an arbitrary game state as follows:</p>
         <p>m n a 1 , . . . , a n | b 1 , . . . , b m L = b i − a i i = 1 i = 1</p>
         <p>Definition 14. Let G = [ Γ | ∆ ] be an arbitrary game state. The risk value of G , denoted Γ | ∆ L , is the real value such that in a game starting in G : I have a strategy guaranteeing that my expected loss will never exceed Γ | ∆ L and</p>
         <p>there exists a strategy for you guaranteeing that my expected loss will never be less than Γ | ∆ L . The existence and uniqueness of the risk value of an arbitrary game state follows from the saddle point theorem which is a basic theorem of game theory. It basically assures that, in a zero-sum game with perfect information, there do always exist optimal strategies for both you and me such that a fixed game value can be assigned to the game. This game value will always be the result of the game assuming both players play rationally according to their optimal strategies. In order to determine the risk value for an arbitrary game state we first decide which move to do next and then we look at all possible successor states according to the game rules. If at this move I have a choice to make, r is assigned the minimum of all risk values of the successor states. But on the other hand, if you have a choice to make, I assign r the maximum of all risk values of the successor states. This procedure corresponds to me always making the “best” choice while assuming the “worst case” for your choices. For an assertion made by you my expected loss can be formalized as follows:</p>
         <p>Γ, A → B | ∆ L = min { Γ | ∆ L , Γ, B | A, ∆ L } Γ, A ∧ B | ∆ L = min { Γ, A | ∆ L , Γ, B | ∆ L } Γ, A ∨ B | ∆ L = max { Γ, A | ∆ L , Γ, B | ∆ L } and for assertions made by me: Γ | A → B, ∆ L = max { Γ, A | B, ∆ L , Γ | ∆ L } Γ | A ∧ B, ∆ L = max { Γ | A, ∆ L , Γ | B, ∆ L } Γ | A ∨ B, ∆ L = min { Γ | A, ∆ L , Γ | B, ∆ L }</p>
         <p>It is easy to see that the risk function assigning a real value to each game state is indeed well-defined by these equations i.e. that there is a unique risk value assigned to each game state.  Next we want to prove that this risk function for arbitrary game states corresponds to Lukasiewicz Logic. In order to do so, we first define how to evaluate game states with respect to Lukasiewicz Logic:</p>
         <p>Definition 15. (a) For a proposition A and an interpretation v we define the function A L := 1 − v L ( A ) , where v L is the extension of v to arbitrary propositions as defined in Definition 3, L L (b) for a multiset Γ of propositions we define the function Γ := A ∈ Γ A and L L L (c) for a game state [ Γ | ∆ ] we define the function Γ | ∆ := Γ − ∆ .</p>
         <p>Note that these are only definitions, they are (for now) not related to the risk function for game states given by the rules above; however, they are connected by the following theorem:</p>
         <p>Lemma 4. Let [ Γ | ∆ ] be an arbitrary game state. For each atomic proposition a let v ( a ) = π ( E a ) , i.e. the truth value assigned to a is equal to the subjective probability assigned to L L a . Then Γ | ∆ = Γ | ∆ L , in other words: the functions · | · and · | · L coincide for all game states.</p>
         <p>Proof. We show Lemma 4 using induction on the number of connectives occurring in all propositions in the game state. This can be regarded as the complexity of the game state. If there are zero connectives, there are only atomic propositions and it is easy to see that  Now, assume that the Lemma holds if there are at most k connectives occurring in a game state. We have to check each of the six formulas for defining · | · L on arbitrary game states</p>
         <p>m n m n a 1 , . . . , a n | b 1 , . . . , b m L = b i − a i = ( 1 − v L ( b i )) − ( 1 − v L ( a i )) i = 1 i = 1 i = 1 i = 1 m n m n = ( 1 − π ( E b i )) − ( 1 − π ( E a i )) = b i − a i = a 1 , . . . , a n | b 1 , . . . , b m L . i = 1 i = 1 i = 1 i = 1</p>
         <p>given above; here only two of them are spelled out, for the others it works analogously: L Γ, A → B | ∆ L L L L = ∆ − Γ − A → B = ∆ L − Γ L − 1 + v L ( A → B ) = ∆ L − Γ L − 1 + ( v L ( A ) ⇒ L v L ( B )) = ∆ L − Γ L − 1 + inf { 1, 1 − v L ( A ) + v L ( B ) } L L L L = ∆ − Γ − 1 + inf { 1, 1 − 1 + A + 1 − B } L L L L L L = inf { 1 + ∆ − Γ − 1, 1 + A − B + ∆ − Γ − 1 } L L = inf { Γ | ∆ , Γ, B | A, ∆ } ( ∗ ) = inf { Γ | ∆ L , Γ, B | A, ∆ L } = Γ, A → B | ∆ L .</p>
         <p>where at step ( ∗ ) the induction step is performed: in both game states [ Γ | ∆ ] and [ Γ, B | A, ∆ ] there occur less connectives than in [ Γ, A → B | ∆ ] . If the move involves an implication asserted by me, the proof works as follows (again with the inductions step performed at ∗ ):</p>
         <p>L Γ | A → B, ∆ L L L L = A → B + ∆ − Γ = ∆ L − Γ L + 1 − v L ( A → B ) = ∆ L − Γ L 1 − ( v L ( A ) ⇒ L v L ( B )) = ∆ L − Γ L + 1 − inf { 1, 1 − v L ( A ) + v L ( B ) } = ∆ L − Γ L + 1 + sup { − 1, − 1 + v L ( A ) − v L ( B ) } L L L L = ∆ − Γ + 1 + sup { − 1, − 1 + 1 − A − 1 + B } L L L L L L = sup { − 1 + ∆ − Γ + 1, − 1 − A + B + ∆ − Γ + 1 } LL L = sup { Γ | ∆ , Γ, A | B, ∆ } ( ∗ ) = sup { Γ | ∆ L , Γ, A | B, ∆ L } = Γ | A → B, ∆ L L L L L and analogously for Γ, A ∨ B | ∆ , Γ, A ∧ B | ∆ , Γ | A ∨ B, ∆ and Γ | A ∧ B, ∆ . For an arbitrary proposition A let us define the risk value of A (for me), denoted A L , by</p>
         <p>the risk value of the game state where I assert A and you assert nothing (i.e. [ | A ] ). Using Lemma 4 it is finally possible to show that the inverted risk value 1 − A L and the valuation of A in Lukasiewicz Logic coincide: Theorem 4. Let A be an arbitrary proposition and v an interpretation. Assume that for each atomic proposition a occurring in A that π ( E a ) = v ( a ) (as in Lemma 4). Then the inverted risk value 1 − A coincides with the truth value v L ( A ) induced by v according to Definition 3, i.e. 1 − A L = v L ( A ) . Proof. Let A be an arbitrary proposition. Then: 1 − A L = 1 − | A L = 1 − | A L = 1 − ( 1 − v L ( A )) = v L ( A ) 3.4.2 Stability of Results</p>
         <p>When evaluating an atomic game state, we can not only calculate my expected loss in this game state under a certain valuation. The variance of my loss may as well be of special interest as there is no corresponding concept in Lukasiewicz Logic. One might, for example, order propositions with the same truth value by the variance of my loss in the final game state(s) reached assuming both players play rationally. Let [ a 1 , a 2 , . . . , a k | a k + 1 , a k + 2 , . . . , a n ] be a final game state and let X i with i = 1 . . . n be random variables with X i = 0 if E a i yields the outcome “yes” and X i = 1 otherwise. Furthermore, we stipulate that my expected value of X i , denoted E ( X i ) is equal to the subjective probability of E a i , namely π ( E a i ) . Then the variance Var ( X i ) can be computed as Var ( X i ) = E ( X 2 i ) − ( E ( X i )) 2 = E ( X i ) − ( E ( X i )) 2 (since X i ∈ { 0, 1 } ). The variance of my loss in the game state [ a 1 , a 2 , . . . , a k | a k + 1 , a k + 2 , . . . , a n ] is computed as:  assuming that all random variables are independent from each other (i.e.: their covariance is 0 ). We see that the variance depends on the number of atomic propositions as well as on their valuations. The function f defined by f : [ 0, 1 ] → [ 0, 1 ] , x → x − x 2 has a maximum at x = 0.5 . Therefore, the variance of an atomic game state is larger for atomic propositions where probabilities of the corresponding experiments are near to 0.5 than for propositions where these probabilities are near to 0 or 1 .</p>
         <p>n k Var ( a 1 , . . . , a k | a k + 1 , . . . , a n L = Var ( X i − X i ) i = k + 1 i = 1 n k = Var ( X i ) + Var ( X i ) i = k + 1 i = 1 n = E ( X i ) − ( E ( X i )) 2 i = 1</p>
         <p>3.5 Devising Rules for Other Connectives So far, we have defined rules for the connectives ∧ , ∨ and → corresponding to min-conjunction, max-disjunction and implication. The aim now is to show how rules for other connectives such as strong conjunction and strong disjunction can be derived. In order to do so, we first define, when two game states are equivalent: Definition 16. Two final game states are called equivalent if my expected expected risk is the same for both states for all possible valuations. Thus, as an example, the game final states [ a, b | a ] and [ b | ] are equivalent as my loss and your loss from asserting a will cancel in the long run. Strong Conjunction</p>
         <p>As shown in Lemma 3 strong conjunction can be expressed using only implications by the equivalence A &amp; B ≡ ¬ ( A → ¬ B ) ≡ ( A → ( B → ⊥ )) → ⊥  Thus, one way to deal with formulas containing strong conjunction in Giles’s game is to simply expand them according to the above equivalence so that they contain only connectives the original game is defined for. But if we want to identify a game rule for &amp; there are two other possibilities:</p>
         <p>(a) We can derive a game rule directly using the semantics of &amp; in analogy to Lemma 4, where this is exemplified for the connectives → , ∨ , and ∧ . (b) Alternatively, we can analyze the game tree of a game starting in [ | A &amp; B ] . Again we assume that both players act rationally. This allows us to exclude some final game states and from the remaining ones we can derive a new game rule. By Theorem 4 each formula can be assigned a definite risk value, respectively truth value, between 0 and 1. Therefore we can use this analysis for arbitrary formulas of the form A &amp; B where A and B denote compound formulas. [ | ((a-&gt;(b-&gt;0))-&gt;0)] You attack by asserting (a-&gt;(b-&gt;0)) You grant ((a-&gt;(b-&gt;0))-&gt;0) I defend by asserting 0 [ | ] [(a-&gt;(b-&gt;0)) | 0] I attack by asserting a I grant (a-&gt;(b-&gt;0)) You defend by asserting (b-&gt;0) [ | 0] [(b-&gt;0) | a,0] I attack by asserting b I grant (b-&gt;0) You defend by asserting 0 [ | a,0] [0 | b,a,0]</p>
         <fig id="F3.2">
            <caption>
               <p>Figure 3.2: Game Tree for a &amp; b</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Here we will focus on possibility (b): Let the game start in the game state [ | ( A → ( B → ⊥ )) → ⊥ ] . <xref id="XR287" ref-type="fig" rid="F3.2">Figure 3.2</xref> shows the whole game tree illustrating which player can do which moves at any point in the game. At first, you can attack my implication reaching the game state [ A → ( B → ⊥ ) | ⊥ ] . My risk value for this game state is 1 (because of asserting ⊥ ) but you can, by the principle of limited liability, limit your expected risk to 1 or even lower. So, you playing rationally, will not admit my implication. (Moreover, on the game tree we see that all final states on the right branch are better for you than [ | ] ). Now I have two choices: I can either admit your implication, reaching the final game state [ | ⊥ ] or attack it reaching [ B → ⊥ | A, ⊥ ] . When choosing the latter, I can again decide whether to admit, reaching [ | A, ⊥ ] , or to attack, reaching [ ⊥ | A, B, ⊥ ] , but when playing rationally I have to do the latter move as instead of reaching [ | A, ⊥ ] I could as well have reached [ | ⊥ ] with my first decision which is better than (or at least equal to) the other game state for me. Now the only remaining final game states are [ | ⊥ ] and [ ⊥ | A, B, ⊥ ] , which is equivalent to [ | A, B ] and as we have seen it depends on my decisions which of both ones is reached. So we can define as a “shortcut” a rule for strong conjunction: (Note that this rule also is in accordance with the principle of limited liability.) Rule 6. He who asserts A &amp; B undertakes to either to assert both A and B or to assert ⊥ at his own choice. Note that this rule also gives an intuitive “meaning” to strong conjunction: When asserting “ A &amp; B ” I have to assert both A and B or to admit to have asserted falsity. Using the formal definition of strong conjunction given in chapter 2.2, this meaning was not obvious at all, nor was the difference in the meanings of strong conjunction and min-conjunction. Remark. We can as well motivate this game rule in the way described in (a):</p>
         <p>| A &amp; B L = | A &amp; B = 1 − ( v L ( A ) ∗ v L ( B )) = 1 − max 0, v L ( A ) + v L ( B ) − 1 = min 1, ( 1 − v L ( A )) + ( 1 − v L ( B )) = min ( 1, | A + | B L ) = min ( 1, | A L + | B L ) which also suggests for Rule 6. Strong Disjunction</p>
         <p>The same method can be employed to find a shortcut rule for strong disjunction using the expansion A ∨ B ≡ ¬ A → B ≡ ( A → ⊥ ) → B   <xref id="XR295" ref-type="fig" rid="F3.5">Figure 3.5</xref> shows the corresponding game tree. We can observe that in the game state [ A → ⊥ | B ] I can safely attack your implication because reaching the final game state [ ⊥ | A, B ] is in any case not worse than [ | B ] (because asserting A does never mean a higher risk for me than asserting ⊥ does for you). So there are only two relevant final game states, namely [ | ] and [ ⊥ | A, B ] , but this time it is you who chooses one of them. An according game rule can be formulated as follows:</p>
         <p>[ | ((a-&gt;0)-&gt;b)] You attack by asserting (a-&gt;0) You grant ((a-&gt;0)-&gt;b) I defend by asserting b [ | ] [(a-&gt;0) | b] I attack by asserting a I grant (a-&gt;0) You defend by asserting 0 [ | b] [0 | a,b]</p>
         <fig id="F3.3">
            <caption>
               <p>Figure 3.3: Game Tree for a ∨ b</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Rule 7. He who asserts A ∨ B undertakes to either to assert [ ⊥ | A, B ] if challenged by his opponent.</p>
         <p>In the case of atomic propositions this rule states that I will succeed in the game [ | a ∨ b ] (i.e. have non negative gain) if either the experiment E a or E b or both yield the outcome “yes” in the expected case. This corresponds to what is intuitively understood as conjunction.  Note that we initially could have defined only the game rule for implication (and, thus, negation by using ¬ A ≡ A → ⊥ ). Then we can expand the other connectives ∧ and ∨ using Definitions 3 and 3. The analysis of the according expansions, analogously to as it is done here for strong conjunction and disjunction in this section, then gives us exactly the same game rules as presented originally by Giles. Giles’s game can be used to prove the equality of two formulas with respect to Lukasiewicz Logic. Lemma 2 states that “min ( x, y ) = x ∗ ( x ⇒ ∗ y ) ” which corresponds to the fact that the two formulas “ a ∧ b ” and “ a &amp; ( a → b ) ” are equivalent in Lukasiewicz Logic. We can prove this equivalence by using Giles’s game. In order to do so, we look at the two games starting in “ a ∧ b ” and in “ a &amp; ( a → b ) ”. We try to show that, given a valuation for a and b , my</p>
         <p>3.6 Logical Equivalences as Game Equivalencies Minimum</p>
         <p>expected gain is the same for both formulas (assuming both players play rationally). [ | (a/\b)] You choose a You choose b [ | a] [ | b]</p>
         <fig id="F3.4">
            <caption>
               <p>Figure 3.4: Game Tree for a ∧ b</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>The first game starts in the state [ | a ∧ b ] . If you attack my assertion, you will choose one of the two propositions and we end up either in the state [ | a ] or in the state [ | b ] at your choice.  The second game starts with [ | a &amp; ( a → b )] . I can either choose to admit the falsity of my assertion ending up in [ | ⊥ ] or not, resulting in the successor state [ | a, a → b ] . Now, if you admit the implication asserted by me, we end up in [ | a ] , if you do not, we end up in [ a | a, b ] . This game state is equivalent to the final state [ | b ] . Now, since both these final states are never worse for me than the game state [ | ⊥ ] , I do never have to admit the falsity of my assertion in the first place. So the game ends either in [ | a ] or in a game state which is equivalent to [ | b ] at your choice which is exactly the same result as for the first game and we can conclude that the propositions “ a ∧ b ” and “ a &amp; ( a → b ) ” are equivalent in Lukasiewicz Logic. We can also prove the second equality of Lemma 2, namely “max ( x, y ) = min ((( x ⇒ ∗ y ) ⇒ ∗ y ) , (( y ⇒ ∗ x ) ⇒ ∗ x )) ” which can be formulated as stating that the two formulas “ a ∨ b ” and “( a → ( b → b )) ∧ ( b → ( a → a ) )” are equivalent in Lukasiewicz Logic by employing Giles’s game. The first game starts with [ | a ∨ b ] and ends either in [ | a ] or in [ | b ] at my choice as shown in <xref id="XR320" ref-type="fig" rid="F3">figure 3.6</xref>. The second game starts in the game state [ | (( a → b ) → b ) ∧ (( b → a ) → a )] . <xref id="XR324" ref-type="fig" rid="F3.6">Figure 3.6</xref> shows the according game tree. Note that the final game states [ b | a, b ] and [ a | b, a ] are equivalent to [ | a ] and [ | b ] respectively. We can observe that the final game state [ | ] is worse for you than all other final game states, so you will never choose to reach [ | ] . Furthermore, depending on your choices we will get either to the game state [ a → b | b ] or [ b → a | a ] . But in both states I can decide between ending up in [ | a ] or in [ | b ] (or an equivalent game state), which is exactly the same result we had for the first game. Thus we can conclude that both propositions “ a ∨ b ” and “ (( a → b ) → b ) ∧ (( b → a ) → a ) ” are equivalent in Lukasiewicz Logic.</p>
         <p>[ | (a&amp;(a-&gt;b))] I choose a, (a-&gt;b) I choose 0 [ | (a-&gt;b),a] [ | 0] You attack by asserting a You grant (a-&gt;b) I defend by asserting b [ | a] [a | b,a]</p>
         <fig id="F3.5">
            <caption>
               <p>Figure 3.5: Game Tree for a &amp; ( a → b )</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>Maximum</p>
         <p>[ | (a\/b)] I choose a I choose b [ | a] [ | b]</p>
         <fig id="F3.6">
            <caption>
               <p>Figure 3.6: Game Tree for a ∨ b</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>3.7 Remarks on Quantifiers So far we have considered only propositional fuzzy logics, particularly propositional Lukasiewicz Logic. That means, we had propositional variables as atomic formulas compound propositions built from these by connecting them with unary or binary connectives. If we want to model first order Lukasiewicz Logic, we extend our syntax by variable symbols x, y . . . , constant symbols d, e, . . . , predicate symbols P, Q, . . . and the quantifiers ∃ , ∀ just as for classical first order logic. In the following we restrict our attention to languages where</p>
         <p>for each element of the domain of the intended interpretation there exists a corresponding constant symbol. Valuations are then generalised from propositional formulas to quantifiers as usual. For a continuous t-norm ∗ the semantics of these quantifiers are defined as:</p>
         <p>v ∗ ( ∃ xA ( x )) := sup v ∗ ( A ( d )) d v ∗ ( ∀ xA ( x )) := inf v ∗ ( A ( d )) d</p>
         <p>As for the other connectives we can observe that these quantifiers behave classically if A ( x ) is assigned a truth value of either 0 or 1 for all instances. The question now is, if it is possible to extend Giles’s Game in such a way that it is adequate for first order Lukasiewicz Logic. We will see that we can answer this question only partly positive. We will use the following two rules for dealing with quantifiers:</p>
         <p>Rule 8. He who asserts ∀ xP ( x ) undertakes to assert P ( d ) for any constant chosen by his opponent. Rule 9. He who asserts ∃ xP ( x ) undertakes to assert P ( d ) for some constant chosen by himself.</p>
         <p>These rules, as the other game rules as well, have already been suggested by Lorenzen in [Lor61]. Here is also the reason why we have to require a constant symbol for each possible value a variable can assume: if for a certain value there existed no constant symbol, no player could choose this value according to Rules 8 and 9. Note that, if x can only assume finitely many different values denoted by the constant symbols d 1 , . . . , d n , then, according to rule 5 , stating the proposition ∀ xP ( x ) is equivalent to stating the proposition P ( d 1 ) ∧ P ( d 2 ) ∧ . . . ∧ P ( d n ) . This is in perfect accordance with the “normal” usage of the ∀ quantifier. The same applies to the ∃ quantifier, which can be regarded as a series of disjunctions. We have to extend the concept of conducting experiments: we introduce parametric experiments . A parametric experiment has (finitely many) parameters used when conducting a trial. With each ( n -ary) predicate symbol P we associate a (yes/no) experiment E P , where E P has n parameters corresponding to the arguments of P . Nonparametric experiments then can seen as a special case where the number of parameters is zero. In the example below the argument to P is a natural number. With this game-based characterization of quantifiers, however, two problems arise:</p>
         <p>If I assert ∀ xP ( x ) for an atomic proposition P ( x ) , how should you, in general, decide which constant to choose, if you have no means of calculating it analytically. Especially if E P is some experiment which chaotically depends on the value of its parameter, you would have to try out the experiment for each value that the interpretation assigns to x (that is, possibly infinitely many times). Moreover, there may not exist an optimal choice. Consider, as an example, the following experiment: Let x denote a natural number. Then the experiment E P with parameter x consists of tossing a coin x times. If each time the result is “heads” then the outcome of the experiment is “no”, otherwise it is “yes”. Now assume that I assert the proposition ∃ xP ( x ) . According to rule 9 I will, of course, choose a large value for x as this increases the chances that the outcome of the experiment will be “yes”. But no matter how large the value of x is, choosing a higher value would have been a better choice. So there is no optimal strategy for me and I will not be able to enforce that I will not lose any money in the long run. But, as the valuation of ∃ xP ( x ) is computed as sup d v ( P ( d )) = 1 , I should be able to do so by theorem 4.</p>
         <p>About the first problem, we cannot do much. The only way, if we want to characterize quantifiers by dialogue game rules, is to assume omniscient players. This means that I am capable of assigning not only a subjective probability value for each x to the proposition a ( x ) but, moreover, I know which value of x to choose in order to achieve a desired subjective probability value. 3 Assuming omniscient players, solves this problem, but we then have to keep in mind that this game no longer constitutes a tangible meaning for propositions with quantifiers as in practice such a strategy cannot implemented. According to the second problem, theorem 4 no longer holds when incorporating quantifiers. This does not come completely unexpected: Scarpellini has proved in [Sca62] that first order Lukasiewicz Logic is not axiomatizable. If we could extend Giles’s game by “sim- ple” rules to propositions containing quantifiers, we would be able to define corresponding rules for the relational hypersequent calculus rH . But this would yield an axiomatization of Lukasiewicz Logic, which does apparently not exist. In Definition 14 we defined the risk value of an arbitrary game state G as the smallest risk value of a final state I can enforce for a game starting in G . Now, with the presence of</p>
         <p>3 If it was just for this one problem, it would suffice to know, for which value of x I assume the highest and lowest subjective probability values to the proposition P ( x ) . But, as we will see, for dealing with the second problem we will need more than that.</p>
         <p>quantifiers in our logic, we have to alter this definition as follows: Definition 17. Let G = [ Γ | ∆ ] be an arbitrary game state. The risk value of G , denoted Γ | ∆ L , is the real value such that in a game starting in G for any given value &gt; 0 : I have a strategy guaranteeing that my expected loss will never exceed Γ | ∆ L + and</p>
         <p>there exists a strategy for you guaranteeing that my expected loss will never be less than Γ | ∆ L − . This definition allows us to assign a “sharp” risk value to game states containing propositions with quantifiers, e.g. for the example above the risk value assigned to the game state [ | ∃ xp ( x )] equals 0 because I can enforce a final game state where my risk value is, although non-negative, arbitrarily small by choosing an accordingly large value for x . Moreover, that risk value again satisfies theorem 4. When trying to prove this fact, one can proceed as before for the rules without quantifiers. The crucial point is recognizing that the risk value of a game state where a proposition is bound by a quantifier can be calculated as follows:</p>
         <p>Γ, ∀ xP ( x ) | ∆ L = inf Γ, P ( d ) | ∆ L d Γ, ∃ xP ( x ) | ∆ L = sup Γ, P ( d ) | ∆ L d Γ | ∀ xP ( x ) , ∆ L = sup Γ | P ( d ) , ∆ L d Γ | ∃ xP ( x ) , ∆ L = inf Γ | P ( d ) , ∆ L d</p>
         <p>As an example, the first equality can be argued as follows: Let c denote the risk value of the game state [ Γ, ∀ xP ( x ) | ∆ ] . I am able to choose any appropriately valued constant d , such that the risk value of the game state [ Γ, P ( d ) | ∆ ] approaches inf d Γ, P ( d ) | ∆ L arbitrarily closely. Then, if c &gt; inf d Γ, P ( x ) | ∆ L I can choose a constant d such that Γ, P ( d ) | ∆ L lies between c and inf d Γ, P ( d ) | ∆ L . But then you have no strategy to ensure that the game ends in a finale state where the risk value exceeds c − if is smaller than c − Γ, P ( d ) | ∆ L which is a direct contradiction to the definition of a risk value. On the other hand, if c &lt; inf d Γ, P ( d ) | ∆ L and &lt; inf d Γ, P ( d ) | ∆ L − c then I will not be able to find a value d such that Γ, P ( d ) | ∆ L does not exceed c + because in that case Γ, P ( d ) | ∆ L would have to be smaller than inf d Γ, P ( d ) | ∆ L . So, since both cases c &gt; inf d Γ, P ( d ) | ∆ L and c &lt; inf d Γ, P ( d ) | ∆ L yield contradictions, the only possibility left is c = inf d Γ, P ( d ) | ∆ L . (For the other equalities we can reason completely analogously.) Assume now, that you have asserted the proposition ∀ xP ( x ) . Then I have to call on you to assert P ( d ) , where I choose d such that v ∗ ( P ( d )) &lt; inf d v ∗ ( P ( d )) − n where n denotes the  number of quantifiers in all propositions of the given game state. The term “ 1 ” is necessary n because otherwise, if there occur more than one quantifiers in the given game state, the risk values of the final game state and the initial game state can differ by more than . The fact that we do not only have to know the suprema (resp. infima) for all propositions containing a variable which is bound by a quantifier, but also which values to choose in order to approach that suprema and infima arbitrarily closely, is another facet of the first problem of omniscient players.</p>
         <fig id="F3.7">
            <caption>
               <p>Figure 3.7: Game Tree for (( a → b ) → b ) ∧ (( b → a ) → a )</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>“You keep changin’ the rules and I can’t play the game. I can’t take it much longer. I think I might go insane.” Michael and Janet Jackson, Scream</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>4</p>
      </sec>
      <sec>
         <title>Extending Giles’s Game to Other Logics</title>
         <p>The relation between Giles’s Game as presented in the previous chapter and Lukasiewicz Logic established by Theorem 4 is, in other words, that my risk value for a proposition and the truth value assigned to that proposition in Lukasiewicz Logic under a corresponding interpretation always add up to one. (My risk value is defined as the expected amount of money I will lose when stating that proposition in the game, assuming both players playing rationally) At this point the question arises if it is possible to modify the game rules to characterize other logics, e.g. Gödel Logic G and Product Logic Π . Here we will answer this question only partly positive: It is possible to give game rules for both logics such that if a proposition is valid in the respective logic, then I have a winning strategy for that game and there exists a winning strategy for you otherwise. First we will modify the rules for evaluating atomic game states reflecting the evaluation functions for G an Π .  Let us assume that after playing Giles’s Game we have finally reached an atomic game state G = [ p 1 , . . . , p m | q 1 , . . . , q n ] . Moreover, let p i and q i denote the risk values associated with the atomic propositions p i and q i . When evaluating the atomic game state G , the expected account of money that I have to pay you, known as the risk value of my tenet, is calculated as n q 1 , . . . , q n L = q i i = 1 (see section 3.4.1). 1 This formula corresponds to the betting scheme of Giles’s Game where for each atomic proposition an experiment is conducted and for every negative outcome of such an experiment the asserting player has to pay ¿ 1 to his opponent. My expected gain can then be calculated as p 1 , . . . , p m L − q 1 , . . . , q n L . Let us consider another version of the game where you have to pay me ¿ 1 unless all trials of experiments associated with propositions asserted by you test positively, and I have to pay you ¿ 1 unless all trials of experiments associated with propositions asserted by me test positively. In this case the risk value of a players tenet [ q 1 , . . . , q n ] is calculated as</p>
         <p>4.1 Different Ways of Combining Bets 4.1.1 Summing Up Bets</p>
         <p>4.1.2 Joint Bets</p>
         <p>n q 1 , . . . , q n Π = 1 − ( 1 − q i ) i = 1 assuming that all experiments are independent of each other. My expected gain in the atomic game state [ p 1 , . . . , p m | q 1 , . . . , q n ] can then be calculated as m n p 1 , . . . , p m Π − q 1 , . . . , q n Π = 1 − ( 1 − p i ) − ( 1 − ( 1 − q i )) i = 1 i = 1 n m = ( 1 − q i ) − ( 1 − p i ) i = 1 i = 1 1 Since in this section we introduce other betting schemes, we use · L instead of · in order to be able to distinguish the risk values for different betting schemes.</p>
         <p>We will use joint bets below when identifying dialogue game rules for Product Logic. To indicate the soundness of this approach for Product Logic Π consider the proposition A = q 1 &amp; q 2 &amp; . . . &amp; q m with q i being atomic. If we play the according game starting in [ | (( p 1 &amp; p 2 ) &amp; . . . ) &amp; p n ] 2 , we will finally end up in the atomic game state [ | p 1 , p 2 , . . . , p n ] assuming you playing rationally. Now, according to the betting scheme presented here, my expected gain is 1 − n i = 1 ( 1 − q i ) = 1 − i m = 1 π ( E q i ) ¿ where π ( E q i ) is the subjective probability of the experiment E q i (see definition 13). If we want to associate a truth value of a tenet analogously to section 3.4.1 as one minus its risk value, we arrive at the truth value n i = 1 pi ( E q i ) for the tenet [ q 1 , . . . , q n ] .  Consider yet another betting scheme: Each player has to select one of his opponent’s atomic propositions. The according experiment is conducted and if it fails, the player asserting the proposition has to pay ¿ 1 to his opponent. We will use this betting scheme below for identifying dialogue game rules for Gödel Logic. Assuming both players playing rational, as in section 3.4.1, they will select an experiment which has the lowest probability value (and, thus a high risk value), hence the risk value of a tenet [ q 1 , . . . , q m ] is calculated as:</p>
         <p>4.1.3 Selecting Representative Bets</p>
         <p>q 1 , . . . , q m G = min ( 1 − q i ) 1 i m My expected gain in the atomic game state [ p 1 , . . . , p m | q 1 , . . . , q n ] can then be calculated as: p 1 , . . . , p m G − q 1 , . . . , q n G = 1 − min ( 1 − p i ) − ( 1 − min ( 1 − q i )) 1 i m 1 i m = min ( 1 − q i ) − min ( 1 − p i ) 1 i m 1 i m</p>
         <p>Note that this definition corresponds to the evaluation of conjunctions of atomic formulas (analogously to the case for Π , above) according to the semantics of Gödel Logic G .  If we are not interested in finding out the exact value of my gain or loss but only in the winner of the game, we can formulate the following winning condition W for ∈ { L , Π, G }</p>
         <p>4.1.4 Winning conditions</p>
         <p>2 Note that &amp; is associative, so we can put the parentheses any way we want.</p>
         <p>for the atomic game state [ q 1 , . . . , q n | p 1 , . . . , p m ] : W [ q 1 , . . . , q n | p 1 , . . . , p m ] ⇐⇒ p 1 , . . . , p m q 1 , . . . , q n For Π and G this definition is equivalent to: n m W Π [ q 1 , . . . , q n | p 1 , . . . , p m ] ⇐⇒ ( 1 − q i ) ( 1 − p i ) i = 1 i = 1 W G [ q 1 , . . . , q n | p 1 , . . . , p m ] ⇐⇒ min ( 1 − q i ) min ( 1 − p i ) 1 i n 1 i m 4.2 Rules for Decomposing Complex Assertions</p>
         <p>As mentioned above we will use joint bets for defining a dialogue game suitable for Π and selecting representative bets for G . However, these schemes together with the game rules from Giles’s Game for decomposing compound propositions do not suffice for characterizing these logics. Consider for example the formula ¬ p → q and an interpretation v with v ( p ) = 0 as well as v ( q ) &lt; 1 . Evaluating the formula in the fuzzy logic based on the t-norm ∗ gives us:  The formula is neither valid in Π nor in G , hence I should have no winning strategy for a game starting in [ | ( p → ⊥ ) → q ] . If you do not attack my implication in the first place, I have already won. Otherwise we get to the game state [ p → ⊥ | q ] and if I attack your implication we end up in [ ⊥ | q, p ] . Evaluating this game state using joint bets as well as selecting representative bets gives us the same result: I win because the respective winning conditions are fulfilled in both cases. (Note that using the winning conditions for Lukasiewicz Logic you would win the game if we reached this final game state. On the other hand, if I did not attack your implication, you would win the game as well.) It is no coincidence that this counter-example involves the truth value 0 , respectively the proposition ⊥ . The problem this truth value is that if one player asserts an atomic proposition with truth value 0 , the risk value for his tenet is 1 , regardless of the other propositions he asserts. As seen in the example, as soon as I can force you to assert ⊥ at any point in the game, I win the game. This is, because, even if my tenet has the truth value 0 , I will not lose any money in the long run. I can always restrict my loss to ¿ 1 or lower (according to the principle of limited liability), while each run I get ¿ 1 from you. If we exclude the symbol ⊥ from our language and evaluate formulas using joint bets, but over the left-open interval ( 0, 1 ] instead of [ 0, 1 ] , we arrive at a logic known as Cancellative Hoop Logic ( CHL ), [EGHM03]. Note that eliminating 0 and, thus, ⊥ significantly reduces the expressiveness of the language since negation is defined in terms of ⊥ . There are several ways for introducing new rules in order to make the game adequate for Π and G . We will first concentrate on the rules given in [Fer09], but we will also describe alternative formulations. In order to remedy the situation, the approach presented in [Fer09] is to introduce an additional flag ¶ . The flag ¶ being raised announces that I will only be declared winner of the game if the evaluation of the final elementary state yields a strictly positive (and not just non-negative) expected gain for me. In other words: For me, in order to win the game, it does no longer suffice not to lose any money, instead I have to gain money in the long run. Formally, this is accomplished by using the winning condition W ∗ &lt; if the flag is raised: We replace rule 2 by the following two rules: (Note that the game rules are no longer symmetric for both players.)</p>
         <p>v ∗ ( ¬ p → q ) = ( v ∗ ( p → ⊥ ) ⇒ ∗ v ( q )) = (( v ∗ ( p ) ⇒ ∗ 0 ) ⇒ ∗ v ( q )) = ( 1 ⇒ ∗ v ( q ) &lt; 1 )</p>
         <p>W &lt; [ q 1 , . . . , q m | p 1 , . . . , p n ] ⇐⇒ q 1 , . . . , q n &lt; p 1 , . . . , p m</p>
         <p>Rule 1a. If I assert A → B then, whenever you choose to attack this statement by asserting A , I have the following choice: either I assert B in reply or I challenge your attack on A → B by replacing the current game with a new one in which you assert A and I assert B . Rule 1b. If you assert A → B then, whenever I choose to attack this statement by asserting A , you have the following choice: either you assert B in reply or you challenge my attack on A → B by replacing the current game with a new one in which the flag is raised and I assert A while you assert B .</p>
         <p>Admittedly, these rules appear rather ad hoc at this point. What we can observe easily is that now our counterexample ¬ p → q with v ( p ) = 0 from above is no problem any longer. When we get to the game state [ p → ⊥ | q ] and I attack your implication, you may, by rule 1b , challenge my attack by replacing the current game with a new one starting in [ ⊥ | p ] in which the flag ¶ is raised. If you do so, we both won’t gain any money, but because of the flag being raised now I am not declared the winner of the game, but you are. This is of course no proof that these rules are sufficient in order to characterize G and Π ; this fact has to be proved separately (and will be done). A motivation for the new rules can be obtained when comparing the rules of the dialogue game and the corresponding rules of  the relational hypersequent calculus rH as defined in Definition 8. As for Lukasiewicz Logic in Section 3.4 we can informally read the following two rules as game rules: In rule ( → , , l ) the two branches do only differ by the relational sequent Γ, B A, ∆ on the one side and B &lt; A on the other one. In the corresponding game rule 1b you have the choice between adding the assertion B to your tenet (and me adding A to mine) leaving the flag ¶ as it is or to replace the current game with a new one where the flag is raised, you asserting only B and me asserting only A . For rule ( → , , r ) we have a similar situation with the difference that now both relational sequents Γ, A B, ∆ and A B are on the same branch (while by the corresponding game rule now I can choose between attacking your assertion and starting a new game). Also note, that now we have A B and by the game rule, in the new game the flag ¶ is not raised either. An alternative formulation of the rules 1a and 1b is the following one:</p>
         <p>G | Γ ∆ G | Γ, A B, ∆ | A B ( → , , r ) G | Γ A → B, ∆ G | Γ ∆ | Γ, B A, ∆ G | Γ ∆ | B&lt;A ( → , , l ) G | Γ, A → B ∆</p>
         <p>Rule 1’. If I have a winning strategy for winning the game starting in the state [ A | B ] , then I am not allowed to attack your assertion of A → B . (And vice versa, i.e., for the roles of you and me switched.)</p>
         <p>According to rule 1b , if I attack your assertion of A → B , then you can challenge that attack and by replacing the current game by a new one starting in [ B | A ] (with the flag ¶ being raised). Consequently, if I believe the risk value of A to be higher than the risk value of B (and if I play rationally), I will not that attack. This in essence means that I have a winning strategy for a game starting in [ A | B ] . Now, rule 1’ explicitly forbids me to perform this in (and only in) that case. As we see, when employing rule 1’ instead of 1a and 1b , both players may have fewer choices to make in such situations but the existence of winning strategies is not affected. Although rule 1’ may better fit Giles’s original format than rules 1a and 1b , there is a certain drawback: In Giles’s original game as well as in its variant using rules 1a and 1b it is possible to play the game without reasoning about winning strategies. If we add rule 1’ , a players is enforced to do so in order to know if he is allowed to attack an assertion of the form A → B made by his opponent.  We show that Giles’s Game augmented with rules 1a and 1b is indeed suitable for Π and G when employing the according winning conditions. One way to do so is to formalize strategies for both players of the game and then formally prove the equivalence between these strategies and the according rules of the hypersequent calculus rH defined in section 2.6. In [Fer09], for example, the rules 1a and 1b are derived from the corresponding rules of the hypersequent calculus rH . Here we will go another way: We will directly prove that the game based on the new rules characterizes G and Π similarly to proving that Giles’s original game characterizes L in section 3.4. The main difference to the proof presented there is that for Lukasiewicz Logic we had the result that the risk value of the game starting with me asserting one proposition directly corresponds to the truth value of that proposition evaluated in L . (see theorem 4) For the new game we don’t have this close correspondence any longer. Instead we will see that I will win the game (i.e. I have a strategy to enforce a final game state which fulfills the winning condition for G or Π ) if and only if the proposition the game started with evaluates to 1 in G , respectively Π . In contrast to section 3.4 we are not really interested in the concrete risk value of a game state. What we need to know is only if I have a strategy to enforce a game state where I win the game. 3 First, we extend the definition of the winning conditions W [ Γ | ∆ ] for ∈ { &lt;, } from atomic game states to arbitrary game states.</p>
         <p>4.3 Adequateness of the Rules</p>
         <p>W [ Γ, A ∧ B | ∆ ] ⇐⇒ W [ Γ, A | ∆ ] or W [ Γ, B | ∆ ] W [ Γ, A ∨ B | ∆ ] ⇐⇒ W [ Γ, A | ∆ ] and W [ Γ, B | ∆ ] W [ Γ | A ∧ B, ∆ ] ⇐⇒ W [ Γ | A, ∆ ] and W [ Γ | B, ∆ ] W [ Γ | A ∨ B, ∆ ] ⇐⇒ W [ Γ | A, ∆ ] or W [ Γ | B, ∆ ]</p>
         <p>These definitions directly correspond to Rules 5 and 4: If, according to the corresponding rule, I have a choice to make, I then I have a strategy to win the game if and only if I have such a strategy in one of the succeeding game states. On the other hand, if you have a choice  to make, I will only win the game, if for all succeeding game states I have a wining strategy. If you assert an implication, then I have a winning strategy if I can either win the game by granting that implication or by attacking it. In the latter case you may choose to challenge my attack. Thus, here I need a winning strategy if you choose to do so as well as if you choose not to challenge my attack. (Note that if you challenge my attack the flag is raised in the new game which is reflected by the winning condition W &lt; being used here):</p>
         <p>3 We could, of course, formalize the risk value of a game state analogously to section 3.4. The problem with this approach is that a risk value of 0 does not necessarily mean that I have won the game; this depends on the flag having been raised in the final game state where the game ended. If we just calculated the risk value of a game state, this information would be lost.</p>
         <p>W [ Γ, A → B | ∆ ] ⇐⇒ W [ Γ | ∆ ] or both W [ Γ, B | A, ∆ ] and W &lt; [ B | A ] For an implication asserted by me we get analogously: W [ Γ | A → B, ∆ ] ⇐⇒ both W [ Γ | ∆ ] and either W [ Γ, A | B, ∆ ] or W [ A | B ]</p>
         <p>For atomic game states we have seen in Section 4.1 how to evaluate the winning condition (with ∈ { G , Π } and π as the subjective probability of an experiment):</p>
         <p>W G [ p 1 , p 2 , . . . , p m | q 1 , q 2 , . . . , q n ] ⇐⇒ min π ( E p i ) min π ( E q j ) 1 i m 1 j n m n W Π [ p 1 , p 2 , . . . , p m | q 1 , q 2 , . . . , q n ] ⇐⇒ π ( E p i ) π ( E q j ) i = 1 j = 1 Next, let us extend the evaluation functions for G and Π at first to multisets of formulas and finally to game states: Definition 18. (a) For a proposition A , an interpretation v , and ∈ { G , Π } we define the function A := 1 − v ( A ) where ∈ { G , Π } and v is the extension of v to arbitrary propositions as defined in Definition 3, (b) for a multiset Γ of propositions we define the functions Γ G := 1 − min v G ( G ) and Γ Π := 1 − v Π ( G ) G ∈ Γ G ∈ Γ G Π (and = = 0 ) (c) for a game state [ Γ | ∆ ] and ∈ { G , Π } we define the function Γ | ∆ := Γ − ∆ . G Π The values Γ | ∆ and Γ | ∆ can be calculated as: Γ | ∆ G = min v G ( G ) − min v G ( D ) and Γ | ∆ Π = v Π ( G ) − v Π ( D ) G ∈ Γ D ∈ ∆ G ∈ Γ D ∈ ∆</p>
         <p>The relation between these definitions and the winning condition derived from the game rules is expressed by the following lemma:</p>
         <p>Lemma 5. Let [ Γ | ∆ ] be an arbitrary game state. For each atomic proposition a let v ( a ) = π ( E a ) , i.e. the truth value assigned to a is equal to the subjective probability assigned to a . Then the following relation holds for ∈ { G , Π } and ∈ { , &lt; } : Γ | ∆ 0 ⇐⇒ W [ Γ | ∆ ]</p>
         <p>Proof. As in section 3.4.1 we use induction by the number of connectives occurring in all propositions in the game state. If there are zero connectives, there are only atomic propositions and it is easy to see by the definition of the winning conditions that Lemma 5 holds. In this case, we can easily see that the extended (inverted) evaluation function and my risk value for the game state coincide:</p>
         <p>G p 1 , . . . , p m | q 1 , . . . , q n 0 ⇐⇒ min v ( p i ) − min v ( q j ) 0 1 i m 1 j n ⇐⇒ min p ( p i ) − min p ( q j ) 0 1 i m 1 j n ⇐⇒ W G [ p 1 , . . . , p m | q 1 , . . . , q n ]</p>
         <p>For Π this is shown goes completely analogously. Assume that Lemma 5 holds if there are at most n connectives occurring in a game state. We have to check each of the six formulas for defining W on arbitrary game states given above. We only show the case where you assert a conjunction and the two cases where one player asserts an implication. Let us assume that you assert a conjunction of two propositions. In this case we have to prove the following</p>
         <p>Γ, A ∧ B | ∆ 0 ⇐⇒ W [ Γ, A | ∆ ] or W [ Γ, B | ∆ ]</p>
         <p>For Π we have: Π Γ, A ∧ B | ∆ 0 ⇐⇒ v Π ( A ∧ B ) · v Π ( G ) − v Π ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ min v Π ( A ) , v Π ( B ) · v Π ( G ) − v Π ( D ) 0 as v Π ( G ) 0 G ∈ Γ D ∈ ∆ G ∈ Γ ⇐⇒ min v Π ( A ) · v Π ( G ) − v Π ( D ) , v Π ( B ) · v Π ( G ) − v Π ( D ) 0 G ∈ Γ D ∈ ∆ G ∈ Γ D ∈ ∆ Π Π ⇐⇒ min Γ, A | ∆ , Γ, B | ∆ 0 Π Π ⇐⇒ Γ, A | ∆ 0 or Γ, B | ∆ 0 and for G we have analogously: G Γ, A ∧ B | ∆ 0 ⇐⇒ min v G ( A ∧ B ) , min v G ( G ) − min v G ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ min min v G ( A ) , v G ( B ) , min v G ( G ) − min v G ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ min min v G ( G ) , min v G ( G ) − min v G ( D ) 0 G ∈ Γ,A G ∈ Γ,B D ∈ ∆ ⇐⇒ min min v G ( G ) − min v G ( D ) , min v G ( G ) − min v G ( D ) 0 G ∈ Γ,A D ∈ ∆ G ∈ Γ,B D ∈ ∆ G G ⇐⇒ min Γ, A | ∆ , Γ, B | ∆ 0 G G ⇐⇒ Γ, A | ∆ 0 or Γ, B | ∆ 0 By applying the induction hypothesis Γ | ∆ 0 ⇐⇒ W [ Γ | ∆ ] (for ∈ { , &lt; } ) to the game states [ Γ, A | ∆ ] and [ Γ, B | ∆ ] we can conclude that Γ, A ∧ B | ∆ 0 ⇐⇒ W [ Γ, A ∧ B | ∆ ]</p>
         <p>The three other cases dealing with conjunction and disjunction go completely analogously, but things get interesting as we get to the new rules for implication: If I assert an implication we have to prove:</p>
         <p>(a) Let us assume that v ( A ) v ( B ) . Then the equality</p>
         <p>holds: Γ | A → B, ∆ Π = v Π ( G ) − v Π ( A → B ) · v Π ( D ) G ∈ Γ D ∈ ∆ = v Π ( G ) − 1 · v Π ( D ) = Γ | ∆ Π G ∈ Γ D ∈ ∆ Γ | A → B, ∆ G = min v G ( G ) − min ( v G ( A → B ) , min v G ( D )) G ∈ Γ D ∈ ∆ = min v G ( G ) − min ( 1, min v G ( D )) = Γ | ∆ G G ∈ Γ D ∈ ∆ and A | B 0 because of A | B = v ( A ) − v ( B ) 0 These two facts finally help us to see that Γ | A → B, ∆ 0 ⇐⇒ Γ | ∆ 0 and either Γ, A | B, ∆ 0 or A | B 0 and applying the induction hypothesis to the game states [ Γ | ∆ ] , [ Γ, A | B, ∆ ] and [ A | B ] gives the desired result. (b) Now let us assume that v Π ( A ) &gt; v Π ( B ) . In this case we cannot prove Equivalence 4.1 directly, we have to prove both “directions” separately, but before let us show that the equivalence</p>
         <p>holds: Γ | A → B, ∆ Π 0 ⇐⇒ v Π ( G ) − v Π ( B ) · v Π ( D ) 0 v Π ( A ) G ∈ Γ D ∈ ∆ ⇐⇒ v Π ( A ) · v Π ( G ) − v Π ( B ) · v Π ( D ) 0 G ∈ Γ D ∈ ∆ Π ⇐⇒ Γ, A | B, ∆ 0</p>
         <p>Γ | A → B, ∆ G 0 ⇐⇒ min v G ( G ) − min v G ( B ) , min v G ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ min v G ( G ) min v G ( B ) , min v G ( D ) G ∈ Γ D ∈ ∆ ⇐⇒ min v G ( A ) , min v G ( G ) min v G ( B ) , min v G ( D ) G ∈ Γ D ∈ ∆ G ⇐⇒ Γ, A | B, ∆ 0 We will use this for proving both directions of Equivalence 4.1: Γ | A → B, ∆ 0 ⇒ W [ Γ | ∆ ] and either W [ Γ, A | B, ∆ ] or W [ A | B ]) : In order to see that the left hand side of the conjunction evaluates to true in this case, we have to show that Γ | A → B, ∆ 0 ⇒ Γ | ∆ 0 holds: Γ | A → B, ∆ Π = v Π ( G ) − v Π ( A → B ) · v Π ( D ) G ∈ Γ D ∈ ∆ v Π ( G ) − 1 · v Π ( D ) = Γ | ∆ Π G ∈ Γ D ∈ ∆ Γ | A → B, ∆ G = min v G ( G ) − min v G ( A → B ) , min v G ( D ) G ∈ Γ D ∈ ∆ min v G ( G ) − min 1, min v G ( D ) = Γ | ∆ G G ∈ Γ D ∈ ∆ Together with Equivalence 4.3 we see that Γ | A → B, ∆ 0 ⇒ Γ | ∆ 0 and either Γ, A | B, ∆ 0 or A | B 0 Again, applying the induction hypothesis to the game states [ Γ | ∆ ] , [ Γ, A | B, ∆ ] and [ A | B ] gives us the desired result. Γ | A → B, ∆ 0 ⇐ W [ Γ | ∆ ] and either W [ Γ, A | B, ∆ ] or W [ A | B ] : Assume that the premise is true. Then also W ∗ [ Γ | ∆ ] holds. By applying the induction hypothesis we can conclude that Γ | ∆ 0 holds and by Equivalence 4.3 we can conclude that the conclusion Γ | A → B, ∆ holds. The last (interesting) case arises, if you assert an implication. We then have to prove:</p>
         <p>Again, we have to distinguish between the case where v ( A ) v ( B ) holds and the one where</p>
         <p>the inequation does not hold: (a) Let us assume that v ( A ) v ( B ) . We see that the equality</p>
         <p>as follows: Γ, A → B | ∆ Π = v Π ( A → B ) · v Π ( G ) − v Π ( D ) G ∈ Γ D ∈ ∆ = 1 · v Π ( G ) − v Π ( D ) = Γ | ∆ Π G ∈ Γ D ∈ ∆ Γ, A → B | ∆ G = min ( v G ( A → B ) , min v G ( G )) − min v G ( D ) G ∈ Γ D ∈ ∆ = min ( 1, min v G ( G )) − min v G ( D ) = Γ | ∆ G . G ∈ Γ D ∈ ∆ Moreover, we see that B | A 0 because of B | A = v ( B ) − v ( A ) 0 . These two facts imply Γ, A → B | ∆ 0 ⇐⇒ Γ | ∆ 0 or both Γ, B | A, ∆ 0 and B | A &lt; 0. Applying the induction hypothesis to the game states [ Γ | ∆ ] , [ Γ, B | A, ∆ ] , and [ B | A ] gives us the desired result. (b) Now let us assume that v Π ( A ) &gt; v Π ( B ) . As before, we prove both directions separately. And, again, it is useful to observe that</p>
         <p>The proof of this statement goes completely analogously to the proof of the corresponding statement in the case where I assert the implication. Γ, A → B | ∆ 0 ⇒ W [ Γ | ∆ ] or both W [ Γ, B | A, ∆ ] and W &lt; [ B | A ] : Taking into account that B | A &lt; 0 , we see from Observation 4.6 that the implication Γ, A → B | ∆ 0 ⇒ Γ | ∆ or both Γ, B | A, ∆ and W &lt; [ B | A ] holds. Applying the induction hypothesis to the game states [ Γ | ∆ ] , [ Γ, B | A, ∆ ] and [ B | A ] gives us the desired result. Γ, A → B | ∆ 0 ⇐ W [ Γ | ∆ ] or both W [ Γ, B | A, ∆ ] and W &lt; [ B | A ] :</p>
         <p>By applying the induction hypothesis to the game states [ Γ | ∆ ] , [ Γ, B | A, ∆ ] and [ B | A ] we see that we need to prove the following: Γ, A → B | ∆ 0 ⇐ Γ | ∆ 0 ∨ ( Γ, B | A, ∆ 0 ∧ B | A &lt; 0 ) We see that Γ, B | A, ∆ 0 ⇒ Γ | ∆ 0 holds because of: Γ | ∆ Π = v Π ( G ) − v Π ( D ) G ∈ Γ D ∈ ∆ v Π ( A → B ) · v Π ( G ) − v Π ( D ) = Γ, A → B | ∆ Π G ∈ Γ D ∈ ∆ Γ | ∆ G = min v G ( G ) − min v G ( D ) G ∈ Γ D ∈ ∆ min v G ( A → B ) , v Π ( G ) − v Π ( D ) = Γ, A → B | ∆ G . G ∈ Γ D ∈ ∆ Together with Observation 4.6 we can conclude that the implication holds. Lemma 5 finally implies that a formula is valid in G or Π if I have a winning strategy for the according game: Theorem 5. Let A be an arbitrary proposition and v an interpretation. Assume that for each atomic proposition a occurring in A that v ( a ) = π ( E a ) (as in Lemma 5). Then I have a strategy to win the game (for G or Π ) if and only if v ( A ) = 1 the truth value 1 is assigned to A by the extension of v to arbitrary propositions for the respective logic (as in Definition 3), i.e. : W [ | A ] ⇐⇒ v ( A ) = 1 for ∈ { G , Π }</p>
         <p>Proof. By Lemma 5 and the definition of the winning conditions I have a strategy to win the game starting in [ | A ] if and only if W [ | A ] holds:  Note that this version of Giles’s Game is still adequate for Lukasiewicz Logic L in the same sense as it is adequate for Π and G . The proof of this goes completely analogously to the proof of the adequateness of the new rules for these two logics. Instead of using the rules 1a and 1b , one can identify adequate rules for G and Π as follows: if one player attacks a formula of the form A → B and that attack is challenged by the other player, the game is not replaced by a new one, where one player asserts A and the other one B .Instead a new game is started where one player asserts A and the other one ⊥ . This sometimes simplifies the game. On the other hand, the close correspondence between the game rules and the hypersequent calculus rH is lost this way.</p>
         <p>∗ W [ | A ] ⇐⇒ | A 0 ⇐⇒ 1 − v ( A ) 0 ⇐⇒ 1 v ( A ) ⇐⇒ 1 = v ( A ) .</p>
         <p>4.4 Alternative Rules</p>
         <p>Rule 1a’. If I assert A → B then, whenever you choose to attack this statement by asserting A , I have the following choice: either I assert B in reply or I challenge your attack on A → B by replacing the current game with a new one in which you assert A and I assert ⊥ and where the flag is not raised. Rule 1b’. If you assert A → B then, whenever I choose to attack this statement by asserting A , you have the following choice: either you assert B in reply or you challenge my attack on A → B by replacing the current game with a new one in which the flag is raised and I assert A while you assert ⊥ .</p>
         <p>Informally these rules ensure that an implication of the form A → B may be attacked if and only if A does not evaluate to 0 in the respective logic. In order to prove that Rules 1a and 1b can be replaced by Rules 1a’ and 1b’ , we proceed analogously to Lemma 5. Note that, when using Rules Rules 1a’ and 1b’ , whenever the flag ¶ is raised, only such game states can be reached in a dialogue, in which your tenet contains the atomic proposition ⊥ . The reason for this is as follows: By rule 1b’ , the formula ⊥ is added to your tenet, when the flag ¶ gets raised. The only way ⊥ can disappear from your tenet is by rule 1a’ if I challenge your attack. In this case the flag ¶ is unraised. Therefore, in the following we will only regard winning conditions, which can possibly be reached in a dialogue. The definition of the winning condition has to be changed in the two cases where the attacked formula is an implication:</p>
         <p>W [ Γ | A → B, ∆ ] ⇐⇒ W [ Γ | ∆ ] and either W [ Γ, A | B, ∆ ] or W [ A | ⊥ ] W [ Γ, A → B | ∆ ] ⇐⇒ W [ Γ | ∆ ] or both W [ Γ, B | A, ∆ ] and W &lt; [ ⊥ | A ] For rule 1a’ we have to prove that Γ | A → B, ∆ 0 ⇐⇒ W ∗ [ Γ | ∆ ] and either W ∗ [ Γ, A | B, ∆ ] or W [ A | ⊥ ]</p>
         <p>i.e., by the induction hypothesis, that Γ | A → B, ∆ 0 ⇐⇒ Γ | ∆ 0 and either Γ, A | B, ∆ 0 or A | ⊥ 0. (4.7) As before, we have to distinguish two cases: (a) Assume that v ( A ) v ( B ) . Equality 4.2, Γ | A → B, ∆ = Γ | ∆ , still holds. We prove both directions of Equivalence 4.7 separately: The direction “ ⇐ ” does clearly hold because if the conjunction holds, then the left hand side must also hold, and by Equality 4.2 the left hand side of the implication then holds as well. We still have to prove the other direction “ ⇒ ”: if v ( A ) = 0 holds, then also A | ⊥ 0 holds. Again, by Equality 4.2 the implication is clearly fulfilled. If v ( A ) &gt; 0 then the implication Γ | A → B, ∆ 0 implies Γ, A | B, ∆ 0 (4.8) holds for Π because of the following two facts: Γ | A → B, ∆ Π = Γ | ∆ Π = v Π ( G ) − v Π ( D ) G ∈ Γ D ∈ ∆ v Π ( G ) − v Π ( B ) · v Π ( D ) , v Π ( A ) G ∈ Γ D ∈ ∆ and, building on that: Γ | A → B, ∆ Π 0 ⇒ v Π ( G ) − v Π ( B ) · v Π ( D ) 0 v Π ( A ) G ∈ Γ D ∈ ∆ ⇐⇒ v Π ( A ) · v Π ( G ) − v Π ( B ) · v Π ( D ) 0 G ∈ Γ D ∈ ∆ Π ⇐⇒ Γ, A | B, ∆ 0. For G we have to take into account at this point that some game states are not reachable in a dialogue as mentioned above. Consider for example four atomic variables a, b, g, d with the valuation v ( a ) = 0.5, v ( b ) = 0.5, v ( g ) = 0.8, v ( d ) = 0.9 . The extended evaluation function for G for the game state [ g | a → b, d ] where the flag ¶ is raised G then gives us g | a → b, d = 0.1 − 0.2 = − 0.1 &lt; 0 . On the other hand, the inequation</p>
         <p>G g, a | b, d = 0 &lt; 0 is not fulfilled and, consequently, Implication 4.8 does not hold. Note that the game states [ g | a → b, d ] and [ g, a | b, d ] , both with the flag ¶ being raised, are such game states which can not be reached. For proving Implication 4.8 we therefore assume that, whenever the flag ¶ is raised G (which corresponds to requiring Γ | A → B, ∆ to be strictly less than 0 ), then min G ∈ Γ v G ( G ) = 0 holds. Γ | A → B, ∆ G &lt; 0 ⇐⇒ min v G ( G ) − min v G ( A → B ) , min v G ( D ) &lt;0 G ∈ Γ D ∈ ∆ ⇐⇒ − min v G ( D ) &lt; 0 D ∈ ∆ (as 0 &lt; v G ( B ) ) ⇒ − min v G ( B ) , min v G ( D ) &lt;0 D ∈ ∆ ⇐⇒ min v G ( A ) , min v G ( G ) − min v G ( B ) , min v G ( D ) &lt;0 G ∈ Γ D ∈ ∆ G ⇐⇒ Γ, A | B, ∆ &lt;0 Γ | A → B, ∆ G 0 ⇐⇒ min v G ( G ) − min v G ( A → B ) , min v G ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ min v G ( G ) − min v G ( D ) 0 G ∈ Γ D ∈ ∆ (as 0 &lt; v G ( A ) v G ( B ) ) ⇒ min v G ( A ) , min v G ( G ) − min v G ( B ) , min v G ( D ) 0 G ∈ Γ D ∈ ∆ G ⇐⇒ Γ, A | B, ∆ 0 (b) On the other hand, if v ( A ) &gt; v ( B ) we can proceed exactly as we did in the proof of Lemma 5 for rule 1a . Next, for rule 1b’ we analogously have to prove that Γ, A → B | ∆ 0 ⇐⇒ W [ Γ | ∆ ] or both W [ Γ, B | A, ∆ ] and W &lt; [ ⊥ | A ] i.e., by the induction hypothesis, that</p>
         <p>As before, we have to distinguish two cases:</p>
         <p>(a) Let us assume that v ( A ) v ( B ) . Then Equality 4.5, Γ, A → B | ∆ = Γ | ∆ , still holds. Let us prove both directions of the equivalence separately: The direction “ ⇒ ” does clearly hold because, if the left hand side of the implication holds, then by the equality mentioned the left hand side of the disjunction also holds and, thus, the whole right hand side of the implication holds as well. We still have to prove the other direction “ ⇐ ”: If v ( A ) = 0 , the term ⊥ | A &lt;0 will be false and, again, by the equivalence the implication is clearly fulfilled. If v ( A ) &gt; 0 ,then ⊥ | A holds. We prove that Γ, B | A, ∆ 0 ⇒ Γ, A → B | ∆ 0 holds as follows: Γ, B | A, ∆ Π 0 ⇐⇒ v Π ( B ) · v Π ( G ) − v Π ( A ) · v Π ( D ) 0 G ∈ Γ D ∈ ∆ ⇐⇒ v Π ( B ) · v Π ( G ) − v Π ( D ) 0 v Π ( A ) G ∈ Γ D ∈ ∆ ⇒ 1 · v Π ( G ) − v Π ( D ) 0 G ∈ Γ D ∈ ∆ Π ⇐⇒ Γ | ∆ 0 Π ⇐⇒ Γ, A → B | ∆ 0 Γ, B | A, ∆ G 0 ⇐⇒ min v G ( B ) , min v G ( G ) − min v G ( A ) , min v G ( D ) 0 G ∈ Γ D ∈ ∆ ⇒ min v G ( G ) − min v G ( D ) 0 G ∈ Γ D ∈ ∆ G ⇐⇒ Γ | ∆ 0 G ⇐⇒ Γ, A → B | ∆ 0 Together with the equality mentioned before we can now establish the direction “ ⇐ ” of Equivalence 4.9. (b) On the other hand, if v ( A ) &gt; v ( B ) we can proceed exactly as we did in the proof before for rule 1b when taking into account that W &lt; [ B | A ] being true implies that also W &lt; [ ⊥ | A ] holds. Again, note that this version of Giles’s Game is still adequate for Lukasiewicz Logic L . The proof is completely analogous to the one for Π and G .</p>
         <p>4.5 Rules for Other Connectives</p>
         <p>In contrast to Lukasiewicz Logic, where we were able to derive a game rule for strong conjunction by expanding propositions of the form A &amp; B and analyzing the resulting game tree, there is generally no such expansion for all t-norm based fuzzy logics and especially not for Gödel Logic G and Product logic Π . What can be done, is to define a game rule for strong conjunction and then to prove this rule the same way as the other game rules for Π and G . Not really surprisingly, we do not even have to invent a new rule, we will see that we can instead use the same rule we obtained for Lukasiewicz Logic L . This rule states that a player asserting a proposition of the form A &amp; B has to either assert both A and B or to assert ⊥ . The player’s choice to discard both A and B and instead to assert ⊥ ensures the principle of limited liability, that is to provide a strategy where the player asserting A &amp; B will in no case lose more then ¿ 1 in the long run. When dealing with G and Π this choice is no longer necessary as for both this logics the principle of limited liability is already guaranteed by the betting and evaluation scheme regardless of the final game state. On the other hand, leaving the rule as it is does no harm to G and Π and the resulting game still is suitable for L as well. The winning conditions for propositions of the form A &amp; B are, by the game rule, given by:</p>
         <p>W [ Γ | A &amp; B, ∆ ] ⇐⇒ W [ Γ | A, B, ∆ ] or W [ Γ | ⊥ , ∆ ] W [ Γ, A &amp; B | ∆ ] ⇐⇒ W [ Γ, A, B | ∆ ] and W [ Γ, ⊥ | ∆ ] .</p>
         <p>For proving that the extended evaluation function for game states is still adequate after adding this rule, we need to prove that:</p>
         <p>Γ | A &amp; B, ∆ 0 ⇐⇒ W [ Γ | A &amp; B, ∆ ] Γ, A &amp; B | ∆ 0 ⇐⇒ W [ Γ, A &amp; B | ∆ ] This amounts to showing that: Γ | A &amp; B, ∆ 0 ⇐⇒ Γ | A, B, ∆ 0 or Γ | ⊥ , ∆ 0 Γ, A &amp; B | ∆ 0 ⇐⇒ Γ, A, B | ∆ 0 and Γ, ⊥ | ∆ 0</p>
         <p>The first statement is entailed by the following facts: Γ | A &amp; B, ∆ Π = v Π ( G ) − v Π ( A &amp; B ) · v Π ( D ) G ∈ Γ D ∈ ∆ = v Π ( G ) − v Π ( A ) · v Π ( B ) · v Π ( D ) = Γ | A, B, ∆ Π G ∈ Γ D ∈ ∆ Γ | A &amp; B, ∆ G = min v G ( G ) − min v G ( A &amp; B ) , min v G ( D ) G ∈ Γ D ∈ ∆ = min v G ( G ) − min min v G ( A ) , v G ( B ) , v Π ( D ) = Γ | A, B, ∆ G G ∈ Γ D ∈ ∆ and Γ | ⊥ , ∆ Π = v Π ( G ) − 0 G ∈ Γ v Π ( G ) − v Π ( A &amp; B ) · v Π ( D ) = Γ | A &amp; B, ∆ Π G ∈ Γ D ∈ ∆ Γ | ⊥ , ∆ G = min v G ( G ) − 0 G ∈ Γ min v G ( G ) − min v G ( A &amp; B ) , min v G ( D ) = Γ | A &amp; B, ∆ G . G ∈ Γ D ∈ ∆</p>
         <p>For the second statement we can proceed completely analogous. Based on the game rule for strong conjunction it is possible to use games for proving equivalences valid for G , Π and L , just as we did for Lukasiewicz logic. The result will be, however, slightly weaker than before: All we are able to prove using the extended game rules is that if one proposition evaluates to 1 then the other one does so as we. We will not be able to prove that the truth value of two propositions actually is the same under all valuations.</p>
         <p>“If life doesn’t offer a game worth playing, then invent a new one.” Anthony J. D’Angelo</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>5</p>
      </sec>
      <sec>
         <title>Truth Comparison Games</title>
         <p>In contrast to Lukasiewicz Logic and Product Logic the truth values of formulas in Gödel Logic only depend on the relative order of the values assigned to its atomic subformulas. I.e., only order comparisons, but no arithmetic operations, have to be performed for evaluation in G . Because of this property it is possible to define dialogue games for G other than the extension of Giles’s Game treated in the previous section, which correspond more closely to the degree based semantics of G . Such a game, called truth comparison game is presented in [FP03]. In contrast to Giles’s Game, which is primarily an evaluation game, it is not necessary to assign any truth values to atomic propositions in advance (nor to define an order on them). Moreover, this game makes it possible to extract counter-models to a formula from the opponent’s winning strategies as well as to transform winning strategies for the proponent into proofs. In the following we will sketch the game rules of that game and describe how winning strategies either for the proponent or the opponent can be further exploited. The game is based on stating assertions , which are of the form A B where A and B are arbitrary formulas and is either &lt; or . Stating ” A &lt; B “ means, intuitively, that the player believes that the truth value of A is less than the truth value of B (and, of course,  A B for the truth value of A being less than or equal to the one of B ). If we want to state that a formula F is satisfiable, this is formalized as stating that there exists an interpretation where F holds. If we want to state that F is unsatisfiable, this is formalized as stating that each interpretation F holds. The main idea for this game is now that any logical connective ◦ of G can be characterized via an adequate response by player O to the other player P ’s attack on O ’s claim that a statement of the form ( A ◦ B ) C or C ( A ◦ B ) holds, where is either &lt; or and ◦ is a (binary) connective. For describing the game we use the following definitions:</p>
         <p>An assertion F G is called atomic if both F and G are atoms. An assertion that is not atomic is called a compound assertion Atomic assertions of the form a &lt; a , a &lt; ⊥ , &lt; a or ⊥ are called elementary contradictions . These are assertions which are false regardless of the interpretation. A set of two assertions of the form { e 1 e, e 2 g } , where e , g and g are atoms and 1 , 2 ∈ { &lt;, } is called an elementary order claim .</p>
         <p>The game starts with the proponent P ’s initial claim that a formula F is valid. In return the other player, called the opponent O , contradicts P ’s by asserting F &lt; . This can informally be seen as O believing that there exists an interpretation v such that v G ( F ) yields a truth value lesser than 1 , in other words, that F is not valid. From that point on each round of the game consists of two steps:</p>
         <p>1. P chooses and attacks either a compound assertion or an elementary order claim from the set of assertions made by O so far in the game, but that have not yet been attacked by P . 2. O answers to this attack by adding a set of assertions according to the rules of <xref id="XR517" ref-type="table" rid="T5">Table 5.1</xref>. Note that, in some cases O can choose between two answers, while in other cases, there is no such choice for O .</p>
         <p>If O asserts an elementary contradiction at any point in the game, the game ends and P is declared the winner of the game. Such a node containing an elementary contradiction is called a winning node for P . Otherwise, O wins if there is no further possible attack for P . Since this game can be seen as a zero-sum game with perfect information, the saddle point theorem states that there exists a winning strategy for either O or P . [FP03] proves that a  formula F is valid exactly P has such a winning strategy for the corresponding game starting with P claiming F . Such a strategy can be modeled as a dialogue tree . This is a tree, where each node is labeled either as an O-node (together with the set of assertions stated by O at that point in the game) or as a P-node (together with the assertion attacked by P ). The root node is an exception to this scheme: It is labeled as a P-node together with the assertion claimed by P to be true. On each path from the root to a leaf in this tree, O-nodes and P-nodes alternate. Since by attacking a compound assertion, only assertions which are less complex (i.e.: they have fewer connectives than the formula attacked) and since compound assertions and elementary order claims can be attacked at most once, a dialogue tree is always finite. A winning strategy for O can be seen as such a dialogue tree where each P-node has exactly one child, each O-node has a child P-node for each attack which P can issue at that point in the game (or is a leaf node, if no attack is possible for P ) and no leaf node is a winning node for P . In [FP03] it is shown, that it is possible to extract counter-models from winning strategies for O as well as to find winning strategies for O induced by counter-models. In particular, one can show that the leaf nodes of a winning strategy for O represent a complete specification of all counter models to the formula at the root node. Similarly, a winning strategy for P can be seen as such a dialogue tree where each O-node is either a winning node for P or has exactly one child and each P-node as a child O-note for each possible answer to P ’s attack by O . For example, <xref id="XR532" ref-type="fig" rid="F5.1">Figure 5.1</xref> shows a winning strategy for P for the truth comparison game starting with P claiming ( A ∧ B ) → ( B ∧ A ) to be valid 1 . At each P-node (except the root) the side of the assertion which is being attacked is underlined. Otherwise, an attack would be ambiguous, if both the left and the right hand side of that assertion consisted of a compound formula 2 . In the course of this thesis a small application, tcgame , has been implemented, which computes winning strategies for P (if there are any) draws a graph showing the strategy. <xref id="XR533" ref-type="fig" rid="F5.1">Figure 5.1</xref> has, as an example, been generated using tcgame . More about tcgame can be found in section 6.4. It is possible to construct a complete dialogue tree for a game, which is a dialogue tree in which at every node for each possible move in the game at that point a corresponding child node exists. It is possible as well to show that such a complete dialogue tree either contains a winning strategy for O or for P as a subtree sharing the same root node. Moreover, in [FP03] a calculus based on relational hypersequents is presented, which is sound and complete for G . The interesting point here is that there exists a one-to-one correspondence between winning strategies for P and proofs in this calculus.</p>
         <table-wrap id="Tx522">
            <caption>
               <p>Table 5.1: Game Rules for the Truth Comparison Game</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td> P attacks:</td>
                     <td> O asserts as answer:</td>
                     <td/>
                     <td/>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> A ∧ B C</td>
                     <td> { A C } or { B C }</td>
                     <td/>
                     <td/>
                  </tr>
                  <tr>
                     <td> C A ∧ B</td>
                     <td> { C A, C B }</td>
                     <td/>
                     <td/>
                  </tr>
                  <tr>
                     <td> A ∨ B C</td>
                     <td> { A C, B C }</td>
                     <td/>
                     <td> P { A attacks: B, B C } O { A asserts C } as</td>
                  </tr>
                  <tr>
                     <td> C A ∨ B</td>
                     <td> { C A } or { C B }</td>
                     <td/>
                     <td/>
                  </tr>
                  <tr>
                     <td> A → B&lt;C</td>
                     <td> { B &lt; A, B &lt; C }</td>
                     <td/>
                     <td> { { A A &lt; B, B, B B &lt; C C } } { { A A &lt; &lt; C C } }</td>
                  </tr>
                  <tr>
                     <td> C&lt;A → B</td>
                     <td> { C &lt; B } or { A B, C &lt;</td>
                     <td> }</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> A → B C</td>
                     <td> { C } or { B &lt; A, B</td>
                     <td> C }</td>
                     <td/>
                  </tr>
                  <tr>
                     <td> C A → B</td>
                     <td> { A B } or { C B }</td>
                     <td/>
                     <td/>
                  </tr>
                  <tr>
                     <td/>
                     <td> with denoting either</td>
                     <td> &lt; or</td>
                     <td> consistently through each line.</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>Winning strategies for O</p>
         <p>Winning strategies for P</p>
         <p>5.1 Extending G by Additional Operators We can observe that in G there exists no formula F , ∈ { &lt;, } with occurrences of propositional variables A and B such that for all interpretations:   1 if v G ( A ) v G ( B ) v G ( F ) =  0 otherwise</p>
         <p>holds. This means that we cannot fully express the natural order on truth degrees within G itself. In order to make G more powerful, we can define two unary connectives and which</p>
         <p>1 In [FP03] such a such a winning strategy is sketched for the formula ( A → B ) ∨ ( B → A ) . Note that the corresponding illustration actually does not show a winning strategy for P ; the second O-node would be required to have only one child node for that purpose. 2 Note that in [FP03] this information is not explicitly included in the label attached to a P-node. In order to know which side of the assertion has been attacked, one would need to take a look at the next O-node and find out to which attack the answer fitted.</p>
         <p>P (( a ∧ b ) → ( b ∧ a )) O { (( a ∧ b ) → ( b ∧ a )) &lt; ⊤} P (( a ∧ b ) → ( b ∧ a )) &lt; ⊤ O { ( b ∧ a ) &lt; ( a ∧ b ) , ( b ∧ a ) &lt; ⊤} P ( b ∧ a ) &lt; ( a ∧ b ) { ( b ∧ a ) &lt; ⊤ , b &lt; ( a ∧ b ) } O O { ( b ∧ a ) &lt; ⊤ , a &lt; ( a ∧ b ) } b &lt; ( a ∧ b ) P P a &lt; ( a ∧ b ) { ( b ∧ a ) &lt; ⊤ , b &lt; a, b &lt; b } O O { ( b ∧ a ) &lt; ⊤ , a &lt; a , a &lt; b }</p>
         <fig id="F5.1">
            <caption>
               <p>Figure 5.1: Winning strategy for P for the game starting with ( a ∧ b ) → ( b ∧ a )</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>accomplish exactly that:    1 if v ∗ ( A ) = 1  1 if v ∗ ( A ) = 0 v ( A ) = and v ( A ) =  0 otherwise  0 otherwise (Note that the connective could as well have been defined in G as A := ¬¬ A , but for this is not possible.) By adding the connective to G , it is possible to find formulas F &lt; and F as specified above: The formula F := ( A → B ) evaluates to 1 if A B and to 0 otherwise, and the formula F &lt; := (( B → A ) → B ) ∧ ¬ ( A )</p>
         <p>accomplishes the same for &lt; . The new connective can be characterized using the truth comparison game presented in this section by adding the following rules in <xref id="XR547" ref-type="table" rid="T5.2">table 5.2</xref> to the game rules. This allows the proponent to attack assertions involving the connective. (As F is equivalent to ¬¬ F for any formula F , this connective can already be characterized by the game without introducing new rules.)</p>
         <p>P attacks: O asserts as answer: A&lt;C { A &lt; , ⊥ &lt; C } C&lt; A { A, C &lt; } A C { A &lt; } or { ⊥ &lt; C } C A { A } or { C ⊥ } where is either &lt; or .</p>
         <table-wrap id="T5.2">
            <caption>
               <p>Table 5.2: Game Rules for the Extended Truth Comparison Game</p>
            </caption>
         </table-wrap>
         <p>“The game is up.” William Shakespeare, “Cymbeline”</p>
      </sec>
      <sec>
         <title>CHAPTER</title>
         <p>6</p>
      </sec>
      <sec>
         <title>Implementation of Giles’s Game</title>
         <p>In the context of this thesis four utilities have been implemented. In the following these applications as well as their usage are documented. The first application, Webgame, runs on any web browser capable of executing JavaScript code. The other three applications are implemented in Haskell, a purely functional programming language 1 . As a compiler, the Glasgow Haskell Compiler 2 is used. For executing, a standard Unix-like environment is required, however they also work under Microsoft Windows using the Cygwin environment 3 . Binaries for Linux and Windows as well as the source code can be downloaded from <ext-link ext-link-type="uri" href="http://www.logic.at/people/roschger/thesis">http://www.logic.at/people/roschger/thesis</ext-link> . Webgame is a web-based application which allows to play Giles’s Game and its variants for Product Logic and Gödel Logic. After playing the game the evaluation of the final game state is simulated. Therefore probability values are assigned to the experiments corresponding to all atomic propositions. Then arbitrarily many runs of the evaluation can be performed and the average loss is displayed. Webgame can be played online at <ext-link ext-link-type="uri" href="http://www.logic.at/people/roschger/thesis/webgame/">http://www.logic.at/people/roschger/thesis/webgame/</ext-link> . The game is divided into five steps which are explained below. At any point in the game it is possible to go back to a former step. In some situations it is necessary to cancel the current game; in this case a warning is issued before stepping back. As an example the current dialogue has to be abandoned if one wants to change the initial game state or the logic determining the game rules. On the other hand, when evaluating a final game state and one wants to change only the probability values assigned to atomic experiments this can be done without replaying the complete dialogue (although the evaluation of the final game state so far will be dismissed of course). The first step of the game consists of choosing one of Lukasiewicz Logic, Product Logic, or Gödel Logic as seen in <xref id="XR572" ref-type="fig" rid="F6">Figure 6.1</xref>. This choice affects the game rules, the evaluation scheme and in some cases how connectives are eliminated (see below). Additionally, there is a checkbox, “Don’t use special characters in formulas”. By checking this, no special characters will be used when displaying formulas. Instead, formulas will be displayed exactly as they have been typed by the user. A user will choose this option if his web browser uses a font which does not support the special characters used for various connectives and symbols.  <xref id="XR574" ref-type="fig" rid="F6.2">Figure 6.2</xref> shows a screen shot of Step 2. Here the user can choose the initial game state. A formula can be added to either my our your initial tenet by typing it into the text field and choosing either “for me” or “for you”. When typing formulas, the notation to be used for the connectives as well as for the constants , ⊥ and atomic propositions is displayed below the input field. If the checkbox in Step 1 was not checked then the symbols for connectives are instantly replaced by the corresponding symbols according to <xref id="XR575" ref-type="table" rid="T6">Table 6.1</xref>. Once a formula has been added to the initial game state, it can be edited and deleted by clicking on it. This removes the formula from the game state and displays it in the input field. When the checkbox “eliminate connectives” is checked, all connectives are eliminated as possible. The truth constant is replaced by ⊥ → ⊥ . For Lukasiewicz Logic only → and ⊥ will be left (see Definition 3 and Lemma 3). Moreover, max-disjunction A ∨ B is eliminated</p>
         <p>6.1 Webgame</p>
         <p>1 see <ext-link ext-link-type="uri" href="http://haskell.org">http://haskell.org</ext-link> 2 see <ext-link ext-link-type="uri" href="http://www.haskell.org/ghc/">http://www.haskell.org/ghc/</ext-link> 3 see <ext-link ext-link-type="uri" href="http://www.cygwin.com/">http://www.cygwin.com/</ext-link>
         </p>
         <fig id="F6.1">
            <caption>
               <p>Figure 6.1: Step 1: Choosing the Logic</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <fig id="F6.2">
            <caption>
               <p>Figure 6.2: Step 2: Choosing an Initial Game State</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <table-wrap id="Tx582">
            <caption>
               <p>Table 6.1: Notation Used in Webgame</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td/>
                     <td> Input as Displayed as</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> min conjunction</td>
                     <td> &amp; ∧</td>
                  </tr>
                  <tr>
                     <td> strong conjunction</td>
                     <td> &amp;&amp;</td>
                  </tr>
                  <tr>
                     <td> max disjunction</td>
                     <td> | ∨</td>
                  </tr>
                  <tr>
                     <td> strong disjunction</td>
                     <td> || ⊕</td>
                  </tr>
                  <tr>
                     <td> implication</td>
                     <td> -&gt; →</td>
                  </tr>
                  <tr>
                     <td> negation</td>
                     <td> - ¬</td>
                  </tr>
                  <tr>
                     <td> falsum</td>
                     <td> 0 ⊥</td>
                  </tr>
                  <tr>
                     <td> verum</td>
                     <td> 1</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>by (( A → B ) → B ) as shown in Section 2.3.</p>
         <p>Next, in Step 3, the user has to give valuations for all atomic propositions (except ⊥ and ) which occur in the initial game state. These valuations give the success probability of an experiment associated with the corresponding atomic proposition. These probability values will be used when simulating the evaluation of an atomic game state in Step 5.  In Step 4 the dialogue game itself is played finally. The tenets of both players are displayed. Below the available moves for both players are listed (see screen shot 6.4(a)). If the mouse pointer hovers over a button for doing a move, the corresponding formula is highlighted in the tenet. If the move involves a min-conjunction or max-disjunction, the chosen formula additionally is underlined. When Product Logic or Gödel Logic have been selected in Step 1, implications are attacked as described in Rules 1a and 1b . In this case there are only two possibilities for the following move: the attacked player has to choose whether to challenge the attack or not. If an attack is challenged and the flag ¶ is raised, this is indicated by the symbol ¶ on the right side of the tenet. Using the “Undo last move” button it is always possible to go back in the game. This also works multiple times, one can always get back as far as to the initial state. Using the “Redo move” button the game can replayed after undoing one or more moves. Eventually, at some point in the game only atomic propositions are left in the players’ tenets. Then the button “Next Step: Evaluation” is activated as screen shot 6.4(b) shows. Clicking it, we reach Step 5. In Step 5 the final game state reached in Step 4 is evaluated. For Lukasiewicz Logic the risk values for both players are calculated and displayed; for Product Logic and Gödel Logic the expect gain is used instead. Additionally the evaluation using dispersive experiments can be simulated: for each atomic proposition in the final game the outcome of the associated experiment is determined using a random number generator. The probability of each experiment to succeed is equal to the probability value given in Step 3. Using the buttons at the bottom the evaluation can be repeated several times. My average gain or loss is displayed; one can see that it approaches the difference of the risk values (respectively expected gain) calculated for both players. Screen shot 6.5 shows a repeated evaluation of the final game state. When repeating the evaluation very often, this can easily slow down the application. The reason is that, at some point, the table showing the outcomes gets too large. Thus, when the checkbox “Do not display evaluations” is checked, the outcomes of the experiments are not displayed in that table. Instead, only my average gain (respectively loss) is calculated and displayed. giles is a small program implemented in Haskell. Its main purpose is to visualize game trees of Giles’s Game for Lukasiewicz Logic. The output of the Haskell program is a dot-file to be further processed by the Graphviz-tools 4 . These tools help drawing graphs by trying to layout them as planarly as possible and providing many output formats such as postscript, png, or svg. giles is invoked at the command prompt. Provided with a formula A it will generate a game tree for Giles’s Game starting in the game state [ | A ] . The edges of this game tree are labeled with the corresponding moves. If there are several compound assertions present in a game state, giles will pick one of these and branch according to the possible successor states. Thus, by taking into account that the order in which assertions are being attacked does not matter (see Section 3.4), it is possible to simplify the game tree considerably. The game tree is then automatically passed to dot , one of the Graphviz-tools. The resulting postscript file is saved as game.ps . If invoked without argument, giles prints a usage message explaining the input syntax and giving some example formulas. <xref id="XR615" ref-type="table" rid="T6.2">Table 6.2</xref> shows the notation for formulas. Note that there is no explicit symbol for negation; ¬ A has to be typed as A -&gt; 0 . Most of the game trees in this thesis have been generated using giles . For example, <xref id="XR616" ref-type="fig" rid="F3.6">Figure 3.6</xref> has been generated by issuing giles "((a -&gt; b) -&gt; b) / \ ((b -&gt; a) -&gt; a)" at the command prompt. hypseq is small utility which finds and prints derivations of formulas in the hypersequent calculus rH (see Section 2.6). If invoked with a formula A , hypseq searches for a derivation with A as the root hypersequent. hypseq is written in Haskell, its output is L A TEX-code using the bussproofs package 5 . For parsing the user input, i.e. the formula to start with, the same Haskell module is used as for the giles utility above. Therefore, the input syntax is equal to the one described in <xref id="XR622" ref-type="table" rid="T6">Table 6.2</xref>. After invoking hypseq the L A TEX compiler is executed automatically and the resulting document is converted to a postscript file. It is saved as proof.ps in the current directory. Note that hypseq just provides derivations with atomic hypersequents as axioms. It is not checked whether these hypersequents are valid as in Definition 7. If there exist multiple derivations (this occurs when there are multiple rules which can be applied to one relational hypersequent), internally a complete tree is constructed including all derivations. Before generating the L A TEX output, however, this tree is reduced such that only one derivation chosen and printed. This final derivation is chosen such that it is the derivation with the smallest depth, i.e. the shallowest derivation. If there are more than one derivations for which this applies, one of them is picked. In Section 2.6 hypersequents are defined as a multiset set of sequents. hypseq instead treats them as sets of sequents, which means that a sequents can occur at most once in a hypersequent. This does not change the expressiveness of the calculus, but makes some proofs more concise. For example, the derivation tree in <xref id="XR623" ref-type="fig" rid="F2.4">Figure 2.4</xref> is generated by hypseq by issuing the command hypseq "a &amp; (a -&gt; b)" at the command prompt. tcgame was developed for finding and printing winning strategies for the proponent of a Truth Comparison Game as defined in Chapter 5. Provided with a formula A it searches for a winning strategy for the proponent of A . The existence of such a strategy can be seen as a proof of A . The application is implemented in Haskell, like giles and hypseq . Since in Gödel Logic min-conjunction and strong conjunction coincide, the latter one can be omitted. Thus the input syntax for formulas is exactly the same as for these two programs with the only difference that there is no symbol for strong conjunction. The definition of winning strategies given in Chapter 5 refers to [FP03]. Such a strategy consists of a tree with the starting formula at the root node. It is visualized using latex and pst-tree, part of the PSTricks package 6 . The output is saved as a postscript file tcgame.ps . For example, <xref id="XR632" ref-type="fig" rid="F5.1">Figure 5.1</xref> has been generated by issuing the command tcgame "(a / \ b) -&gt; (b / \ a)" .</p>
         <fig id="F6.3">
            <caption>
               <p>Figure 6.3: Step 3: Probabilities for Atomic Experiments</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <fig id="Fx598">
            <caption>
               <p/>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>(a) Doing a Move</p>
         <fig id="Fx600">
            <caption>
               <p/>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>(b) Reaching a Final Game State</p>
         <fig id="F6.4">
            <caption>
               <p>Figure 6.4: Step 4: Playing the Game</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <p>6.2 Giles</p>
         <p>4 see <ext-link ext-link-type="uri" href="http://www.graphviz.org/">http://www.graphviz.org/</ext-link>
         </p>
         <fig id="F6.5">
            <caption>
               <p>Figure 6.5: Step 5: Evaluating the Final Game State</p>
            </caption>
            <graphic xlink:href=""/>
         </fig>
         <table-wrap id="Tx612">
            <caption>
               <p>Table 6.2: Notation Used in Giles</p>
            </caption>
            <table>
               <thead>
                  <tr>
                     <td/>
                     <td> Input as</td>
                  </tr>
               </thead>
               <tbody>
                  <tr>
                     <td> min conjunction</td>
                     <td> / \</td>
                  </tr>
                  <tr>
                     <td> strong conjunction</td>
                     <td> &amp;</td>
                  </tr>
                  <tr>
                     <td> max disjunction</td>
                     <td> \ /</td>
                  </tr>
                  <tr>
                     <td> implication</td>
                     <td> -&gt;</td>
                  </tr>
                  <tr>
                     <td> falsum</td>
                     <td> 0</td>
                  </tr>
               </tbody>
            </table>
         </table-wrap>
         <p>6.3 Hypseq</p>
         <p>6.4 TCGame</p>
         <p>5 see <ext-link ext-link-type="uri"
                      href="http://www.ctan.org/tex-archive/help/Catalogue/entries/bussproofs.html">http://www.ctan.org/tex-archive/help/Catalogue/entries/bussproofs.html</ext-link>
         </p>
         <p>6 see <ext-link ext-link-type="uri" href="http://tug.org/PSTricks/main.cgi/">http://tug.org/PSTricks/main.cgi/</ext-link>
         </p>
      </sec>
      <sec>
         <title>Notation used</title>
         <p>Atom The set of all atomic propositions. Atomic propositions are usually denoted using lower letters, e.g. a, b, c, . . . . Prop The set of all propositions as defined in Definition 3, Prop ⊃ Atom . Compound propositions are usually denoted using upper letters, e.g. A, B, C, . . . . Exper The set of all yes/no experiments. The experiment associated with the atomic proposition a is denoted as E a (see Definition 9). f : [ 0, 1 ] n → [ 0, 1 ] The truth function assigned to the n-ary connective . v : Atom → [ 0, 1 ] The truth value assigned to an atomic proposition. v ∗ : Prop → [ 0, 1 ] The truth value assigned to an arbitrary proposition in the fuzzy logic based on the t-norm ∗ ; see Definition 3. π : Exper → [ 0, 1 ] The subjective probability assigned to an experiment; see definition 13.</p>
         <p>[ Γ | ∆ ] A game state, where Γ denoting a multiset of formulas asserted by you and ∆ denoting a multiset of formulas asserted by me.</p>
         <p>Γ | ∆ ∗ ∗ ∈ , G , Π }</p>
      </sec>
      <sec>
         <title>for { L</title>
         <p>My risk value for the game state [ Γ | ∆ ] , i.e. the amount of money I expect to lose assuming both players acting rationally. See Definition 14.</p>
         <p>A ∗ ∗ ∈ , G , Π }</p>
      </sec>
      <sec>
         <title>for { L</title>
         <p>The risk value of the game starting in [ | A ] . I.e. short for | A ∗</p>
         <p>∗ Γ | ∆ ∗ ∈ , G , Π }</p>
      </sec>
      <sec>
         <title>for { L</title>
         <p>The extension of the evaluation function v ∗ (see Definition 3) to arbitrary game states as in Definitions 15 and 18.</p>
      </sec>
      <sec>
         <title>Bibliography</title>
         <p>[Avr91] Arnon Avron. Hypersequents, logical consequence and intermediate logics for concurrency. Annals of Mathematics and Artificial Intelligence , 4(3):225–248, 1991. [BF99] Matthias Baaz and Christian G. Fermüller. Analytic calculi for projective logics. In TABLEAUX ’99: Proceedings of the International Conference on Automated Reasoning with Analytic Tableaux and Related Methods , pages 36–50, London, UK, 1999. Springer-Verlag. [CFM04] Agata Ciabattoni, Christian G. Fermüller, and George Metcalfe. Uniform Rules and Dialogue Games for fuzzy logics. In Franz Baader and Andrei Voronkov, editors, LPAR , volume 3452 of Lecture Notes in Computer Science , pages 496– 510. Springer, 2004. [Dum59] M. Dummett. A propositional calculus with denumerable matrix. J. Symbolic Logic , 24(2):97–106, 1959. [EG01] F. Esteva and L. Godo. Monoidal t-norm based logic: towards a logic for left- continuous t-norms. Fuzzy sets and systems , 124(3):271–288, 2001. [EGHM03] F. Esteva, L. Godo, P. Hájek, and F. Montagna. Hoops and Fuzzy Logic. Journal of Logic and Computation , 13(4):532–555, 2003. [Fer09] Christian G. Fermüller. Revisiting Giles - Connecting Bets, Dialogue Games, and Fuzzy Logics. In Ondrej Majer, Ahti-Veikko Pietarinen, and Tero Tulenheimo,</p>
         <p>editors, Games: Unifying Logic, Language, and Philosophy , volume 15 of Logic, Epistemology and the Unity of Science . Springer, 2009. [FK06] C.G. Fermuller and R. Kosik. Combining Supervaluation and Degree Based Reasoning Under Vagueness. Lecture Notes in Computer Science , 4246:212, 2006. [FP03] Christian G. Fermüller and Norbert Preining. A Dialogue Game for Intuitionistic Fuzzy Logic Based on Comparisons of Degrees of Truth. In Proceedings of InTech‘03 (Fourth International Conference on Intelligent Technologies) , Chiang Mai, Thailand, December 2003. [Gen69] G. Gentzen. Investigations into logical deduction. The Collected Papers of Ger- hard Gentzen , pages 68–131, 1969. [Gil74] Robin Giles. A non-classical logic for physics. Studia Logica , 33(4):397–415, 1974. [Gil82] Robin Giles. Semantics for Fuzzy Reasoning. International Journal of Man- Machine Studies , 17:401–415, 1982. [Göd32] K. Gödel. Zum intuitionisticschen Aussagenkalkül. Anzeiger Akademie der Wis- senschaften Wien, mathematisch-naturwiss. Klasse , 32:65–66, 1932. [Gog69] J.A. Goguen. The logic of inexact concepts. Synthése , 19(3):325–373, 1969. [Háj02] Petr Hájek. Why fuzzy logic. In Dale Jacquette, editor, A Companion to Philo- sophical Logic , pages 595–605. Blackwell, Massachusetts, 2002. [HGE95] Petr Hájek, Lluis Godo, and Francesc Esteva. Fuzzy logic and probability. In Proceedings of the 11th Annual Conference on Uncertainty in Artificial Intelligence (UAI-95) , pages 237–244, San Francisco, CA, 1995. Morgan Kaufmann. [HGE96] P. Hájek, L. Godo, and F. Esteva. A complete many-valued logic with product- conjunction. Archive for Mathematical Logic , 35(3):191–208, 1996. [Há02] Petr Hájek. Metamathematics of Fuzzy Logic , volume 4 of Trends in Logic . Springer, 2002. [KMP00] E.P. Klement, Radko Mesiar, and Endre Pap. Triangular Norms , volume 8 of Trends in Logic . Springer, 2000.</p>
         <p>[Lor60] P. Lorenzen. Logik und Agon. In Atti del Congresso Internazionale di Filosofia , pages 187–194, Firenze, 1960. Sansoni. [Lor61] P. Lorenzen. Ein dialogisches Konstruktivitätskriterium. In Infinitistic Methods , pages 193–200, Warszawa, 1961. PWN. Proceed. Symp. Foundations of Math. [Luk20] J. Lukasiewicz. O logice trojwartosciowej. Ruch Filozoficzny , 5(169-171):32, 1920. [MOG04] George Metcalfe, Nicola Olivetti, and Dov Gabbay. Analytic Proof Calculi for Product Logics. Archive for Mathematical Logic , 43(7):859–889, 2004. [MOG05] George Metcalfe, Nicola Olivetti, and Dov Gabbay. Sequent and hypersequent calculi for abelian and Lukasiewicz logics. ACM Trans. Comput. Logic , 6(3):578– 613, 2005. [RJM94] II Robert J. Marks. Fuzzy Logic Technology and Applications I . IEEE Press, Piscataway, NJ, USA, 1994. [Sca62] B. Scarpellini. Die Nichtaxiomatisierbarkeit des unendlichwertigen Prädikatenkalküls von Lukasiewicz. Journal of Symbolic Logic , 27(2):159– 170, 1962. [Zad96] L.A. Zadeh. The role of fuzzy logic in modeling, identification and control. Fuzzy Sets, Fuzzy Logic, and Fuzzy Systems: Selected Papers , 1996.</p>
      </sec>
      <sec>
         <title>List of Figures</title>
         <p>2.1 Lukasiewicz T-Norm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9 2.2 Gödel T-Norm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.3 Product T-Norm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.4 Sample proof for a &amp; ( a → b ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 3.1 Game Tree for the Game Starting With ( a ∧ b ) → ( ¬ b ∨ a ) . . . . . . . . . . 23 3.2 Game Tree for a &amp; b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 3.3 Game Tree for a ∨ b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35 3.4 Game Tree for a ∧ b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3.5 Game Tree for a &amp; ( a → b ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 3.6 Game Tree for a ∨ b . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37 3.7 Game Tree for (( a → b ) → b ) ∧ (( b → a ) → a ) . . . . . . . . . . . . . . . . . . 42 5.1 Winning strategy for P for the game starting with ( a ∧ b ) → ( b ∧ a ) . . . . . 67 6.1 Step 1: Choosing the Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 6.2 Step 2: Choosing an Initial Game State . . . . . . . . . . . . . . . . . . . . . . 71 6.3 Step 3: Probabilities for Atomic Experiments . . . . . . . . . . . . . . . . . . 72 6.4 Step 4: Playing the Game . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 6.5 Step 5: Evaluating the Final Game State . . . . . . . . . . . . . . . . . . . . . 74</p>
      </sec>
      <sec>
         <title>List of Tables</title>
         <p>2.1 T-Norms and Their Residua . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8 5.1 Game Rules for the Truth Comparison Game . . . . . . . . . . . . . . . . . . 65 5.2 Game Rules for the Extended Truth Comparison Game . . . . . . . . . . . . . 68 6.1 Notation Used in Webgame . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 6.2 Notation Used in Giles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74</p>
         <p>analyticity, 14 avowed meaning, 17 Cancellative Hoop Logic, 47 CHL, see Cancellative Hoop Logic completeness, 13 conditions of admissability, 16 conjunction min conjunction, 8 strong conjunction, 8 dialogue game rules, 20 dialogue tree, 65 dispersion-free, 17 dispersive, 17 elementary contradiction, 64 elementary order claim, 64 equivalent formulas, 8 equivalent game states, 32 first order Lukasiewicz Logic, 37 flag, 47 frame rules, 20 fuzzy modus ponens, 7</p>
      </sec>
      <sec>
         <title>Index</title>
         <p>game state, 22 game tree, 23 Giles, Robin, 16 hypersequent system, 12 implication Gödel, 8 Goguen, 7 Lukasiewicz, 8 Product, 8 interpretation, 8 Intuitionistic Logic, 10 invertible rules, 14 involutive negation, 10 logical identity, 25 Lorenzen, Paul, 18, 20 monoidal t-norm logic, 6 omniscient player, 39 ordinal sum, 6 parametric experiment, 38 principle of limited liability, 19, 20, 61</p>
         <p>probability definite, 27 relational hypersequent, 12 relational sequent, 12 residuum, 6 rH, 48 risk value, 27 saddle point theorem, 28, 64 sequent, 12 soundness, 13 subjective probability, 27 subjectively false, 24 subjectively true, 24 t-norm, 5 Gödel, 6 Lukasiewicz, 6 Product, 6 tangible meaning, 17 tenet, 22 truth comparison game, 63 truth functionality, 4 valid formula, 9 valuation, 8 winning condition, 45, 47, 57 zero sum game, 26</p>
      </sec>
   </body>
   <back/>
</article>