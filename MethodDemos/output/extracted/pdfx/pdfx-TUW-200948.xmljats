<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article
  SYSTEM "http://dtd.nlm.nih.gov/archiving/3.0/archivearticle3.dtd">
<article xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xmlns:mml="http://www.w3.org/1998/Math/MathML"
         xmlns:xlink="http://www.w3.org/1999/xlink">
   <front>
      <journal-meta>
         <journal-id/>
         <journal-title-group>
            <journal-title/>
         </journal-title-group>
         <issn/>
         <publisher>
            <publisher-name/>
         </publisher>
      </journal-meta>
      <article-meta>
         <title-group>
            <article-title>A Probabilistic Approach to Problems Parameterized Above or Below Tight Bounds</article-title>
         </title-group>
         <supplement>
            <p>Gregory Gutin 1 , Eun Jung Kim 1 , Stefan Szeider 2 , and Anders Yeo 1 1 Department of Computer Science Royal Holloway, University of London Egham, Surrey TW20 0EX, UK { gutin|eunjung|anders } @cs.rhul.ac.uk 2 Department of Computer Science, Durham University, Durham DH1 3LE, England, UK <email>stefan@szeider.net</email>
            </p>
         </supplement>
         <abstract>
            <sec>
               <p>We introduce a new approach for establishing fixed-parameter tractability of problems parameterized above tight lower bounds or below tight upper bounds. To illustrate the approach we consider two problems of this type of unknown complexity that were introduced by Mahajan, Raman and Sikdar (J. Comput. Syst. Sci. 75, 2009). We show that a generalization of one of the problems and three nontrivial special cases of the other problem admit kernels of quadratic size.</p>
            </sec>
         </abstract>
      </article-meta>
   </front>
   <body>
      <sec>
         <title>1 Introduction</title>
      </sec>
      <sec>
         <title>2 Probabilistic Inequalities</title>
         <p>In our approach we introduce a random variable X such that the answer to the problem parameterized above a tight lower bound or below a tight upper bound is yes if and only if X takes with positive probability a value greater or equal to the parameter k . In this paper all random variables are real. A random variable is discrete if its distribution function has a finite or countable number of positive increases. A random variable X is a symmetric if − X has the same distribution function as X . If X is discrete, then X is symmetric if and only if Prob( X = a ) = Prob( X = − a ) for each real a. Let X be a symmetric variable for which the first moment E ( X ) exists. Then E ( X ) = E ( − X ) = − E ( X ) and, thus, E ( X ) = 0 . The following is easy to prove [<xref id="XR24" ref-type="bibr" rid="R17">17</xref>]. Lemma 1. If X is a symmetric random variable and E ( X 2 ) &lt; ∞ , then</p>
         <p>Prob( X ≥ E ( X 2 ) ) &gt; 0 .</p>
         <p>See Sections 3 and 4 for applications of Lemma 1. Unfortunately, often X is not symmetric, but Lemma 2 provides an inequality that can be used in many such cases. This lemma was proved by Alon et al. [<xref id="XR27" ref-type="bibr" rid="R2">2</xref>]; a weaker version was obtained by H ̊ astad and Venkatesh [<xref id="XR28" ref-type="bibr" rid="R12">12</xref>].</p>
         <p>Lemma 2. Let X be a random variable and suppose that its first, second and forth moments satisfy E ( X ) = 0 , E ( X 2 ) = σ 2 &gt; 0 and E ( X 4 ) ≤ bσ 4 , respectively. Then Prob( X &gt; 4 √ σ b ) ≥ 4 4 1 / 3 b .</p>
         <p>Since it is often rather nontrivial to evaluate E ( X 4 ) in order to check whether E ( X 4 ) ≤ bσ 4 holds, one can sometimes use the following result by Bourgain [<xref id="XR32" ref-type="bibr" rid="R5">5</xref>]. Lemma 3. Let f = f ( x 1 , . . . , x n ) be a polynomial of degree r in n variables x 1 , . . . , x n with domain {− 1 , 1 } . Define a random variable X by choosing a vec- tor ( 1 , . . . , n ) ∈ {− 1 , 1 } n uniformly at random and setting X = f ( 1 , . . . , n ) . Then E ( X 4 ) ≤ 2 6 r ( E ( X 2 )) 2 .</p>
      </sec>
      <sec>
         <title>3 Linear Ordering</title>
         <p>Let D = ( V, A ) be a digraph with no loops or parallel arcs in which every arc ij has a positive weight w ij . The problem of finding an acyclic subdigraph of D of maximum weight, known as Linear Ordering , has applications in economics [<xref id="XR35" ref-type="bibr" rid="R3">3</xref>]. Let n = | V | and consider a bijection α : V → { 1 , . . . , n } . Observe that the subdigraphs ( V, { ij ∈ A : α ( i ) &lt; α ( j ) } ) and ( V, { ij ∈ A : α ( i ) &gt; α ( j ) } ) are acyclic. Since the two subdigraphs contain all arcs of D , at least one of them has weight at least W/ 2, where W = ij ∈ A w ij , the weight of D . Thus, W/ 2 is a lower bound on the maximum weight of an acyclic subdigraph of D . Consider a digraph D where for every arc ij of D there is also an arc ji of the same weight. Each maximum weight subdigraph of D has weight exactly W/ 2. Hence the lower bound W/ 2 is tight.</p>
         <p>Linear Ordering Above Tight Lower Bound ( LOALB ) Instance: A digraph D = ( V, A ), each arc ij has an integral positive weight w ij , and a positive integer k . Parameter: The integer k . Question: Is there an acyclic subdigraph of D of weight at least W/ 2+ k , where W = ij ∈ A w ij ?</p>
         <p>Mahajan, Raman, and Sikdar [<xref id="XR38" ref-type="bibr" rid="R15">15</xref>] asked whether LOALB is fixed-parameter tractable for the special case when all arcs are of weight 1 (i.e., D is unweighted). In this section we will prove that LOALB admits a kernel with O ( k 2 ) arcs; consequently the problem is fixed-parameter tractable. Note that if we allow weights to be positive reals, then we can show, similarly to the NP-completeness proof given in the next section, that LOALB is NP-complete already for k = 1. Consider the following reduction rule: Reduction Rule 1 Assume D has a directed 2-cycle iji ; if w ij = w ji delete the cycle, if w ij &gt; w ji delete the arc ji and replace w ij by w ij − w ji , and if w ji &gt; w ij delete the arc ij and replace w ji by w ji − w ij . It is easy to check that the answer to LOALB for a digraph D is yes if and only if the answer to LOALB is yes for a digraph obtained from D using the reduction rule as long as possible. Let D = ( V, A ) be an oriented graph, let n = | V | and W = ij ∈ A w ij . Consider a random bijection: α : V → { 1 , . . . , n } and a random variable X ( α ) = 2 1 ij ∈ A ij ( α ), where ij ( α ) = w ij if α ( i ) &lt; α ( j ) and ij ( α ) = − w ij , otherwise.</p>
         <p>It is easy to see that X ( α ) = { w ij : ij ∈ A, α ( i ) &lt; α ( j ) } − W/ 2. Thus, the answer to LOALB is yes if and only if there is a bijection α : V → { 1 , . . . , n } such that X ( α ) ≥ k . Since E ( ij ) = 0, we have E ( X ) = 0. Let W (2) = ij ∈ A w ij 2 . We will prove the following: Lemma 4. E ( X 2 ) ≥ W (2) / 12 . Proof. Let N + ( i ) and N − ( i ) denote the sets of out-neighbors and in-neighbors of a vertex i in D . By the definition of X ,</p>
         <p>where the second sum is taken over ordered pairs of distinct arcs. Clearly, ij ∈ A E ( 2 ij ) = W (2) . To compute ij,pq ∈ A E ( ij pq ) we consider the following cases:</p>
         <p>Case 1: { i, j } ∩ { p, q } = ∅ . Then ij and pq are independent and E ( ij pq ) = E ( ij ) E ( pq ) = 0. Case 2a: |{ i, j } ∩ { p, q }| = 1 and i = p . Since the probability that i &lt; min { j, q } or i &gt; max { j, q } is 2 / 3, ij iq = w ij w iq with probability 3 2 and ij iq = − w ij w iq with probability 1 3 . Thus, for every i ∈ V we have ij,iq ∈ A E ( ij iq ) = 1 3 { w ij w iq : j = q ∈ N + ( i ) } = 1 3 ( j ∈ N + ( i ) w ij ) 2 − 3 1 j ∈ N + ( i ) w ij 2 . Case 2b: |{ i, j } ∩ { p, q }| = 1 and j = q . Similarly to Case 2a, we obtain ij,pj ∈ A E ( ij pj ) = 3 1 ( i ∈ N − ( j ) w ij ) 2 − 1 3 i ∈ N − ( j ) w ij 2 . Case 3a: |{ i, j } ∩ { p, q }| = 1 and i = q . Since ij pi = w ij w pi with probability 1 3 and ij pi = − w ij w pi with probability 3 2 , we obtain ij,pi ∈ A E ( ij pi ) = − 1 3 { w ij w pi : j ∈ N + ( i ) , p ∈ N − ( i ) } = − 3 1 j ∈ N + ( i ) w ij p ∈ N − ( i ) w pi .</p>
         <p>Case 3b: |{ i, j } ∩ { p, q }| = 1 and j = p . Similarly to Case 3a, we obtain ij,jq ∈ A E ( ij jq ) = − 3 1 i ∈ N − ( j ) w ij q ∈ N + ( j ) w jq . Equation (1) and the subsequent computations imply that 4 · E ( X 2 ) = W (2) + 1 3 ( Q − R ) , where Q = i ∈ V j ∈ N + ( i ) w ij 2 − j ∈ N + ( i ) w ij 2 + j ∈ N − ( i ) w ji 2 − j ∈ N − ( i ) w ji 2 , and R = 2 · i ∈ V j ∈ N + ( i ) w ij j ∈ N − ( i ) w ji . By the inequality of arithmetic and geometric means, for each i ∈ V , we have 2 2 w ij + w ji − 2 w ij w ji ≥ 0 . j ∈ N + ( i ) j ∈ N − ( i ) j ∈ N + ( i ) j ∈ N − ( i ) Therefore, Q − R ≥− w ij 2 − w ji 2 = − 2 W (2) , i ∈ V j ∈ N + ( i ) i ∈ V j ∈ N − ( i )</p>
         <p>and 4 · E ( X 2 ) ≥ W (2) − 2 W (2) / 3 = W (2) / 3, implying E ( X 2 ) ≥ W (2) / 12. Now we can prove the main result of this section. Theorem 1. The problem LOALB admits a kernel with O ( k 2 ) arcs.</p>
         <p>Proof. Let H be a digraph. We know that the answer to LOALB for H is yes if and only if the answer to LOALB is yes for a digraph D obtained from H using Reduction Rule 1 as long as possible. Observe that D is an oriented graph. Let B be the set of bijections from V to { 1 , . . . , n } . Observe that f : B → B such that f ( α ( v )) = | V | + 1 − α ( v ) for each α ∈ B is a bijection. Note that X ( f ( α )) = − X ( α ) for each α ∈ B . Therefore, Prob( X = a ) = Prob( X = − a ) for each real a and, thus, X is symmetric. Thus, by Lemmas 1 and 4, we have Prob( X ≥ W (2) / 12 ) &gt; 0. Hence, if W (2) / 12 ≥ k , there is a bijection α : V → { 1 , . . . , n } such that X ( α ) ≥ k and, thus, the answer to LOALB (for both D and H ) is yes . Otherwise, | A | ≤ W (2) &lt; 12 · k 2 . We close this section by outlining how Theorem 1 can be used to actually find a solution to LOALB if one exists. Let ( D, k ) be an instance of LOALB where D = ( V, A ) is a directed graph with integral positive arc-weights and k ≥ 1 is an integer. Let W be the total weight of D . As discussed above, we may assume that D is an oriented graph. If | A | &lt; 12 k 2 then we can find a solution, if one exists, by trying all subsets A ⊆ A , and testing whether ( V, A ) is acyclic and has weight at least W/ 2 + k ; this search can be carried out in time 2 O ( k 2 ) . Next we assume | A | ≥ 12 k 2 . We know by Theorem 1 that ( D, k ) is a yes -instance; it remains to find a solution. For a vertex i ∈ V let d D ( i ) denote its unweighted degree in D , i.e., the number of arcs (incoming or outgoing) that are incident with i . Consider the following reduction rule: Reduction Rule 2 If there is a vertex i ∈ V with | A | − 12 k 2 ≥ d D ( i ) , then delete i from D . Observe that by applying the rule we obtain again a yes -instance ( D − i, k ) of LOALB since D − i has still at least 12 k 2 arcs. Moreover, if we know a solution D i of ( D − i, k ), then we can efficiently obtain a solution D of ( D, k ): if j ∈ N + ( i ) w ij ≥ j ∈ N − ( i ) w ij then we add i and all outgoing arcs ij ∈ A to D i ; otherwise, we add i and all incoming arcs ji ∈ A to D i . After multiple applications of Rule 2 we are left with an instance ( D 0 , k ) to which Rule 2 cannot be applied. Let D 0 = ( V 0 , A 0 ). We pick a vertex i ∈ V 0 . If i has a neighbor j with d D 0 ( j ) = 1, then | A 0 | ≤ 12 k 2 , since | A 0 | − d D 0 ( j ) &lt; 12 k 2 . On the other hand, if d D 0 ( j ) ≥ 2 for all neighbors j of i , then i has less than 2 · 12 k 2 neighbors, since D 0 − i has less than 12 k 2 arcs; thus | A 0 | &lt; 3 · 12 k 2 . Therefore, as above, time 2 O ( k 2 ) is sufficient to try all subsets A 0 ⊆ A 0 to find a solution to the instance ( D 0 , k ). Let n denote the input size of instance ( D, k ). Rule 2 can certainly be applied in polynomial time n O (1) , and we apply it less than n times. Hence, we can find a solution to ( D, k ), if one exists, in time n O (1) + 2 O ( k 2 ) . Recall that a kernelization reduces in polynomial time an instance ( I, k ) of a parameterized problem to a decision-equivalent instance ( I , k ), its problem  kernel , where k ≤ k and the size of I is bounded by a function of k . Solutions for ( I, k ) and solutions for ( I , k ) are possibly unrelated to each other. We call ( I , k ) a faithful problem kernel if from a solution for ( I , k ) we can construct a solution for ( I, k ) in time polynomial in | I | and k . Clearly the above ( D 0 , k ) is a faithful kernel.</p>
      </sec>
      <sec>
         <title>4 Max Lin-2</title>
         <p>Consider a system of m linear equations e 1 , . . . , e m in n variables z 1 , . . . , z n over GF(2), and suppose that each equation e j has a positive integral weight w j , j = 1 , . . . , m . The problem Max Lin-2 asks for an assignment of values to the variables that maximizes the total weight of the satisfied equations. Let W = w 1 + · · · + w m . To see that the total weight of the equations that can be satisfied is at least W/ 2, we describe a simple procedure suggested in [ <xref id="XR53" ref-type="bibr" rid="R12">12</xref>]. We assign values to the variables z 1 , . . . , z n one by one and simplify the system after each assignment. When we wish to assign 0 or 1 to z i , we consider all equations reduced to the form z i = b , for a constant b . Let W be the total weight of all such equations. We set z i := 0, if the total weight of such equations is at least W / 2, and set z i := 1, otherwise. If there are no equations of the form z i = b , we set z i := 0 . To see that the lower bound W/ 2 is tight, consider a system consisting of pairs of equations of the form i ∈ I z i = 1 and i ∈ I z i = 0 where both equations have the same weight. The parameterized complexity of Max Lin-2 parameterized above the tight lower bound W/ 2 was stated by Mahajan, Raman and Sikdar [<xref id="XR54" ref-type="bibr" rid="R15">15</xref>] as an open question: Max Lin-2 Parameterized Above Tight Lower Bound ( LinALB ) Instance: A system S of m linear equations e 1 , . . . , e m in n variables z 1 , . . . , z n over GF(2), each equation e i with a positive integral weight w i , i = 1 , 2 , . . . , m , and a positive integer k . Each equation e j can be written as i ∈ I j z i = b j , where ∅ = I j ⊆ { 1 , . . . , n } . Parameter: The integer k . Question: Is there an assignment of values to the variables z 1 , . . . , z n such that the total weight of the satisfied equations is at least W/ 2 + k , m where W = i =1 w i ? Let r j be the number of variables in equation e j , and let r ( S ) = max m i =1 r j . We are not able to determine whether LinALB is fixed-parameter tractable or not, but we can prove that the following three special cases are fixed-parameter tractable: (1) there is a set U of variables such that each equation contains an odd number of variables from U , (2) there is a constant r such that r ( S ) ≤ r , (3) there is a constant ρ such that any variable appears in at most ρ equations. Notice that in our formulation of LinALB it is required that each equation has a positive integral weight. In a relaxed setting in which an equation may have any positive real number as its weight, the problem is NP-complete even for k = 1 and each r j = 2. Indeed, let each linear equation be of the form z u + z v = 1. Then the problem is equivalent to MaxCut , the problem of finding a cut of total weight at least L in an undirected graph G , where V ( G ) is the set of variables, E ( G ) contains ( z u , z v ) if and only if there is a linear equation z u + z v = 1, and the weight of an edge ( z u , z v ) equals the weight of the corresponding linear equation. The problem MaxCut is a well-known NP- complete problem. Let us transform an instance I of MaxCut into an instance I of the “relaxed” LinALB by replacing the weight w i by w i := w i / ( L − W/ 2). We may assume that L − W/ 2 &gt; 0 since otherwise the instance is immediately seen as a yes -instance. Observe that the new instance I has an assignment of values with total weight at least W / 2 + 1 if and only if I has a cut with total weight at least L . We are done. Let A be the matrix of the coefficients of the variables in S . It is well-known that the maximum number of linearly independent columns of A equals rank A , and such a collection of columns can be found in time polynomial in n and m , using, e.g., the Gaussian elimination on columns [<xref id="XR57" ref-type="bibr" rid="R4">4</xref>]. We have the following reduction rule and supporting lemma.</p>
         <p>Reduction Rule 3 Let A be the matrix of the coefficients of the variables in S , let t = rank A and let columns a i 1 , . . . , a i t of A be linearly independent. Then delete all variables not in { z i 1 , . . . , z i t } from the equations of S . Lemma 5. Let T be obtained from S by Rule 3. Then T is a yes -instance if and only if S is a yes -instance. Moreover, T can be obtained from S in time polynomial in n and m .</p>
         <p>Proof. If t = n , set T := S , so assume that t &lt; n. The remark before the lemma immediately implies that T can be obtained from S in time polynomial in n and m . Let S be a system of equations from S and let T be the corresponding system of equations from T . It is sufficient to prove the following claim: There is an assignment of values to z 1 , . . . , z n satisfying all equations in S and falsifying the rest of equations in S if and only if there is an assignment of values to z i 1 , . . . , z i t satisfying all equations in T and falsifying the rest of equations in T . Let an assignment z 0 of values to z = ( z 1 , . . . , z n ) satisfy all equations of S and falsify the equations of S , where S = S \ S . This assignment satisfies all equations of R , the system obtained from S by replacing the right hand side b j of each equation in S by 1 − b j . Note that R has the same matrix A of coefficients with columns a 1 , . . . , a n . Let a column a i ∈ { a i 1 , . . . , a i t } . Then, by definition of a i 1 , . . . , a i t , a i = λ 1 a i 1 + · · · + λ t a i t for some numbers λ j ∈ { 0 , 1 } . Knowing the numbers λ j , we may eliminate a variable z i from R by replacing a i with the sum of all columns from { a i 1 , . . . , a i t } for which λ j = 1 and carrying out the obvious simplification of the system. Thus, we may eliminate from R all variables z i ∈ { z i 1 , . . . , z i t } and get y i 1 a i 1 + · · · + y i t a i t = b , where b is the right hand side of R and each y j ∈ { 0 , 1 } . Now replace, in the modified R , the right hand side b j of each equation corresponding to an equation in S by 1 − b j  obtaining T . Clearly, ( y i 1 , . . . , y i t ) satisfies all equations of T and falsifies all equations in T = T \ T . Suppose now that ( y i 1 , . . . , y i t ) satisfies all equations of T and falsifies all equations in T . Then ( y 1 , . . . , y n ), where y j = 0 if j ∈ { i 1 , . . . , i t } , satisfies all equations of S and falsifies all equations in S . Thus, the claim has been proved. Consider the following reduction rule for LinALB used in [<xref id="XR62" ref-type="bibr" rid="R12">12</xref>]. Reduction Rule 4 If we have, for a subset I of { 1 , 2 , . . . , n } , the equation i ∈ I z i = b with weight w , and the equation i ∈ I z i = b with weight w , then we replace this pair by one of these equations with weight w + w if b = b and, otherwise, by the equation whose weight is bigger, modifying its new weight to be the difference of the two old ones. If the resulting weight is 0, we omit the equation from the system. If Rule 4 is not applicable to a system we call the system reduced under Rule 4 . Note that the problem LinALB for S and the system obtained from S by applying Rule 4 as long as possible have the same answer. Let I j ⊆ { 1 , . . . , n } be the set of indices of the variables participating in equation e j , and let b j ∈ { 0 , 1 } be the right hand side of e j . Define a random variable X = m j =1 X j , where X j = ( − 1) b j w j i ∈ I j i and all the i are independent uniform random variables on {− 1 , 1 } ( X was first introduced in [<xref id="XR63" ref-type="bibr" rid="R12">12</xref>]). We set z i = 0 if i = 1 and z i = 1, otherwise, for each i . Observe that X j = w j if e j is satisfied and X j = − w j , otherwise. Lemma 6. Let S be reduced under Rule 4. The weight of the satisfied equations is at least W/ 2 + k if and only if X ≥ 2 k . We have E ( X ) = 0 and E ( X 2 ) = m j =1 w j 2 . Proof. Observe that X is the difference between the weights of satisfied and falsified equations. Therefore, the weight of the satisfied equations equals ( X + W ) / 2, and it is at least W/ 2 + k if and only if X ≥ 2 k . Since i are independent, E ( i ∈ I j i ) = i ∈ I j E ( i ) = 0. Thus, E ( X j ) = 0 and E ( X ) = 0 by linearity of expectation. Moreover, m m E ( X 2 ) = E ( X j 2 )+ E ( X j X q ) = w j 2 &gt; 0 j =1 1 ≤ j = q ≤ m j =1</p>
         <p>as E ( i ∈ I j i · i ∈ I q i ) = E ( i ∈ I j ∆I q i ) = 0 implies E ( X j X q ) = 0 , where I j ∆I q is the symmetric difference between I j and I q ( I j ∆I q = ∅ due to Rule 4). Lemma 7. Let S be reduced under Rule 4 and suppose that no variable appears in more than ρ ≥ 2 equations of S . Then E ( X 4 ) ≤ 2 ρ 2 ( E ( X 2 )) 2 . Proof. Observe that</p>
         <p>where [ m ] = { 1 , . . . , m } . Note that if the product X p X q X s X t contains a variable i in only one or three of the factors, then E ( X p X q X s X t ) = A · E ( i ) = 0 , where A is a polynomial in random variables l , l ∈ { 1 , . . . , n } \ { i } . Thus, the only nonzero terms in (2) are those for which either (1) p = q = s = t , or (2) there are two distinct integers j, l such that each of them coincides with two elements in the sequence p, q, s, t , or (3) |{ p, q, s, t }| = 4, but each variable i appears in an even number of the factors in X p X q X s X t . In Cases 1 and 2, we have E ( X p X q X s X t ) = w p 4 and E ( X p X q X s X t ) = w j 2 w l 2 , respectively. In Case 3, E ( X p X q X s X t ) ≤ w p w q w s w t ≤ ( w p 2 w q 2 + w s 2 w t 2 ) / 2 . Let 1 ≤ j &lt; l ≤ m . Observe that E ( X p X q X s X t ) = w j 2 w l 2 in Case 2 for 4 = 6 4-tuples ( p, q, s, t ) ∈ [ m ] 4 . In Case 3, we claim that j, l ∈ { p, q, s, t } for 2 at most 4 · ( ρ − 1) 2 4-tuples ( p, q, s, t ) ∈ [ m ] 4 . To see this, first note that w p 2 w q 2 and w s 2 w t 2 appear in our upper bound on E ( X p X q X s X t ) (with coefficient 1/2). Therefore, there are only four possible ways for w j 2 w l 2 to appear in our upper bound, namely the following: (i) j = p, l = q , (ii) l = p, j = q , (iii) j = s, l = t , and (iv) l = s, j = t. Now assume, without loss of generality, that j = p and l = q . Since S is reduced under Rule 4, the product X j X l must have a variable i of degree one. Thus, i must be in X s or X t , but not in both (two choices). Assume that i is in X s . Observe that there are at most ρ − 1 choices for s . Note that X j X l X s must contain contain a variable i of odd degree. Thus, i must be in X t and, hence, there are at most ρ − 1 choices for t . Therefore, we have m  m  2 E ( X 4 ) ≤ w j 4 + (6 + 4( ρ − 1) 2 ) w j 2 w l 2 &lt; 2 ρ 2  w j 2  . j =1 1 ≤ j&lt;l ≤ m j =1  Thus, by Lemma 6, E ( X 4 ) ≤ 2 ρ 2 ( E ( X 2 )) 2 . Case 1 of Theorem 2 is of interest since its condition can be checked in polynomial time due to the following:</p>
         <p>Proposition 1. We can check, in polynomial time, whether there exists a set U of variables such that each equation of S contains an odd number of variables from U .</p>
         <p>Proof. Observe that such a set U exists if and only if the unweighted system S of linear equations over GF(2) obtained from S by replacing each b j with 1 has a solution. Indeed, if U exists, set z j = 1 for each z j ∈ U and z j = 0 for each z j ∈ U . This assignment is a solution to S . If a solution to S exists, form U by including in it all variables z j which equal 1 in the solution. We can check whether S has a solution using the Gaussian elimination or other polynomial- time algorithms, see, e.g., [<xref id="XR72" ref-type="bibr" rid="R6">6</xref>]. Now we can prove the following: Theorem 2. Let S be reduced under Rule 4. The following three special cases of LinALB are fixed-parameter tractable: (1) there is a set U of variables such</p>
         <p>that each equation contains an odd number of variables from U , (2) there is a constant r such that r ( S ) ≤ r , (3) there is a constant ρ , such that any variable appears in at most ρ equations. In each case, there exists a kernel with O ( k 2 ) equations and variables.</p>
         <p>Proof. Case 1. Let z 0 = ( z 1 0 , . . . , z n 0 ) ∈ { 0 , 1 } n be an assignment of values to the variables z 1 , . . . , z n , and let − z 0 = ( z 1 , . . . , z n ) , where z i = 1 − z i 0 if z i ∈ U and z i = z i 0 , otherwise, i = 1 , . . . , n. Observe that f : z 0 → − z 0 is a bijection on the set of assignments and X ( − z 0 ) = − X ( z 0 ). Thus, √ X is a symmetric random variable. Therefore, by Lemmas 1 and 6, Prob( X ≥ m ) ≥ Prob( X ≥ m j =1 w j 2 ) &gt; 0 . Hence, if √ m ≥ 2 k , the answer to LinALB is yes . Otherwise, m &lt; 4 k 2 and after applying Rule 3, we obtain a kernel with O ( k 2 ) equations and variables. Case 2. Since X is a polynomial of degree at most r , it follows by Lemma 3 that E ( X 4 ) ≤ 2 6 r E ( X 2 ) 2 . This inequality and the results in the previ- Prob ous paragraph X &gt; √ P 4 show m j · 8 =1 r w j 2 that &gt; the 0 , conditions implying of Prob Lemma X &gt; 2 4 √ · 8 m are r satisfied &gt; 0 . Consequently, and, thus, √ if 2 k − 1 ≤ m/ (4 · 8 r ), then there is an assignment of values to the variables z 1 , . . . , z n √ which satisfies equations of total weight at least W/ 2 + k . Otherwise, 2 k − 1 &gt; m/ (4 · 8 r ) and m &lt; 16(2 k − 1) 2 64 r . After applying Rule 3, we obtain the required kernel. Case 3. If ρ = 1, it is easy to find an assignment to the variables that satisfies all equations of S . Thus, we may assume that ρ ≥ 2 . To prove that there exists a kernel with O ( k 2 ) equations, we can proceed as in Case 2, but use Lemma 7 rather than Lemma 3. Remark 1. Note that even if S does not satisfy Case 2 of the theorem, T , the system obtained from S using Rule 3, may still satisfy Case 2. However, we have not formulated the theorem for S reduced under Rule 3 as the reduced system depends on the choice of a maximum linear independent collection of columns of A .</p>
      </sec>
      <sec>
         <title>5 Discussions</title>
         <p>We have showed that the new method allows us to prove that some maximization problems parameterized above tight lower bounds are fixed-parameter tractable. Our method can also be used for minimization problems parameterized below tight upper bounds. As a simple example, consider the feedback arc problem: given a digraph D = ( V, A ) find a minimum set F of arcs such that D − F is acyclic. Certainly, | A | / 2 is a tight upper bound on a minimum feedback set and we can consider the parameterized problem which asks whether D has a feedback arc set with at most | A | / 2 − k arcs. Fixed-parameter tractability of this parameterized problem follows immediately from fixed-parameter tractability  of LOALB, but we could prove this result directly using essentially the same approach as for LOALB. Theorem 2.1 in [<xref id="XR80" ref-type="bibr" rid="R1">1</xref>] allows one to obtain a smaller kernel for LOALB on dense digraphs than given in our paper. The proof of Theorem 2.1 in [<xref id="XR81" ref-type="bibr" rid="R1">1</xref>] also uses a probabilistic approach, but it is more specialized than SABEM. It would be interesting to obtain applications of our method to other problems parameterized above tight lower bounds or below tight upper bounds. One such very recent application is given in [<xref id="XR82" ref-type="bibr" rid="R9">9</xref>], where an open problem due to Benny Chor and described in [<xref id="XR83" ref-type="bibr" rid="R16">16</xref>] was solved. Acknowledgments. Research of Gutin, Kim and Yeo was supported in part by an EPSRC grant.</p>
      </sec>
      <sec>
         <title>References</title>
      </sec>
   </body>
   <back>
      <ref-list>
         <ref id="R1">
            <mixed-citation>1. N. Alon, Voting paradoxes and digraphs realizations. Advances in Applied Math. , 29:126–135, 2002.</mixed-citation>
         </ref>
         <ref id="R2">
            <mixed-citation>2. N. Alon, G. Gutin, and M. Krivelevich. Algorithms with large domination ratio. J. Algorithms , 50(1):118–131, 2004.</mixed-citation>
         </ref>
         <ref id="R3">
            <mixed-citation>3. J. Bang-Jensen and G. Gutin. Digraphs: Theory, Algorithms and Applications . Springer-Verlag, London, 2nd edition, 2009.</mixed-citation>
         </ref>
         <ref id="R4">
            <mixed-citation>4. T. S. Blyth and E. F. Robertson, Basic Linear Algebra , Springer, 2000.</mixed-citation>
         </ref>
         <ref id="R5">
            <mixed-citation>5. J. Bourgain. Walsh subspaces of L p -product spaces. In Seminar on Functional Analysis, 1979–1980 (French) . Ecole  ́ Polytech., Palaiseau, 1980. Exp. No. 4A, 9.</mixed-citation>
         </ref>
         <ref id="R6">
            <mixed-citation>6. D. Coppersmith. Solving linear systems over GF(2): block Lanczos algorithm. Lin. Algebra Applic. , 192:33–60, 1993.</mixed-citation>
         </ref>
         <ref id="R7">
            <mixed-citation>7. R. G. Downey and M. R. Fellows, Parameterized Complexity , Springer, 1999.</mixed-citation>
         </ref>
         <ref id="R8">
            <mixed-citation>8. J. Flum and M. Grohe. Parameterized Complexity Theory , volume XIV of Texts in Theoretical Computer Science. An EATCS Series . Springer Verlag, 2006.</mixed-citation>
         </ref>
         <ref id="R9">
            <mixed-citation>9. G. Gutin, E. J. Kim, M. Mnich, and A. Yeo. Ordinal Embedding Relaxations Parameterized Above Tight Lower Bound. Tech. Report arXiv:0907.5427.</mixed-citation>
         </ref>
         <ref id="R10">
            <mixed-citation>10. G. Gutin, A. Rafiey, S. Szeider, and A. Yeo. The linear arrangement problem parameterized above guaranteed value. Theory Comput. Syst. , 41:521–538, 2007.</mixed-citation>
         </ref>
         <ref id="R11">
            <mixed-citation>11. G. Gutin, S. Szeider, and A. Yeo. Fixed-parameter complexity of minimum profile problems. Algorithmica , 52(2):133–152, 2008.</mixed-citation>
         </ref>
         <ref id="R12">
            <mixed-citation>12. J. H ̊ astad and S. Venkatesh. On the advantage over a random assignment. In Pro- ceedings of the Thirty-Fourth Annual ACM Symposium on Theory of Computing , pages 43–52, New York, 2002. ACM. Full version appeared in Random Structures Algorithms 25(2) (2004), pp. 117–149.</mixed-citation>
         </ref>
         <ref id="R13">
            <mixed-citation>13. P. Heggernes, C. Paul, J. A. Telle, and Y. Villanger. Interval completion with few edges. In STOC’07—Proceedings of the 39th Annual ACM Symposium on Theory of Computing , pages 374–381. ACM, 2007. Full version appeared in SIAM J. Comput. 38(5), 2008/09.</mixed-citation>
         </ref>
         <ref id="R14">
            <mixed-citation>14. M. Mahajan and V. Raman. Parameterizing above guaranteed values: MaxSat and MaxCut. J. Algorithms , 31(2):335–354, 1999.</mixed-citation>
         </ref>
         <ref id="R15">
            <mixed-citation>15. M. Mahajan, V. Raman, and S. Sikdar. Parameterizing above or below guaranteed values. J. of Computer and System Sciences , 75(2):137–153, 2009.</mixed-citation>
         </ref>
         <ref id="R16">
            <mixed-citation>16. R. Niedermeier. Invitation to Fixed-Parameter Algorithms . Oxford Lecture Series in Mathematics and its Applications. Oxford University Press, 2006.</mixed-citation>
         </ref>
         <ref id="R17">
            <mixed-citation>17. V. Vovk, Private communication, August, 2009.</mixed-citation>
         </ref>
      </ref-list>
   </back>
</article>