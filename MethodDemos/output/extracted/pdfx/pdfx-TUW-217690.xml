<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>92391c0f49d4bb064ae2b420cff26b50f437887cc250a6baf94493a7858ec317</job>
    <base_name>l48</base_name>
    <doi>http://dx.doi.org/10.1109/vr.2013.6549441</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <title-group>
        <article-title class="DoCO:Title" id="1">Parallel Tracking and Mapping in Hofburg Festsaal</article-title>
      </title-group>
      <region class="unknown" id="2">Georg Gerstweiler* Hannes Kaufmann Olga Kosyreva Christian Schönauer Interactive Media Systems Group, Vienna University of Technology</region>
      <region class="DoCO:FigureBox" id="F1">
        <image class="DoCO:Figure" src="l48.page_001.image_01.png" thmb="l48.page_001.image_01-thumb.png"/>
        <caption class="deo:Caption" id="4">Figure 1: A user with the mobile setup in Festsaal (left) and a virtual theater stage placed on the real stage (right).</caption>
      </region>
    </front>
    <body class="DoCO:BodyMatter">
      <region class="DoCO:TextChunk" id="5" page="1" column="1">A BSTRACT Precise localization for mobile Augmented Reality in large indoor environments without specific tracking infrastructure is challenging. This is especially true for rooms with changing properties, like lighting, seating and carpeting. With these constraints a map for a vision based tracking approach has to be continuously updated. The Parallel Tracking and Mapping (PTAM) algorithm is capable of generating and extending a map while tracking the camera pose in an unknown environment. However, it has originally been designed for small workspace environments and has therefore certain limitations. We have extended and modified the original implementation in order to ensure efficient and robust map generation and tracking in large rooms. Furthermore, we have tested a mobile setup with the system in Festsaal in Vienna’s Hofburg, which is close to thousand square meters in size. The user’s position and path was tracked while the environment was augmented with virtual objects and the system was successfully tested for robustness and occlusions.</region>
      <region class="DoCO:TextChunk" id="7" confidence="possible" page="1" column="1">Keywords : Tracking, and mapping, augmented, and virtual realities Index Terms : H.5.1 [Multimedia Information Systems]: Artificial, augmented, and virtual realities—; I.4.8 [Scene Analysis]: Object Recognition—Tracking * <email id="6">gerstweiler/kaufmann/kosyreva/schoenauer/vonach@ims.tuwien.ac.at</email></region>
      <region class="unknown" id="8" page="1" column="2">Emanuel Vonach</region>
      <region class="DoCO:TextChunk" id="14" page="1" column="2">1 I NTRODUCTION Vienna’s historic Hofburg accommodates many grandiose rooms, the largest of which is Festsaal. These premises are being used as venues for exhibitions, conferences and cultural events. In this context our project partner, the Wiener Kongresszentrum Hofburg, is interested in providing visitors with audio/video information about the current room or paintings on walls and ceilings (frescos) as well as different room configurations on a mobile device. Furthermore, a visualization of the current position on a map can aid navigation within Hofburg. This can be helpful to find a certain conference booth or another person during an event (e.g. a ball). The rooms of the Hofburg are rich of features on walls and ceilings, which makes them well-suited for a computer vision- based approach. However, changes in lighting, seating, carpeting and other changing elements like conference booths pose certain restrictions. Therefore, we favor PTAM [ <xref ref-type="bibr" rid="R1" id="9" class="deo:Reference">1</xref>], which doesn’t require any fiducial markers or models for pose estimation, over model- based approaches.<marker type="block"/> 2 S YSTEM &amp; W ORKFLOW Our test platform was a dual-core laptop with an off-the-shelf webcam. The software was based on Castle and Klein’s PTAM implementation [<xref ref-type="bibr" rid="R2" id="11" class="deo:Reference">2</xref>] with several extensions and modifications to ensure efficient and robust map generation and tracking in large rooms. In a first stage the system was used to create a detailed map in a semi-automatic procedure, while walking through the room. Our adaptations made this process more efficient by improving the selection of features and keyframes, resulting in a more precise map while using less keyframes. New interface methods allow manual intervention to avoid structures, which shouldn't be integrated in the map (e.g. falsework present in Festsaal during<marker type="page" number="2"/><marker type="column" number="1"/><marker type="block"/> first tests, or chandeliers, which are problematic due to their complicated structure and reflective properties). In addition, we have modified the constraints of the original algorithm to allow tracking behind the user's original position. New constraints maintain efficiency in the larger environment for example by avoiding high feature density in certain areas and removal of features outside the basic cubical shape of the room.<marker type="block"/> 3 R ESULTS &amp; C ONCLUSION We have tested our mobile setup in Festsaal and created a detailed map. Once the camera pose was available, the environment was augmented with various virtual content. In a first test we added a virtual theater stage and walked around it. The position and scaling of the scene was robust, while the frame-rate remained close to the update-rate of the camera. In addition, we added a virtual furniture set, which showed similar results. Another important use case was tracking of a user within the map. Therefore, we reconstructed the path of the user frame-by-frame in real-time. Another test demonstrated the system's behavior despite rapid camera movement and occlusions. During first tests in Festsaal there was a falsework in the middle of the room. While massive occlusions pose problems on any vision-based tracking system, with limited occlusions the tracking remained robust in many cases.</region>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="15" confidence="possible" page="2" column="1">R EFERENCES</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="16" confidence="possible" page="2" column="1">[1] Georg Klein and David Murray, Parallel Tracking and Mapping for Small AR Workspaces. In Proc. International Symposium on Mixed and Augmented Reality (ISMAR'07, Nara), 2007.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="17" confidence="possible" page="2" column="1">[2] R. O. Castle, G. Klein, and D. W. Murray. Video-rate localization in multiple maps for wearable augmented reality. In Proc. 12th IEEE Int. Symp. on Wearable Computing, Pittsburgh PA, pages 15–22, 2008.</ref>
        </ref-list>
      </section>
    </body>
  </article>
</pdfx>
