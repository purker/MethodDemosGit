<?xml version='1.0' encoding='UTF-8'?>
<pdfx xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://pdfx.cs.man.ac.uk/static/article-schema.xsd">
  <meta>
    <job>16e4de08db9c2fb0309524b2ea3f5b764b27ba4d0e8a6ec45f98a53b0164754e</job>
    <base_name>l3h</base_name>
    <doi>10.4204/EPTCS.15.5</doi>
    <warning>Name identification was not possible. </warning>
  </meta>
  <article>
    <front class="DoCO:FrontMatter">
      <title-group>
        <article-title class="DoCO:Title" id="1">Extending Context-Sensitivity in Term Rewriting</article-title>
      </title-group>
      <region class="unknown" id="2">Bernhard Gramlich and Felix Schernhammer ∗ Institute of Computer Languages, Theory and Logic Group Vienna University of Technology { gramlich,felixs } @logic.at</region>
      <abstract class="DoCO:Abstract" id="3" confidence="possible">We propose a generalized version of context-sensitivity in term rewriting based on the notion of “forbidden patterns”. The basic idea is that a rewrite step should be forbidden if the redex to be contracted has a certain shape and appears in a certain context. This shape and context is expressed through forbidden patterns. In particular we analyze the relationships among this novel approach and the commonly used notion of context-sensitivity in term rewriting, as well as the feasibility of rewriting with forbidden patterns from a computational point of view. The latter feasibility is characterized by demanding that restricting a rewrite relation yields an improved termination behaviour while still being powerful enough to compute meaningful results. Sufficient criteria for both kinds of properties in certain classes of rewrite systems with forbidden patterns are presented.</abstract>
    </front>
    <body class="DoCO:BodyMatter">
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="4" page="1" column="1">1 Introduction and Overview</h1>
      </section>
      <region class="DoCO:TextChunk" id="6" page="1" column="1">Standard term rewriting systems (TRSs) are well-known to enjoy nice logical and closure properties. Yet, from an operational and computational point of view, i.e., when using term rewriting as computational model, it is also well-known that for non-terminating systems restricted versions of rewriting obtained by imposing context-sensitivity and/or strategy requirements may lead to better results (e.g., in terms of computing normal forms, head-normal forms, etc.). One major goal when using reduction strategies and context restrictions is to avoid non-terminating reductions. On the other hand the restrictions should not be too strong either, so that the ability to compute useful results in the restricted rewrite systems is not lost. We introduce a novel approach to context restrictions relying on the notion of “forbidden patterns”, which generalizes existing approaches and succeeds in handling examples in the mentioned way (i.e., producing a terminating reduction relation which is powerful enough to compute useful results) where others fail. The following example motivates the use of reduction strategies and/or context restrictions. Example 1. Consider the following rewrite system, cf. e.g. [<xref ref-type="bibr" rid="R15" id="5" class="deo:Reference">15</xref>]:</region>
      <region class="DoCO:TextChunk" id="7" confidence="possible" page="1" column="1">inf ( x ) → x : inf ( s ( x )) 2nd ( x : ( y : zs )) → y</region>
      <region class="DoCO:TextChunk" id="33" page="1" column="1">This TRS is non-terminating and not even weakly normalizing. Still some terms like 2nd ( inf ( x )) are reducible to a normal form while also admitting infinite reduction sequences. One goal of context restrictions and reduction strategies is to restrict derivations in a way such that normal forms can be computed whenever they exist, while infinite reductions are avoided. One way to address the problem of avoiding non-normalizing reductions in Example 1 is the use of reduction strategies. For instance for the class of (almost) orthogonal rewrite systems (the TRS of ∗ This author has been supported by the Austrian Academy of Sciences under grant 22.361. <marker type="page" number="2"/><marker type="block"/> Example 1 is orthogonal), always contracting all outermost redexes in parallel yields a normalizing strategy (i.e. whenever a term can be reduced to a normal form it is reduced to a normal form under this strategy) [<xref ref-type="bibr" rid="R18" id="12" class="deo:Reference">18</xref>]. Indeed, one can define a sequential reduction strategy having the same property for an even wider class of TRSs [<xref ref-type="bibr" rid="R3" id="13" class="deo:Reference">3</xref>]. One major drawback (or asset depending on one’s point of view) of using reduction strategies, however, is that their use does not introduce new normal forms. This means that the set of normal forms w.r.t. to some reduction relation is the same as the set of normal forms w.r.t. to the reduction relation under some strategy. Hence, strategies can in general not be used to detect non- normalizing terms or to impose termination on not weakly normalizing TRSs (with some exceptions cf. e,g. [3, Theorem 7.4]). Moreover, the process of selecting a suitable redex w.r.t. to a reduction strategy is often complex and may thus be inefficient. These shortcomings of reduction strategies led to the advent of proper restrictions of rewriting that usually introduce new normal forms and select respectively forbid certain reductions according to the syntactic structure of a redex and/or its surrounding context. The most well-known approach to context restrictions is context-sensitive rewriting. There, a replacement map μ specifies the arguments μ ( f ) ⊆ { 1 , . . . , ar ( f ) } which can be reduced for each function f . However, regarding Example 1, context-sensitive rewriting does not improve the situation, since allowing the reduction of the second argument of ‘:’ leads to non-termination, while disallowing its reduction leads to incompleteness in the sense that for instance a term like 2nd ( inf ( x )) cannot be normalized via the corresponding context-sensitive reduction relation, despite having a normal form in the unrestricted system. Other ideas of context restrictions range from explicitly modeling lazy evaluation (cf. e.g. [<xref ref-type="bibr" rid="R9" id="14" class="deo:Reference">9</xref>, <xref ref-type="bibr" rid="R17" id="15" class="deo:Reference">17</xref>, <xref ref-type="bibr" rid="R19" id="16" class="deo:Reference">19</xref>]), to imposing constraints on the order of argument evaluation of functions (cf. e.g. [<xref ref-type="bibr" rid="R10" id="17" class="deo:Reference">10</xref>, <xref ref-type="bibr" rid="R7" id="18" class="deo:Reference">7</xref>]), and to combinations of these concepts, also with standard context-sensitive rewriting (cf. e.g. [<xref ref-type="bibr" rid="R15" id="19" class="deo:Reference">15</xref>, <xref ref-type="bibr" rid="R2" id="20" class="deo:Reference">2</xref>]). The latter generalized versions of context-sensitive rewriting are quite expressive and powerful (indeed some of them can be used to restrict the reduction relation of the TRS in Example 1 in a way, so that the restricted relation is terminating and still powerful enough to compute (head-)normal forms), but on the other hand tend to be hard to analyze and understand, due the subtlety of the strategic information specified. The approach we present in this paper is simpler in that its definition only relies on matching and simple comparison of positions rather than on laziness or prioritizing the evaluation of certain arguments of functions over others. In order to reach the goal of restricting the reduction relation in such a way that it is terminating while still being powerful enough to compute useful results, we provide a method to verify termination of a reduction relation restricted by our approach (Section 5) as well as a criterion which guarantees that normal forms computed by the restricted system are head-normal forms of the unrestricted system (Section 4). Recently it turned out that, apart from using context-sensitivity as computation model for standard term rewriting (cf. e.g. [<xref ref-type="bibr" rid="R16" id="21" class="deo:Reference">16</xref>, <xref ref-type="bibr" rid="R14" id="22" class="deo:Reference">14</xref>]), context-sensitive rewrite systems naturally also appear as intermediate representations in many areas relying on transformations, such as program transformation and termination analysis of rewrite systems with conditions [<xref ref-type="bibr" rid="R6" id="23" class="deo:Reference">6</xref>, <xref ref-type="bibr" rid="R20" id="24" class="deo:Reference">20</xref>] / under strategies [<xref ref-type="bibr" rid="R8" id="25" class="deo:Reference">8</xref>]. This suggests that apart from using restrictions as guidance and thus as operational model for rewrite derivations, a general, flexible and well-understood framework of restricted term rewriting going beyond context-sensitive rewriting may be useful as a valuable tool in many other areas, too. The major problem in building such a framework is that imposing context restrictions on term rewriting in general invalidates the closure properties of term rewriting relations, i.e., stability under contexts and substitutions. Note that in the case of context-sensitive rewriting à la [<xref ref-type="bibr" rid="R14" id="26" class="deo:Reference">14</xref>, <xref ref-type="bibr" rid="R16" id="27" class="deo:Reference">16</xref>] only stability under contexts is lost.<marker type="page" number="3"/><marker type="block"/> In this work we will sketch and discuss a generalized approach to context-sensitivity (in the sense of [<xref ref-type="bibr" rid="R14" id="31" class="deo:Reference">14</xref>, <xref ref-type="bibr" rid="R16" id="32" class="deo:Reference">16</xref>]) relying on forbidden patterns rather than on forbidden arguments of functions. From a systematic point of view we see the following design decisions to be made. • What part of the context of a (sub)term is relevant to decide whether the (sub)term may be reduced or not? • In order to specify the restricted reduction relation, is it better/advantageous to explicitly define the allowed or the forbidden part of the context-free reduction relation? • What are the forbidden/allowed entities, for instance whole subterms, contexts, positions, etc.? • Does it depend on the shape of the considered subterm itself (in addition to its outside context) whether it should forbidden or not (if so, stability under substitutions may be lost)? • Which restrictions on forbidden patterns seem appropriate (also w.r.t. practical feasibility) in order to guarantee certain desired closure and preservation properties. The remainder of the paper is structured as follows. In Section 2 we briefly recall some basic notions and notations. Rewriting with forbidden patterns is defined, discussed and exemplified in Section 3. In the main Sections 4 and 5 we develop some theory about the expressive power of rewriting with forbidden patterns (regarding the ability to compute original (head-)normal forms), and about how to prove ground termination for such systems via a constructive transformational approach. Crucial aspects are illustrated with the two running Examples 1 and 3. Finally, in Section 6 we summarize our approach and its application in the examples, discuss its relationship to previous approaches and briefly touch the important perspective and open problem of (at least partially) automating the generation of suitable forbidden patterns in practice. 1</region>
      <outsider class="DoCO:TextBox" type="footer" id="9" page="1" column="1">M. Fernandez (Ed.): 9th Int. Workshop on Reduction Strategies in Rewriting and Programming (WRS’09) EPTCS 15, 2010, pp. 56–68, doi:10.4204/EPTCS.15.5</outsider>
      <outsider class="DoCO:TextBox" type="header" id="10" page="2" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="11" page="2" column="1">57</outsider>
      <outsider class="DoCO:TextBox" type="page_nr" id="29" page="3" column="1">58</outsider>
      <outsider class="DoCO:TextBox" type="header" id="30" page="3" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="34" page="3" column="1">2 Preliminaries</h1>
        <region class="DoCO:TextChunk" id="39" page="3" column="1">We assume familiarity with the basic notions and notations in term rewriting, cf. e.g. [<xref ref-type="bibr" rid="R4" id="35" class="deo:Reference">4</xref>], [<xref ref-type="bibr" rid="R5" id="36" class="deo:Reference">5</xref>]. Since we develop our approach in a many-sorted setting, we recall a few basics on many-sorted equational reasoning (cf. e.g. [<xref ref-type="bibr" rid="R5" id="37" class="deo:Reference">5</xref>]). A many-sorted signature F is a pair ( S , Ω ) where S is a set of sorts and Ω is a family of (mutually disjoint) sets of typed function symbols: Ω = ( Ω ω , s | ω ∈ S ∗ , s ∈ S ) . We also say, f is of type ω → s (or just s if ω = 0) / if f ∈ Ω ω , s . V = ( V s | s ∈ S ) is a family of (mutually disjoint) countably infinite sets of typed variables (with V ∩ Ω = 0). / The set T ( F , V ) s of (well-formed) terms of sort s is the least set containing V s , and whenever f ∈ Ω ( s 1 ,..., s n ) , s and t i ∈ T ( F , V ) s i for all 1 ≤ i ≤ n , then f ( t 1 , . . . , t n ) ∈ T ( F , V ) s . The sort of a term t is denoted by sort ( t ) . Rewrite rules are pairs of terms l → r where sort ( l ) = sort ( r ) . Subsequently, we make the types of terms and rewrite rules explicit only if they are relevant. Throughout the paper x , y , z represent (sorted) variables. Positions are possibly empty sequences of natural numbers (the empty sequence is denoted by ε ). We use the standard partial order ≤ on positions given by p ≤ q if there is some position p ′ , such that p . p ′ = q (i.e., p is a prefix of q ). Pos ( s ) ( Pos F ( s ) ) denotes the set of (non-variable) positions of a term p s . By s → t we mean rewriting at position p . Given a TRS R = ( F , R ) we partition F into the set D of defined function symbols, which are those that occur as root symbols of left-hand sides of rules in R , and the set C of constructors (given by F \ D ). For TRSs R = ( F , R ) we sometimes confuse R and R , e.g., by omitting the signature. 1 Due to lack of space the obtained results are presented without proofs. The latter can be found in the full technical report version of the paper, cf. <ext-link ext-link-type="uri" href="http://www.logic.at/staff/" id="38">http://www.logic.at/staff/</ext-link> { gramlich,schernhammer } / .</region>
        <outsider class="DoCO:TextBox" type="header" id="40" page="4" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="41" page="4" column="1">59</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="42" page="4" column="1">3 Rewriting with Forbidden Patterns</h1>
        <region class="DoCO:TextChunk" id="47" page="4" column="1">In this section we define a generalized approach to rewriting with context restrictions relying on term patterns to specify forbidden subterms/superterms/positions rather than on a replacement map as in context- sensitive rewriting. Definition 1 (forbidden pattern) . A forbidden pattern (w.r.t. to a signature F ) is a triple t , p , λ , where t ∈ T ( F , V ) is a term, p a position from Pos ( t ) and λ ∈ { h , b , a } . The intended meaning of the last component λ is to indicate whether the pattern forbids reductions • exactly at position p , but not outside (i.e., strictly above or parallel to p ) or strictly below – ( h for here), or • strictly below p , but not at or outside p – ( b for below), or • strictly above position p , but not at, below or parallel to p – ( a for above). Abusing notation we sometimes say a forbidden pattern is linear, unifies with some term etc. when we actually mean that the term in the first component of a forbidden pattern has this property. We denote a finite set of forbidden patterns for a signature F by Π F or just Π if F is clear from the context or irrelevant. For brevity, patterns of the shape , , h / b / a are also called h / b / a -patterns, or here / below / above -patterns. 2 Note that if for a given term t we want to specify more than just one restriction by a forbidden pattern, this can easily be achieved by having several triples of the shape t , , . In contrast to context-sensitive rewriting, where a replacement map defines the allowed part of the reduction, the patterns are supposed to explicitly define its forbidden parts, thus implicitly yielding allowed reduction steps as those that are not forbidden. Definition 2 (forbidden pattern reduction relation) . Let R = ( F , R ) be a TRS with forbidden patterns Π F . The forbidden pattern reduction relation → R , Π F , or → Π for short, induced by some set of forbidden patterns Π and R , is given by s → R , Π F t if s → p R t for some p ∈ Pos F ( s ) such that there is no pattern u , q , λ ∈ Π F , no context C and no position q ′ with • s = C [ u σ ] q ′ and p = q ′ . q, if λ = h, • s = C [ u σ ] q ′ and p &gt; q ′ . q, if λ = b, and • s = C [ u σ ] q ′ and p &lt; q ′ . q, if λ = a. Note that for a finite rewrite system R (with finite signature F ) and a finite set of forbidden patterns Π F it is decidable whether s → R , Π F t for terms s and t . We write ( R , Π ) for rewrite systems with associated forbidden patterns. Such a rewrite system ( R , Π ) is said to be Π -terminating (or just terminating if no confusion arises) if → R , Π is well-founded. We also speak of Π -normal forms instead of → R , Π -normal forms. Special degenerate cases of ( R , Π ) include e.g. Π = 0 / where → R , Π = → R , and Π = { l , ε , h | l → r ∈ R } where → R , Π = 0. / In the sequel we use the notions of allowed and forbidden (by Π ) redexes. A redex s | p of a term s is p allowed if s → Π t for some term t , and forbidden otherwise. <marker type="page" number="5"/><marker type="block"/> Example 2. Consider the TRS from Example 1. If Π = { ( x : ( y : inf ( z )) , 2 . 2 , h ) } , then → Π can automatically be shown to be terminating. Moreover, → Π is powerful enough to compute original head-normal forms if they exist (cf. Examples 6 and 11 below). Example 3. Consider the non-terminating TRS R given by take ( 0 , y : ys ) → y app ( nil , ys ) → ys take ( s ( x ) , y : ys ) → take ( x , ys ) app ( x : xs , ys ) → x : app ( xs , ys ) take ( x , nil ) → 0 inf ( x ) → inf ( s ( x )) with two sorts S = { Nat , NatList } , where the types of function symbols are as follows: nil : NatList, 0 : Nat, s : Nat → Nat, : is of type Nat , NatList → NatList, inf : Nat → NatList, app : NatList , NatList → NatList and take : Nat , NatList → Nat. If one restricts rewriting in R via Π given by x : inf ( y ) , 2 , h x : app ( inf ( y ) , zs ) , 2 . 1 , h x : app ( y : app ( z , zs ) , us ) , 2 , h , then → Π is terminating and still every well-formed ground term can be normalized with the restricted relation → Π (provided the term is normalizing). See Examples 7 and 12 below for justifications of these claims. Several well-known approaches to restricted term rewriting as well as to rewriting guided by reduction strategies occur as special cases of rewriting with forbidden patterns. In the following we provide some examples. Context-sensitive rewriting, where a replacement map μ specifies the arguments μ ( f ) ⊆ { 1 , . . . , ar ( f ) } which can be reduced for each function f , arises as special case of rewriting with forbidden patterns by defining Π to contain for each function symbol f and each j ∈ { 1 , . . . , ar ( f ) }\ μ ( f ) the forbidden patterns ( f ( x 1 , . . . , x ar ( f ) ) , j , h ) and ( f ( x 1 , . . . , x ar ( f ) ) , j , b ) . Moreover, with forbidden patterns it is also possible to simulate position-based reduction strategies such as innermost and outermost rewriting. The innermost reduction relation of a TRS R coincides with the forbidden pattern reduction relation if one uses the forbidden patterns l , ε , a for the left-hand sides l of each rule of R . Dually, if patterns ( l , ε , b ) are used, the forbidden pattern reduction relation coincides with the outermost reduction relation w.r.t. R . However, note that more complex layered combinations of the aforementioned approaches, such as innermost context-sensitive rewriting cannot be modeled by forbidden patterns as proposed in this paper. Still, the definition of forbidden patterns and rewriting with forbidden patterns is rather general and leaves many parameters open. In order to make this approach feasible in practice, it is necessary to identify interesting classes of forbidden patterns that yield a reasonable trade-off between power and simplicity. For these interesting classes of forbidden patterns we need methods which guarantee that the results (e.g. normal forms) computed by rewriting with forbidden patterns are meaningful, in the sense that they have some natural correlation with the actual results obtained by unrestricted rewriting. For instance, it is desirable that normal forms w.r.t. the restricted rewrite system are original head-normal forms. In this case one can use the restricted reduction relation to compute original normal forms (by an iterated process) whenever they exist (provided that the TRS in question is left-linear, confluent and the restricted reduction relation is terminating) (cf. Section 4 below for details). We define a criterion ensuring that normal forms w.r.t. the restricted system are original head-normal forms in the following section.</region>
        <region class="unknown" id="44" page="4" column="1">2 Here and subsequently we use a wildcard notation for forbidden patterns. For instance, , , i stands for t , p , i where t is some term and p some position in t of no further relevance.</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="45" page="5" column="1">60</outsider>
        <outsider class="DoCO:TextBox" type="header" id="46" page="5" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="48" page="5" column="1">4 Computing Meaningful Results</h1>
        <region class="DoCO:TextChunk" id="55" page="5" column="1">We are going to use canonical context-sensitive rewriting as defined in [ <xref ref-type="bibr" rid="R14" id="49" class="deo:Reference">14</xref>, <xref ref-type="bibr" rid="R16" id="50" class="deo:Reference">16</xref>] as an inspiration for our approach. There, for a given (left-linear) rewriting system R certain restrictions on the associated<marker type="page" number="6"/><marker type="block"/> replacement map μ guarantee that → μ -normal forms are → R -head-normal-forms. Hence, results computed by → μ and → R share the same root symbol. The basic idea is that reductions that are essential to create a more outer redex should not be forbidden. In the case of context-sensitive rewriting this is guaranteed by demanding that whenever an f -rooted term t occurs (as subterm) in the left-hand side of a rewrite rule and has a non-variable direct subterm t | i , then i ∈ μ ( f ) . It turns out that for rewriting with forbidden patterns severe restrictions on the shape of the patterns are necessary in order to obtain results similar to the ones for canonical context-sensitive rewriting in [<xref ref-type="bibr" rid="R14" id="54" class="deo:Reference">14</xref>]. First, no forbidden patterns of the shape , ε , h or , , a may be used as they are in general not compatible with the desired root-normalizing behaviour of our forbidden pattern rewrite system. Moreover, for each pattern t , p , we demand that • t is linear, • p is a variable or maximal (w.r.t. to the prefix ordering ≤ on positions) non-variable position in t , and • for each position q ∈ Pos ( t ) with q || p we have t | q ∈ V . We call the class of patterns obtained by the above restrictions simple patterns . Definition 3 (simple patterns) . A set Π of forbidden patterns is called simple if it does not contain patterns of the shape , ε , h or , , a and for every pattern ( t , p , ) ∈ Π it holds that t is linear, t | p ∈ V or t | p = f ( x 1 , . . . , x ar ( f ) ) for some function symbol f , and for each position q ∈ Pos ( t ) with q || p we have that t | q is a variable. Basically these syntactical properties of forbidden patterns are necessary to ensure that reductions which are essential to enable other, more outer reductions are not forbidden. Moreover, these properties, contrasting those defined in Definition 4 below, are independent of any concrete rewrite system. The forbidden patterns of the TRS ( R , Π ) in Example 4 below are not simple, since the patterns contain terms with parallel non-variable positions. This is the reason why it is not possible to head- normalize terms (w.r.t R ) with → Π : Example 4. Consider the TRS R given by f ( b , b ) → g ( f ( a , a )) a → b and forbidden patterns f ( a , a ) , 1 , h and f ( a , a ) , 2 , h . f ( a , a ) is linear and 1 and 2 are maximal positions (w.r.t. ≤ ) within this term. However, positions 1 and 2 are both non-variable and thus e.g. for f ( a , a ) , 1 , h there exists a position 2 || 1 such that f ( a , a ) | 2 = a ∈ V . Hence, Π is too restrictive to compute all R -head-normal forms in this example. Indeed, f ( a , a ) → ∗ R f ( b , b ) → R g ( f ( a , a )) where the latter term is a R -head-normal form. The term f ( a , a ) is a Π -normal form, although it is not a head-normal form (w.r.t. R ). Note also that the (first components of) forbidden patterns are not unifiable with the left-hand side of the rule that is responsible for the (later) possible root-step when reducing f ( a , a ) , not even if the forbidden subterms in the patterns are replaced by fresh variables. Now we are ready to define canonical rewriting with forbidden patterns within the class of simple forbidden patterns. To this end, we demand that patterns do not overlap with left-hand sides of rewrite rules in a way such that reductions necessary to create a redex might be forbidden. Definition 4 (canonical forbidden patterns) . Let R = ( F , R ) be a TRS with simple forbidden patterns Π F (w.l.o.g. we assume that R and Π F have no variables in common). Then, Π F is R -canonical (or just canonical ) if the following holds for all rules l → r ∈ R :</region>
        <outsider class="DoCO:TextBox" type="header" id="52" page="6" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="53" page="6" column="1">61</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="56" page="7" column="1">62</outsider>
        <outsider class="DoCO:TextBox" type="header" id="57" page="7" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
        <region class="DoCO:TextChunk" id="58" confidence="possible" page="7" column="1">1. There is no pattern ( t , p , λ ) such that • t ′ | q and l unify for some q ∈ Pos F ( t ) where t ′ = t [ x ] p and q &gt; ε , and • there exists a position q ′ ∈ Pos F ( l ) with q . q ′ = p for λ = h respectively q . q ′ &gt; p for λ = b. 2. There is no pattern ( t , p , λ ) such that • t ′ and l | q unify for some q ∈ Pos F ( l ) where t ′ = t [ x ] p , and • there exists a position q ′ with q . q ′ ∈ Pos F ( l ) and q ′ = p for λ = h respectively q ′ &gt; p for λ = b. Here, x denotes a fresh variable. Example 5. Consider the TRS R given by the single rule</region>
        <region class="DoCO:TextChunk" id="59" page="7" column="1">l = f ( g ( h ( x ))) → x = r . Then, Π = { t , p , h } with t = g ( f ( a )) , p = 1 . 1 is not canonical since t [ x ] p | q = g ( f ( y )) | 1 = f ( y ) and l unify where q = q ′ = 1 and thus q . q ′ = p (hence root ( l | q ′ ) = g). Moreover, also Π = { t , p , h } with t = g ( i ( x )) , p = 1 is not canonical, since l | q = g ( h ( x )) and t [ x ] p = f ( y ) unify for q = 1 and q . p = 1 . 1 is a non-variable position in l. On the other hand, Π = { g ( g ( x )) , 1 . 1 , h } is canonical. Note that all of the above patterns are simple. In order to prove that normal forms obtained by rewriting with simple and canonical forbidden patterns are actually head-normal forms w.r.t. unrestricted rewriting, and also to provide more intuition on canonical rewriting with forbidden patterns, we define the notion of a partial redex (w.r.t. to a rewrite system R ) as a term that is matched by a non-variable term l ′ which in turn matches the left-hand side of some rule of R . We call l ′ a witness for the partial match. Definition 5 (Partial redex) . Given a rewrite system R = ( F , R ) , a partial redex is a term s that is matched by a non-variable term l ′ which in turn matches the left-hand side of some rule in R. The (non-unique) term l ′ is called witness for a partial redex s. Thus, a partial redex can be viewed as a candidate for a future reduction step, which can only be performed if the redex has actually been created through more inner reduction steps. Hence, the idea of canonical rewriting with forbidden patterns could be reformulated as guaranteeing that the reduction of subterms of partial redexes is allowed whenever these reductions are necessary to create an actual redex. Lemma 1. Let R = ( F , R ) be a left-linear TRS with canonical (hence, in particular simple ) forbidden patterns Π F . Moreover, let s be a partial redex w.r.t. to the left-hand side of some rule l with witness l ′ such that l | p ∈ V but l ′ | p ∈ V . Then in the term C [ s ] q the position q . p is allowed by Π F for reduction provided that q is allowed for reduction. Theorem 1. Let R = ( F , R ) be a left-linear TRS with canonical (hence in particular simple ) forbidden patterns Π F . Then → R , Π F -normal forms are → R -head-normal forms. Given a left-linear and confluent rewrite system R and a set of canonical forbidden patterns Π such that → Π is well-founded, one can thus normalize a term s (provided that s is normalizing) by computing the → Π -normal form t of s which is R -root-stable according to Theorem 1, and then do the same recur- sively for the immediate subterms of t . Confluence of R assures that the unique normal form of s will indeed be computed this way. Example 6. As the forbidden pattern defined in Example 2 is (simple and) canonical, Theorem 1 yields that → R , δ -normal forms are → R -head-normal forms. For instance we get 2 nd ( inf ( 0 )) → Π ∗ s ( 0 ) .</region>
        <outsider class="DoCO:TextBox" type="header" id="60" page="8" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="61" page="8" column="1">63</outsider>
        <region class="DoCO:TextChunk" id="62" confidence="possible" page="8" column="1">Example 7. Consider the TRS with R and forbidden patterns Π from Example 3. We will prove below that R is Π -terminating (cf. Example 12). Furthermore we are able to show that every well-formed ground term that is reducible to a normal form in R is reducible to the same normal form with → R , Π and that every → R -normal form is root-stable w.r.t. → R .</region>
      </section>
      <section class="DoCO:Section">
        <h1 class="DoCO:SectionTitle" id="63" page="8" column="1">5 Proving Termination</h1>
        <region class="DoCO:TextChunk" id="69" page="8" column="1">We provide another example of a result on a restricted class of forbidden patterns, this time concerning termination. We exploit the fact that, given a finite signature and linear h -patterns, a set of allowed contexts complementing each forbidden one can be constructed. Thus, we can transform a rewrite system with this kind of forbidden patterns into a standard (i.e., context-free) one by explicitly instantiating and embedding all rewrite rules (in a minimal way) in contexts (including a designated top -symbol representing the empty context) such that rewrite steps in these contexts are allowed. To this end we propose a transformation that proceeds by iteratively instantiating and embedding rules in a minimal way. This is to say that the used substitutions map variables only to terms of the form f ( x 1 , . . . , x ar ( f ) ) and the contexts used for the embeddings have the form g ( x 1 , . . . , x i − 1 , , x i + 1 , x ar ( f ) ) for some function symbols f ∈ F , g ∈ F ⊎ { top } and some argument position i of f (resp. g ). It is important to keep track of the position of the initial rule inside the embeddings. Thus we associate to each rule introduced by the transformation a position pointing to the embedded original rule. To all initial rules of R we thus associate ε . Note that it is essential to consider a new unary function symbol top s for every sort s ∈ S (of type s → s ) representing the empty context. This is illustrated by the following example. Example 8. Consider the TRS given by <marker type="block"/> with F = { a , f } and the set of forbidden patterns Π = { f ( x ) , 1 , h } } . This system is not Π -terminating as we have a → Π f ( a ) → Π a → Π . . . Whether a subterm s | p = a is allowed for reduction by Π depends on its context. Thus, according to the idea of our transformation we try to identify all contexts C [ a ] p such that the reduction of a at position p is allowed by Π . However, there is no such (non-empty) context, although a may be reduced if C is the empty context. Moreover, there cannot be a rule l → r in the transformed system where l = a, since that would allow the reduction of terms that might be forbidden by Π . Our solution to this problem is to introduce a new function symbol top explicitly representing the empty context. Thus, in the example the transformed system will contain a rule top ( a ) → top ( f ( a )) . Abusing notation we subsequently use only one top -symbol, while we actually mean the top s -symbol of the appropriate sort. Moreover, in the following by rewrite rules we always mean rewrite rules with an associated (embedding) position, unless stated otherwise. All forbidden patterns used in this section (particularly in the lemmata) are linear here-patterns. We will make this general assumption explicit only in the more important results. Definition 6 (instantiation and embedding) . Let F = ( S , Ω ) be a signature, let l → r , p be a rewrite rule of sort s over F and let Π be a set of forbidden patterns (linear, h). The set of minimal instantiated<marker type="page" number="9"/><marker type="block"/> and embedded rewrite rules T Π ( l → r , p ) (or just T ( l → r , p ) ) is T Π i ( l → r , p ) ⊎ T Π e ( l → r , p ) where T e ( l → r , p ) = { C [ l ] → C [ r ] , i . p | C = f ( x 1 , . . . , x i − 1 , , x i + 1 , . . . , x ar ( f ) ) , f ∈ Ω ( s 1 ,..., s i − 1 , s , s i + 1 ,..., s ar ( f ) ) , s ′ , f ∈ F ⊎ { top s | s ∈ S } , i ∈ { 1 , . . . , ar ( f ) } , ∃ u , o , h ∈ Π . u | q θ = l θ ∧ q = ε ∧ o = q . p } T Π i ( l → r , p ) = { l σ → r σ , p | x σ = f ( x 1 , . . . , x ar ( f ) ) , sort ( x ) = sort ( f ( x 1 , . . . x ar ( f ) )) , f ∈ F , y = x ⇒ y σ = y , x ∈ RV Π ( l , p ) } and RV Π ( l , p ) = { x ∈ Var ( l ) | ∃ u , o , h ∈ Π . θ = mgu ( u , l | q ) ∧ q . o = p ∧ x θ ∈ V } . We also call the elements of T ( l → r , p ) the one-step T -successors of l → r , p . The reflexive- transitive closure of the one-step T -successor relation is the many-step T -successor relation or just T successor relation. We denote the set of all many-step T -successors of a rule l → r , p by T ∗ ( l → r , p ) . The set RV Π ( l , p ) of “relevant variables” is relevant in the sense that their instantiation might con- tribute to a matching by some (part of a) forbidden pattern term. Note that in the generated rules l ′ → r ′ , p ′ in T Π ( l → r , p ) , a fresh top s -symbol can only occur at the root of both l ′ and r ′ or not at all, according to the construction in Definition 6. Example 9. Consider the TRS ( R , Π ) where R = ( { a , f , g } , { f ( x ) → g ( x ) } ) and the forbidden patterns Π are given by { g ( g ( f ( a ))) , 1 . 1 , h } . T ( f ( x ) → g ( x ) , ε ) consists of the following rewrite rules.</region>
        <region class="unknown" id="65" page="8" column="1">a → f ( a ) f ( x ) → x</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="67" page="9" column="1">64</outsider>
        <outsider class="DoCO:TextBox" type="header" id="68" page="9" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
        <disp-formula class="DoCO:FormulaBox" id="F1">
          <label class="DoCO:Label" id="70">1</label>
          <content class="DoCO:Formula" id="71" page="9" column="1">f ( f ( x )) → g ( f ( x )) , ε</content>
        </disp-formula>
        <disp-formula class="DoCO:FormulaBox" id="F3">
          <label class="DoCO:Label" id="72">3</label>
          <content class="DoCO:Formula" id="73" page="9" column="1">f ( g ( x )) → g ( g ( x )) , ε f ( a ) → g ( a ) , ε</content>
        </disp-formula>
        <disp-formula class="DoCO:FormulaBox" id="F4">
          <label class="DoCO:Label" id="74">4</label>
          <content class="DoCO:Formula" id="75" page="9" column="1">f ( f ( x )) → f ( g ( x )) , 1</content>
        </disp-formula>
        <disp-formula class="DoCO:FormulaBox" id="F5">
          <label class="DoCO:Label" id="76">5</label>
          <content class="DoCO:Formula" id="77" page="9" column="1">g ( f ( x )) → g ( g ( x )) , 1</content>
        </disp-formula>
        <region class="DoCO:TextChunk" id="81" page="9" column="1">Note that RV Π ( f ( x ) , ε ) = { x } because g ( g ( f ( a ))) 1 . 1 = f ( a ) unifies with f ( x ) and mgu θ where x θ = a ∈ V . On the other hand RV Π ( f ( f ( x )) , 1 ) = 0 / . Lemma 2 (finiteness of instantiation and embedding) . Let l → r , p be a rewrite rule and let Π be a set of forbidden patterns. The set of (many-step) instantiations and embeddings of l → r , p (i.e. T ∗ ( l → r , p )) is finite. The transformation we are proposing proceeds by iteratedly instantiating and embedding rewrite rules. The following definitions identify the rules for which no further instantiation and embedding is needed. Definition 7 ( Π -stable) . Let l → r , p be a rewrite rule and let Π be a set of forbidden patterns. l → r , p is Π -stable (stb Π ( l → r , p ) for short) if there is no context C and no substitution σ such that C [ l σ ] q | q ′ = u θ and q . p = q ′ . o for any forbidden pattern u , o , h ∈ Π and any θ . Note that Π -stability is effectively decidable (for finite signatures and finite Π ), since only contexts and substitutions involving terms not exceeding a certain depth depending on Π need to be considered. Definition 8 ( Π -obsolete) . Let l → r , p be a rewrite rule and let Π be a set of forbidden patterns. l → r , p is Π -obsolete (obs Π ( l → r , p ) for short) if there is a forbidden pattern Π = u , o , h such that l | q = u θ and p = q . o. In Example 9, the rules (1), (2) and (4) are Π -stable, while rules (3) and (5) would be processed further. After two more steps e.g. a rule g ( g ( f ( a ))) → g ( g ( g ( a ))) , 1 . 1 is produced that is Π -obsolete. The following lemmata state some properties of Π -stable rules. <marker type="page" number="10"/><marker type="block"/> Lemma 3. Let Π be a set of forbidden patterns and let l ′ = C [ l σ ] p → C [ r σ ] p = r ′ , p be a Π -stable rewrite rule corresponding to l → r. If s → t with l ′ → r ′ , then s → Π t with l → r. Lemma 4. Let l → r , p be a rule and Π be a set of forbidden patterns. If T ( l → r , p ) = 0 / , then l → r , p is either Π -stable or Π -obsolete. Definition 9. Let R = ( F , R ) be a TRS with an associated set of forbidden patterns Π where F = ( S , Ω ) . The transformation T maps TRSs with forbidden patterns to standard TRSs T ( R , Π ) . It proceeds in 5 steps. 1. R tmp = { l → r , ε | l → r ∈ R } R acc = 0 / 2. R acc = { l → r , p ∈ R tmp | stb Π ( l → r , p ) } R tmp = { l → r , p ∈ R tmp | ¬ stb Π ( l → r , p ) ∧ ¬ obs Π ( l → r , p ) } 3. R tmp = l → r , p ∈ R tmp T ( l → r , p ) 4. If R tmp = 0 / go to 2 5. T ( R , Π ) = ( F ⊎ { top s | s ∈ S } , { l → r | l → r , p ∈ R acc } ) In the transformation rewrite rules are iteratively created and collected in R tmp (temporary rules). Those rules that are Π -stable and will thus be present in the final transformed system are collected in R acc (accepted rules). Lemma 5. Let R be a rewrite system and Π be a set of forbidden (linear h-)patterns. If s → R , Π t for ground terms s and t, then top ( s ) → top ( s ) in T ( R , Π ) . Theorem 2. Let R be a TRS and Π be a set of linear here-patterns. We have s → + Π t for ground terms s and t if and only if top ( s ) → + T ( R , Π ) top ( t ) . Proof. The result is a direct consequence of Lemmata 3 and 5. Corollary 1. Let R be a TRS and Π be a set of linear h-patterns. R is ground terminating under Π if and only if T ( R , Π ) is ground terminating. Note that the restriction to ground terms is crucial in Corollary 1. Moreover, ground termination and general termination do not coincide in general for rewrite systems with forbidden patterns (observe that the same is true for other important rewrite restrictions and strategies such as the outermost strategy). Example 10. Consider the TRS R = ( F , R ) given by F = { a , f } (where a is a constant) and R consisting of the rule f ( x ) → f ( x ) . Moreover, consider the set of forbidden patterns Π = { f ( a ) , ε , h , f ( f ( x )) , ε , h } . Then R is not Π terminating because we have f ( x ) → Π f ( x ) but it is Π -terminating on all ground terms, as can be shown by Theorem 2, since T ( R , Π ) = 0 / . Example 11. Consider the TRS of Example 2. We use two sorts NatList and Nat, with function symbol types 2nd : NatList → Nat, inf : Nat → NatList, top : NatList → NatList (note that another “ top ” symbol of type Nat → Nat is not needed here), s : Nat → Nat, 0 : Nat, nil : NatList and : of type Nat , NatList → NatList. According to Definition 9, the rules of T ( R , Π ) are:</region>
        <outsider class="DoCO:TextBox" type="header" id="79" page="10" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="80" page="10" column="1">65</outsider>
        <region class="DoCO:TextChunk" id="82" confidence="possible" page="10" column="1">2nd ( inf ( x )) → 2nd ( x : inf ( s ( x ))) 2nd ( x : ( y : zs )) → y top ( inf ( x )) → top ( x : inf ( s ( x ))) 2nd ( x ′ : inf ( x )) → 2nd ( x ′ : ( x : inf ( s ( x )))) top ( x ′ : inf ( x )) → top ( x ′ : ( x : inf ( s ( x )))) .</region>
        <outsider class="DoCO:TextBox" type="page_nr" id="83" page="11" column="1">66</outsider>
        <outsider class="DoCO:TextBox" type="header" id="84" page="11" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
        <region class="DoCO:TextChunk" id="87" confidence="possible" page="11" column="1">This system is terminating (and termination can be verified automatically, e.g. by AProVE [<xref ref-type="bibr" rid="R12" id="85" class="deo:Reference">12</xref>]). Hence, by Corollary 1 also the TRS with forbidden patterns from Example 2 is ground terminating. Example 12. The TRS R and forbidden patterns Π from Example 3 yield the following system T ( R , Π ) . For the sake of saving space we abbreviate app by a , take by t and inf by i . top ( i ( x )) → top ( x : i ( s ( x ))) t ( y , i ( x )) → t ( y , x : i ( s ( x ))) a ( y , i ( x )) → a ( y , x : i ( s ( x ))) top ( a ( i ( x ) , y )) → top ( a ( x : i ( s ( x )) , y )) t ( a ( i ( x ) , y ) , z ) → t ( a ( x : i ( s ( x )) , y ) , z ) t ( z , a ( i ( x ) , y )) → t ( z , a ( x : i ( s ( x )) , y )) a ( a ( i ( x ) , y ) , z ) → a ( a ( x : i ( s ( x )) , y ) , z ) a ( z , a ( i ( x ) , y )) → a ( z , a ( x : i ( s ( x )) , y )) top ( a ( x : xs , ys )) → top ( x : a ( xs , ys )) t ( z , a ( x : xs , ys )) → t ( z , x : a ( xs , ys )) a ( a ( x : xs , ys ) , z ) → a ( x : a ( xs , ys ) , z ) a ( z , a ( x : xs , ys )) → a ( z , x : a ( xs , ys )) a ( x : i ( zs ) , ys ) → x : a ( i ( zs ) , ys ) a ( x : s ( zs ) , ys ) → x : a ( s ( zs ) , ys ) a ( x : ( y : zs ) , ys ) → x : a ( y : zs , ys ) a ( nil , x ) → x t ( s ( x ) , y : ys ) → t ( x , ys ) t ( 0 , y : ys ) → y t ( x , nil ) → 0 This system is terminating (and termination can be verified automatically, e.g. by AProVE [<xref ref-type="bibr" rid="R12" id="86" class="deo:Reference">12</xref>]). Hence, again by Corollary 1 also the TRS with forbidden patterns from Example 3 is ground terminating.</region>
      </section>
      <section class="deo:Conclusion">
        <h1 class="DoCO:SectionTitle" id="88" page="11" column="1">6 Conclusion and Related Work</h1>
        <region class="DoCO:TextChunk" id="96" page="11" column="1">We have presented and discussed a novel approach to rewriting with context restrictions using forbidden patterns to specify forbidden/allowed positions in a term rather than arguments of functions as it was done previously in context-sensitivity. Thanks to their flexibility and parametrizability, forbidden patterns are applicable to a wider class of TRSs than traditional methods. In particular, position-based strategies and context-sensitive rewriting occur as special cases of such patterns. For the TRSs in Examples 1 and 3 nice operational behaviours can be achieved by using rewriting with forbidden patterns. The restricted reduction relation induced by the forbidden patterns is terminating while still being powerful enough to compute (head-) normal forms. When using simpler approaches such as position-based strategies or context-sensitive rewriting in these examples, such operational properties cannot be achieved. For instance, consider Example 1. There is an infinite reduction sequence starting from inf ( x ) with the property that every term has exactly one redex. Thus, non-termination is preserved under any reduction strategy (as strategies do not introduce new normal forms by definition). On the other hand, in order to avoid this infinite sequence using context-sensitive rewriting, we must set 2 ∈ μ ( : ) (regardless of any additional reduction strategy). But in this case → μ does not compute head-normal forms. In [ <xref ref-type="bibr" rid="R15" id="89" class="deo:Reference">15</xref>] on-demand rewriting was introduced, which is able to properly deal with the TRS of Example 1. This means that with the on-demand rewriting the reduction relation induced by the TRS of Example 1 can be restricted in a way such that it becomes terminating while still normal forms w.r.t. the restricted relation are head-normal forms w.r.t. the unrestricted one. Indeed, Example 1 was the main motivating example for the introduction of on-demand rewriting in [<xref ref-type="bibr" rid="R15" id="90" class="deo:Reference">15</xref>]. However, for Example 3 we get that by restricting rewriting by the proposed forbidden patterns we obtain a terminating relation that is able to compute the normal forms of all well-formed ground terms. As the system is orthogonal, any outermost-fair reduction strategy, e.g. parallel outermost, is normalizing. Yet, by using such a strategy the relation still remains non-terminating. In particular, our forbidden<marker type="page" number="12"/><marker type="block"/> patterns approach yields an effective procedure for deciding whether a ground term is normalizing or not (it is not normalizing if its → Π -normal form is not an → -normal form) for this example. On the other hand, by using context-sensitive rewriting, termination can only be obtained if 2 ∈ μ ( : ) which in turn implies that the term 0 : app ( nil , nil ) cannot be normalized despite having a normal form 0 : nil . For Examples 1 and 3 effective strategies like parallel outermost or S ω of [<xref ref-type="bibr" rid="R3" id="94" class="deo:Reference">3</xref>] are normalizing (though under either strategy there are still infinite derivations). We provide another example for which these strategies fail to provide normalization while the use of appropriate forbidden patterns yields normalization (and termination) Example 13. Consider the TRS R consisting of the following rules a → b b → a c → c g ( x , x ) → d f ( b , x ) → d Using a parallel outermost strategy the term g ( a , b ) is not reduced to its (unique) normal form d. Using S ω , f ( a , c ) is not reduced to its (unique) normal form d. However, it is easy to see that when using a Π = { c , ε , h , b , ε , h } , → Π is terminating and all R -normal forms can be computed. Note however, that the forbidden patterns used in Example 13 are not canonical. Thus it is not clear how to come up with such patterns automatically. We argued that for our forbidden pattern approach it is crucial to identify reasonable classes of patterns that provide trade-offs between practical feasibility, simplicity and power, favoring either component to a certain degree. We have sketched and illustrated two approaches to deal with the issues of verifying termination and guaranteeing that it is possible to compute useful results (in our case original head-normal forms) with the restricted rewrite relation. To this end we proposed a transformation from rewrite systems with forbidden patterns to ordinary rewrite systems and showed that ground termination of both induced reduction relations coincide. Moreover, we provided a criterion based on canonical rewriting with forbidden patterns to ensure that normal forms w.r.t. the restricted reduction relation are original head-normal forms. In particular “here”-patterns seem interesting as their use avoids context restrictions to be non-local . That is to say that whether a position is allowed for reduction or not depends only on a restricted “area” around the position in question regardless of the actual size of the whole object term. Note that this is not true for ordinary context-sensitive rewriting and has led to various complications in the theoretical analysis (cf. e.g. [11, Definition 23] [1, Definition 7] and [13, Definitions 1-3]). Regarding future work, among many interesting questions and problems one particularly important aspect is to identify conditions and methods for the automatic (or at least automatically supported) syn- thesis of appropriate forbidden pattern restrictions.<marker type="block"/> Acknowledgements : We are grateful to the anonymous referees for numerous helpful and detailed com- ments and criticisms.</region>
        <outsider class="DoCO:TextBox" type="header" id="92" page="12" column="1">B. Gramlich &amp; F. Schernhammer</outsider>
        <outsider class="DoCO:TextBox" type="page_nr" id="93" page="12" column="1">67</outsider>
      </section>
      <section class="DoCO:Bibliography">
        <h1 class="DoCO:SectionTitle" id="97" page="12" column="1">References</h1>
        <ref-list class="DoCO:BiblioGraphicReferenceList">
          <ref rid="R1" class="deo:BibliographicReference" id="98" page="12" column="1">[1] B. Alarcón, F. Emmes, C. Fuhs, J. Giesl, R. Gutiérrez, S. Lucas, P. Schneider-Kamp and R. Thiemann. Im- proving context-sensitive dependency pairs. In I. Cervesato, H. Veith and A. Voronkov, eds., Proc. LPAR’08, Doha, Qatar, November 22-27, 2008 , LNCS 5330, pp. 636–651. Springer, 2008.</ref>
          <ref rid="R2" class="deo:BibliographicReference" id="101" page="13" column="1">[2] M. Alpuente, S. Escobar, B. Gramlich and S. Lucas. On-demand strategy annotations revisited: An improved on-demand evaluation Strategy. Theoretical Computer Science , 411(2):504–541, 2010.</ref>
          <ref rid="R3" class="deo:BibliographicReference" id="102" page="13" column="1">[3] S. Antoy and A. Middeldorp. A sequential reduction strategy. Theoretical Computer Science , 165(1):75–95, 1996.</ref>
          <ref rid="R4" class="deo:BibliographicReference" id="103" page="13" column="1">[4] F. Baader and T. Nipkow. Term rewriting and All That . Cambridge University Press, 1998.</ref>
          <ref rid="R5" class="deo:BibliographicReference" id="104" page="13" column="1">[5] M. Bezem, J. Klop, and R. de Vrijer, eds. Term Rewriting Systems . Cambridge Tracts in Theoretical Computer Science 55. Cambridge University Press, Mar. 2003.</ref>
          <ref rid="R6" class="deo:BibliographicReference" id="105" page="13" column="1">[6] F. Durán, S. Lucas, C. Marché, J. Meseguer and X. Urbain. Proving operational termination of membership equational programs. Higher-Order and Symbolic Computation , 21(1-2):59–88, 2008.</ref>
          <ref rid="R7" class="deo:BibliographicReference" id="106" page="13" column="1">[7] S. Eker. Term rewriting with operator evaluation strategies. Electr. Notes Theor. Comput. Sci. , 15:311–330 (Proc. WRLA’98, Abbaye des Prémontrés at Pont-à-Mousson, France, September 1998, C. Kirchner and H. Kirchner, eds.), 1998.</ref>
          <ref rid="R8" class="deo:BibliographicReference" id="107" page="13" column="1">[8] J. Endrullis and D. Hendriks. From outermost to context-sensitive rewriting. In R. Treinen, ed., Proc. RTA’09, Brasilia, Brazil, June 29 - July 1, 2009 , LNCS 5595, pp. 305–319, Springer, June 2009.</ref>
          <ref rid="R9" class="deo:BibliographicReference" id="108" page="13" column="1">[9] W. Fokkink, J. Kamperman and P. Walters. Lazy rewriting on eager machinery. ACM Transactions on Programming Languages and Systems (TOPLAS) , 22(1):45–86, 2000.</ref>
          <ref rid="R10" class="deo:BibliographicReference" id="109" page="13" column="1">[10] K. Futatsugi, J. Goguen, J.-P. Jouannaud and J. Meseguer. Principles of OBJ2. In Conference Record of the 12th Annual ACM Symposium on Principles of Programming Languages (POPL’85) , pp. 52–66. ACM Press, 1985.</ref>
          <ref rid="R11" class="deo:BibliographicReference" id="110" page="13" column="1">[11] J. Giesl and A. Middeldorp. Transformation techniques for context-sensitive rewrite systems. Journal of Functional Programming , 14(4):379–427, Jul. 2004.</ref>
          <ref rid="R12" class="deo:BibliographicReference" id="111" page="13" column="1">[12] J. Giesl, P. Schneider-Kamp and R. Thiemann AProVE 1.2: Automatic termination proofs in the dependency pair framework. In U. Furbach and N. Shankar , eds., Proc. IJCAR’06, Seattle, Wasington, USA, August 17-20, 2006 , LNCS 4130, pp. 281–286. Springer, 2006.</ref>
          <ref rid="R13" class="deo:BibliographicReference" id="112" page="13" column="1">[13] B. Gramlich and S. Lucas. Generalizing Newman’s Lemma for left-linear rewrite systems. In F. Pfenning, ed., Proc. RTA’06, Seattle, Washington, USA, August 12-14, 2006 , LNCS 4098, pp. 66–80. Springer, 2006.</ref>
          <ref rid="R14" class="deo:BibliographicReference" id="113" page="13" column="1">[14] S. Lucas. Context-sensitive computations in functional and functional logic programs. Journal of Functional and Logic Programming , 1998(1), Jan. 1998.</ref>
          <ref rid="R15" class="deo:BibliographicReference" id="114" page="13" column="1">[15] S. Lucas. Termination of on-demand rewriting and termination of OBJ programs. In Proc. PPDP’01, September 5-7, 2001, Florence, Italy , pp. 82–93. ACM, 2001.</ref>
          <ref rid="R16" class="deo:BibliographicReference" id="115" page="13" column="1">[16] S. Lucas. Context-sensitive rewriting strategies. Information and Computation , 178(1):294–343, 2002.</ref>
          <ref rid="R17" class="deo:BibliographicReference" id="116" page="13" column="1">[17] S. Lucas. Lazy rewriting and context-sensitive rewriting. Electr. Notes Theor. Comput. Sci. 64:234–254 (Proc. WFLP’01, Kiel, Germany, September 13-15, 2001, Selected Papers, M. Hanus, ed.), 2002.</ref>
          <ref rid="R18" class="deo:BibliographicReference" id="117" page="13" column="1">[18] M.J. O’Donnell. Computing in systems described by equations. LNCS 58, Springer, 1977.</ref>
          <ref rid="R19" class="deo:BibliographicReference" id="118" page="13" column="1">[19] F. Schernhammer and B. Gramlich. Termination of lazy rewriting revisited. Electronic Notes in Theoretical Computer Science , 204:35–51 (Final Proc. WRS’07, Jürgen Giesl, ed.), Apr. 2008.</ref>
          <ref rid="R20" class="deo:BibliographicReference" id="119" page="13" column="1">[20] F. Schernhammer and B. Gramlich. Characterizing and proving operational termination of deterministic conditional term rewriting systems. Journal of Logic and Algebraic Programming , Selected revised papers of NWPT’08, to appear, 2009.</ref>
          <ref rid="R21" class="deo:BibliographicReference" id="120" page="13" column="1">[21] F. Schernhammer and B. Gramlich. VMTL – a modular termination laboratory. In R. Treinen, ed., Proc. RTA’09, Brasilia, Brazil, June 29 - July 1, 2009 , LNCS 5595, pp. 285–294, Springer, June 2009.</ref>
          <ref rid="R22" class="deo:BibliographicReference" id="121" page="13" column="1">[22] F. Schernhammer and B. Gramlich. On some implementation aspects of VMTL. In A. Geser and J. Wald- mann, eds., Proc. WST’09, Leipzig, Germany , pp. 72-75, June 2009.</ref>
        </ref-list>
        <outsider class="DoCO:TextBox" type="page_nr" id="99" page="13" column="1">68</outsider>
        <outsider class="DoCO:TextBox" type="header" id="100" page="13" column="1">Extending Context-Sensitivity in Term Rewriting</outsider>
      </section>
    </body>
  </article>
</pdfx>
