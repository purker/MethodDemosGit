<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017297">
<title confidence="0.989312">
Unsupervised Clustering of Social Events
</title>
<author confidence="0.998211">
Matthias Zeppelzauer
</author>
<affiliation confidence="0.755189">
Vienna University of
Technology, Austria
Interactive Media Sys. Group
</affiliation>
<email confidence="0.997114">
mzz@ims.tuwien.ac.at
</email>
<author confidence="0.992641">
Maia Zaharieva
</author>
<affiliation confidence="0.9268485">
University of Vienna, Austria
Research Group Multimedia
</affiliation>
<address confidence="0.412129">
Information Systems
</address>
<email confidence="0.994361">
zaharieva@cs.univie.ac.at
</email>
<author confidence="0.989734">
Manfred Del Fabro
</author>
<affiliation confidence="0.926708333333333">
Klagenfurt University, Austria
Institute of Information
Technology
</affiliation>
<email confidence="0.997633">
manfred@itec.aau.at
</email>
<sectionHeader confidence="0.981333" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999640142857143">
This paper describes our contribution to the social event de-
tection (SED) task of the MediaEval Benchmark 2013. We
present a robust unsupervised approach for the clustering of
tagged photos and videos into social events. Results on the
SED datasets show that the proposed approach yields an ex-
cellent generalization ability and state-of-the-art clustering
performance.
</bodyText>
<sectionHeader confidence="0.998716" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.99990580952381">
We participated in challenge 1 of the Social Event De-
tection (SED) task [4]. The goal of the task is to build
photo clusters belonging to unique social events in a large
collection of tagged flicker images. Thereby the total num-
ber of events is not provided. In an additional subtask we
assign unlabeled videos to the previously discovered photo
clusters. The development set comprises 300k images from
14882 unique events. For the test set of 131k images no
ground truth is available.
We consider challenge 1 as an unsupervised data mining
task. The basic idea is to rely on robust heuristics and
to reduce the number of parameters of the approach to a
minimum to obtain a good generalization ability between
different datasets. Additionally, the proposed approach does
not require any external (online) data sources.
In the course of the SED2013 task, we focus on the fol-
lowing research questions: (i) Which level of clustering per-
formance can be obtained by relying on simple but robust
heuristics for unsupervised clustering and how do the results
compare to more complex clustering methods? (ii) How well
does the proposed approach generalize to unknown data?
</bodyText>
<sectionHeader confidence="0.999628" genericHeader="related work">
2. RELATED WORK
</sectionHeader>
<bodyText confidence="0.9973459">
Many existing approaches for event detection in image
collections require a separate training [1, 3]. Becker et al.
create separate clusters for each feature such as title, descrip-
tion, time, etc. The authors employ single-pass incremental
clustering whereas the threshold for each cluster is tuned
based on a set of training data [1]. Reuter and Cimiano em-
ploy machine learning techniques to detect events in social
streams. The authors employ SVMs to classify Flickr images
annotated by machine tags from last.fm into events [3].
Vavliakis et al. propose a social event detection approach
</bodyText>
<copyright confidence="0.800181">
Copyright is held by the author/owner(s).
</copyright>
<note confidence="0.340729">
MediaEval 2013 Workshop, October 18-19, 2013, Barcelona, Spain
</note>
<bodyText confidence="0.999801454545455">
based on topic detection [5]. The authors perform topic
detection by Latent Dirichlet Allocation (LDA) for each city
in the image collection. Additionally, the authors manually
identify topics that are typical for a specific event cluster.
From related approaches we observe that many assump-
tions are made on the training set and (partially manual)
optimizations are required which limits general applicabil-
ity. Our unsupervised approach minimizes the assumptions
on the data and avoids manual intervention. The approach
exhibits a strong generalization ability and results show that
the sensitivity to the involved parameters is reasonably low.
</bodyText>
<sectionHeader confidence="0.783449" genericHeader="method">
3. APPROACH
</sectionHeader>
<subsectionHeader confidence="0.995632">
3.1 Full Clustering
</subsectionHeader>
<bodyText confidence="0.986420441176471">
The input to the approach are the available metadata of
the SED dataset (capture data, location, title, tags, descrip-
tion) and a stopword list. No other data sources are re-
quired. In a first step, the metadata are preprocessed: Since
a user cannot be at two locations at the same time, we as-
sign locations of photos taken by the same user at the same
time to the user’s non-geotagged photos. Additionally, the
textual metadata are filtered by the stopword list.
In a next step, we perform three independent cluster-
ings in parallel: temporal clustering, location clustering, and
topic clustering. For temporal clustering we employ mean-
shift and set the bandwidth parameter βT in a way that
the resulting clusters span between 2 and 6 hours, which is
a reasonable temporal resolution for social events. For lo-
cation clustering we observe that the performance gain of
meanshift clustering does not justify the computational ef-
forts. Hence, we skip meanshift clustering and assign each
individual and unique location in the data a separate cluster
ID. Topic clustering is based on topic extraction by LDA.
We perform topic modeling on the textual descriptions of
each photo (title, tags, description) using LDA and extract
T topics for the employed dataset. For each photo i, we
estimate the likelihoods li,1 and li,2 of the first- and second-
best matching topics. If the difference of the likelihoods is
larger than a threshold τ (li,1 − li,2 &amp;gt; τ) the most likely
topic is assigned to the photo otherwise no topic is assigned.
Parameter τ is set to 0.3 for all experiments.
The three independent clusterings are the basis for the
generation of initial event clusters. Photos which share the
same temporal cluster, location cluster, and topic cluster
are assigned the same unique event ID. The remaining pho-
tos are assigned to existing and new events in a number
of matching steps. First, remaining photos which share
final event clusters
</bodyText>
<figureCaption confidence="0.999552">
Figure 1: Overview of the approach
</figureCaption>
<bodyText confidence="0.999951769230769">
the same user and capture time as photos in already ex-
isting events are assigned to the respective events. If sev-
eral events share the same users and capture times, the
events are merged. Second, remaining photos without loca-
tion information are matched to existing events by time and
topic. If no match to an existing event can be established, a
new (non-geotagged event cluster) is generated. For photos
where no location and no topic is available we generate new
events by their capture time.
The resulting sets of events (refined event clusters and
non-geotagged event clusters) may oversegment the true event
distribution. Hence, we merge events that share similar
time, location, and topic to obtain the final event clusters.
</bodyText>
<subsectionHeader confidence="0.999146">
3.2 Full Clustering of Media using Videos
</subsectionHeader>
<bodyText confidence="0.999987444444444">
For the video subtask, we apply the above described topic
modeling to the stopword-filtered textual descriptions of the
videos (title, description, keywords). Temporal clustering
and location clustering are neglected, because most videos
do not contain location information and a capturing date.
As a consequence, parameter τ is set to 0.0 for all experi-
ments to achieve a complete clustering of all videos.
We investigate three different approaches for generating
the video clusters: (i) LDA is applied to train a topic model
with 200 topics on the development data from which the
topics of the test data are derived; (ii) each video constitutes
a topic on its own; and (iii) an unsupervised LDA-based
approach is used to detect 70 topics in the test data. After
the video clusters are created, we link them to the previously
generated photo clusters. The keywords of video clusters
V are compared to the keywords of the photo clusters P
using the Jaccard similarity coefficient. Each video cluster
is linked to the photo cluster with the highest similarity.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="evaluation">
4. EXPERIMENTS AND RESULTS
</sectionHeader>
<bodyText confidence="0.998874647058823">
We use the same parameters for experiments on the de-
velopment and test set. To estimate the numbers of topics,
we assume that each topic is constituted in average by 100-
200 photos. Additionally, we evaluate different values of βT
corresponding to an event duration of 2-6 hours. The results
of the proposed approach for both sets demonstrate its ex-
cellent generalization ability (see Table 1). Results for the
test set are even better than for the development set. The
clustering performance is comparable to (more complex) su-
pervised state-of-the-art methods. The approach by Petkos
et al., for example, yields NMI values of 0.92 (average of best
results) and 0.69 (average performance) on a portion of the
SED2011 dataset (no F1 reported) [2]. Becker et al. [1] yield
NMI values between 0.92 and 0.94 and F1 values from 0.77
to 0.82 on a test set consisting of 270k photos (10 splits).
Reuter and Cimiano report an F1 of 0.74 for a dataset of
700k photos (7 splits, no NMI reported) [3].
</bodyText>
<tableCaption confidence="0.996209">
Table 1: Results for Full Clustering
</tableCaption>
<table confidence="0.998717142857143">
βT Development Set Test Set
Topics F1 NMI Topics F1 NMI
0.2 2000 0.74 0.94 1000 0.78 0.94
0.2 3000 0.74 0.94 1500 0.78 0.94
0.2 1600 0.74 0.94 800 0.78 0.94
0.1 2000 0.73 0.93 1000 0.76 0.94
0.5 2000 0.72 0.93 1000 0.77 0.94
</table>
<bodyText confidence="0.99740925">
The three approaches submitted to the video subtask show
different results. The supervised approach trained on the de-
velopment data performs suboptimally (F1=0.42, NMI=0.68).
The reason for this may be that the events of the test data
are inferred from the events in the development data. If an
event is not included in the development data, it cannot be
inferred. The second approach shows that comparing the
metadata of single videos with the accumulated LDA key-
words from clusters is not well-suited to link single videos
to clusters (F1=0.34, NMI=0.77). The unsupervised LDA-
based approach performs best (F1=0.69, NMI=0.85) and
builds a promising baseline for future improvements.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="conclusions">
5. CONCLUSIONS AND OUTLOOK
</sectionHeader>
<bodyText confidence="0.991958714285714">
In this paper we presented our contribution to the SED
challenge of the MediaEval 2013 Benchmark. We proposed a
robust unsupervised method for the clustering of photos and
videos into social events. The method exhibits strong gen-
eralization ability, low sensitivity to parameters, and yields
state-of-the-art performance. Future work focuses on more
sophisticated event refinements and visual content analysis.
</bodyText>
<sectionHeader confidence="0.999953" genericHeader="acknowledgments">
6. ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.999688">
This work has been partly funded by the Vienna Science
and Technology Fund (WWTF) through project ICT12-010
and the Carinthian Economic Promotion Fund (KWF) un-
der grant KWF-20214 22573 33955.
</bodyText>
<sectionHeader confidence="0.964881" genericHeader="references">
7. REFERENCES
</sectionHeader>
<reference confidence="0.9997793125">
[1] H. Becker, M. Naaman, and L. Gravano. Learning
similarity metrics for event identification in social
media. In ACM WSDM, pp. 291–300, 2010.
[2] G. Petkos, S. Papadopoulos, and Y. Kompatsiaris.
Social event detection using multimodal clustering and
integrating supervisory signals. In ACM ICMR, pp.
23:1–8, 2012.
[3] T. Reuter and P. Cimiano. Event-based classification of
social media streams. In ACM ICMR, pp. 22:1–8, 2012.
[4] T. Reuter, S. Papadopoulos, V. Mezaris, P. Cimiano,
C. de Vries, and S. Geva. Social Event Detection at
MediaEval 2013: Challenges, datasets, and evaluation.
In MediaEval 2013 Workshop, 2013.
[5] K. N. Vavliakis, F. A. Tzima, and P. A. Mitkas. Event
detection via LDA for the MediaEval2012 SED Task.
In MediaEval 2012 Workshop, 2012.
</reference>
<figure confidence="0.997931625">
merge events
stop
words
topic clustering
refined event clusters
description location time
initial clusters
update, merge
update
merge
location clustering temporal clustering
merge clusterings
preprocessing
match
time + topic
match
user + time
metadata
non-geotagged event clusters
all
unassigned fotos
no location
new
no location, no topic
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.204504">
<title confidence="0.998683">Unsupervised Clustering of Social Events</title>
<author confidence="0.999838">Matthias Zeppelzauer</author>
<affiliation confidence="0.835325">Vienna University Technology, Interactive Media Sys. Group</affiliation>
<email confidence="0.832032">mzz@ims.tuwien.ac.at</email>
<author confidence="0.989608">Maia Zaharieva</author>
<affiliation confidence="0.960721333333333">University of Vienna, Research Group Information Systems</affiliation>
<email confidence="0.819205">zaharieva@cs.univie.ac.at</email>
<author confidence="0.9993">Manfred Del Fabro</author>
<affiliation confidence="0.884851">Klagenfurt University, Institute of Technology</affiliation>
<email confidence="0.718709">manfred@itec.aau.at</email>
<abstract confidence="0.99319475">This paper describes our contribution to the social event detection (SED) task of the MediaEval Benchmark 2013. We present a robust unsupervised approach for the clustering of tagged photos and videos into social events. Results on the SED datasets show that the proposed approach yields an excellent generalization ability and state-of-the-art clustering performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Becker</author>
<author>M Naaman</author>
<author>L Gravano</author>
</authors>
<title>Learning similarity metrics for event identification in social media.</title>
<date>2010</date>
<booktitle>In ACM WSDM,</booktitle>
<pages>291--300</pages>
<contexts>
<context position="2050" citStr="[1, 3]" startWordPosition="307" endWordPosition="308"> clustering methods? (ii) How well does the proposed approach generalize to unknown data? 2. RELATED WORK Many existing approaches for event detection in image collections require a separate training [1, 3]. Becker et al. create separate clusters for each feature such as title, description, time, etc. The authors employ single-pass incremental clustering whereas the threshold for each cluster is tuned b</context>
<context position="7919" citStr="[1]" startWordPosition="1260" endWordPosition="1260"> The approach by Petkos et al., for example, yields NMI values of 0.92 (average of best results) and 0.69 (average performance) on a portion of the SED2011 dataset (no F1 reported) [2]. Becker et al. [1] yield NMI values between 0.92 and 0.94 and F1 values from 0.77 to 0.82 on a test set consisting of 270k photos (10 splits). Reuter and Cimiano report an F1 of 0.74 for a dataset of 700k photos (7 spl</context>
</contexts>
<marker>[1]</marker>
<rawString>H. Becker, M. Naaman, and L. Gravano. Learning similarity metrics for event identification in social media. In ACM WSDM, pp. 291–300, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Petkos</author>
<author>S Papadopoulos</author>
<author>Y Kompatsiaris</author>
</authors>
<title>Social event detection using multimodal clustering and integrating supervisory signals.</title>
<date>2012</date>
<booktitle>In ACM ICMR,</booktitle>
<pages>23--1</pages>
<contexts>
<context position="7900" citStr="[2]" startWordPosition="1256" endWordPosition="1256">of-the-art methods. The approach by Petkos et al., for example, yields NMI values of 0.92 (average of best results) and 0.69 (average performance) on a portion of the SED2011 dataset (no F1 reported) [2]. Becker et al. [1] yield NMI values between 0.92 and 0.94 and F1 values from 0.77 to 0.82 on a test set consisting of 270k photos (10 splits). Reuter and Cimiano report an F1 of 0.74 for a dataset of</context>
</contexts>
<marker>[2]</marker>
<rawString>G. Petkos, S. Papadopoulos, and Y. Kompatsiaris. Social event detection using multimodal clustering and integrating supervisory signals. In ACM ICMR, pp. 23:1–8, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Reuter</author>
<author>P Cimiano</author>
</authors>
<title>Event-based classification of social media streams.</title>
<date>2012</date>
<booktitle>In ACM ICMR,</booktitle>
<pages>22--1</pages>
<contexts>
<context position="2050" citStr="[1, 3]" startWordPosition="307" endWordPosition="308"> clustering methods? (ii) How well does the proposed approach generalize to unknown data? 2. RELATED WORK Many existing approaches for event detection in image collections require a separate training [1, 3]. Becker et al. create separate clusters for each feature such as title, description, time, etc. The authors employ single-pass incremental clustering whereas the threshold for each cluster is tuned b</context>
<context position="2480" citStr="[3]" startWordPosition="377" endWordPosition="377">ata [1]. Reuter and Cimiano employ machine learning techniques to detect events in social streams. The authors employ SVMs to classify Flickr images annotated by machine tags from last.fm into events [3]. Vavliakis et al. propose a social event detection approach Copyright is held by the author/owner(s). MediaEval 2013 Workshop, October 18-19, 2013, Barcelona, Spain based on topic detection [5]. The </context>
<context position="8144" citStr="[3]" startWordPosition="1304" endWordPosition="1304">een 0.92 and 0.94 and F1 values from 0.77 to 0.82 on a test set consisting of 270k photos (10 splits). Reuter and Cimiano report an F1 of 0.74 for a dataset of 700k photos (7 splits, no NMI reported) [3]. Table 1: Results for Full Clustering βT Development Set Test Set Topics F1 NMI Topics F1 NMI 0.2 2000 0.74 0.94 1000 0.78 0.94 0.2 3000 0.74 0.94 1500 0.78 0.94 0.2 1600 0.74 0.94 800 0.78 0.94 0.1 </context>
</contexts>
<marker>[3]</marker>
<rawString>T. Reuter and P. Cimiano. Event-based classification of social media streams. In ACM ICMR, pp. 22:1–8, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Reuter</author>
<author>S Papadopoulos</author>
<author>V Mezaris</author>
<author>P Cimiano</author>
<author>C de Vries</author>
<author>S Geva</author>
</authors>
<title>Social Event Detection at MediaEval 2013: Challenges, datasets, and evaluation.</title>
<date>2013</date>
<booktitle>In MediaEval 2013 Workshop,</booktitle>
<contexts>
<context position="844" citStr="[4]" startWordPosition="111" endWordPosition="111">t the proposed approach yields an excellent generalization ability and state-of-the-art clustering performance. 1. INTRODUCTION We participated in challenge 1 of the Social Event Detection (SED) task [4]. The goal of the task is to build photo clusters belonging to unique social events in a large collection of tagged flicker images. Thereby the total number of events is not provided. In an additional</context>
</contexts>
<marker>[4]</marker>
<rawString>T. Reuter, S. Papadopoulos, V. Mezaris, P. Cimiano, C. de Vries, and S. Geva. Social Event Detection at MediaEval 2013: Challenges, datasets, and evaluation. In MediaEval 2013 Workshop, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K N Vavliakis</author>
<author>F A Tzima</author>
<author>P A Mitkas</author>
</authors>
<title>Event detection via LDA for the MediaEval2012 SED Task.</title>
<date>2012</date>
<booktitle>In MediaEval 2012 Workshop,</booktitle>
<contexts>
<context position="2674" citStr="[5]" startWordPosition="405" endWordPosition="405">vents [3]. Vavliakis et al. propose a social event detection approach Copyright is held by the author/owner(s). MediaEval 2013 Workshop, October 18-19, 2013, Barcelona, Spain based on topic detection [5]. The authors perform topic detection by Latent Dirichlet Allocation (LDA) for each city in the image collection. Additionally, the authors manually identify topics that are typical for a specific eve</context>
</contexts>
<marker>[5]</marker>
<rawString>K. N. Vavliakis, F. A. Tzima, and P. A. Mitkas. Event detection via LDA for the MediaEval2012 SED Task. In MediaEval 2012 Workshop, 2012.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>