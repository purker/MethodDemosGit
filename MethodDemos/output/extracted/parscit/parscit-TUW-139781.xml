<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000067">
<note confidence="0.84896">
MIC2005. The 6th Metaheuristics International Conference 775
</note>
<title confidence="0.6917445">
Cooperating Memetic and Branch-and-Cut Algorithms for
Solving the Multidimensional Knapsack Problem
</title>
<author confidence="0.994845">
Jakob Puchinger* Günther R. Raidl* Martin Gruber*
</author>
<affiliation confidence="0.998995">
*Institute of Computer Graphics and Algorithms, Vienna University of Technology
</affiliation>
<address confidence="0.799638">
Favoritenstrae 9-11/1861, 1040 Vienna, Austria
</address>
<email confidence="0.990043">
{puchinger,raidl,gruber}@ads.tuwien.ac.at
</email>
<sectionHeader confidence="0.998055" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999671666666667">
Recent work in combinatorial optimization indicates the high potential of combining meta-
heuristics with integer linear programming (ILP) techniques. We study here a hybrid system
in which a memetic algorithm (MA) and a general purpose ILP solver based on branch-and-cut
(B&amp;C) are executed in parallel and continuously exchange information in a bidirectional, asyn-
chronous way. As target problem, we consider the multidimensional knapsack problem (MKP).
The memetic algorithm uses a direct binary encoding of candidate solutions and repair and
local improvement strategies that are steered by pseudo-utility ratios. As B&amp;C framework we
use the general purpose commercial ILP-solver CPLEX. The information exchanged between
the two heterogenous algorithms are so-far best primal solutions and promising dual variable
values of solutions to certain linear programming (LP) relaxations. These dual variable values
are used in the MA to update the pseudo-utility ratios of local improvement and repair.
We will see that this combination of a metaheuristic and an exact optimization method
is able to benefit from synergy: Experimental results document that within the same limited
total time, the cooperative system yields better heuristic solutions than each algorithm alone.
In particular, the cooperative system also competes well with today’s best algorithms for the
MKP, needing substantially shorter total running times.
The next section introduces the MKP formally and gives some references to state-of-the-
art algorithms for solving it. Section 3 explains the MA-part. The used ILP formulation and
B&amp;C solver are described in Sect. 4. Details about the parallel execution and asynchronous
communication are given in Sect. 5. Finally, Sect. 6 presents exemplary results, and conclusions
are drawn in Sect. 7.
</bodyText>
<footnote confidence="0.562459666666667">
This work is supported by the RTN ADONET under grant 504438 and the Austrian Science Fund (FWF)
under grant P16263-N04.
Vienna, Austria, August 22–26, 2005
</footnote>
<note confidence="0.690843">
776 MIC2005. The 6th Metaheuristics International Conference
</note>
<sectionHeader confidence="0.728932" genericHeader="method">
2 The Multidimensional Knapsack Problem
</sectionHeader>
<bodyText confidence="0.939317">
The MKP is a well-studied, strongly NP-hard combinatorial optimization problem occurring
in many different applications. It can be defined by the following ILP:
</bodyText>
<equation confidence="0.99944625">
(MKP) maximize z =
subject to Xn wijxj G ci, i = 1, ... , m (2)
j=1
xj E {0, 1}, j = 1,..., n. (3)
</equation>
<bodyText confidence="0.998841739130435">
Given are n items with profits pj &gt; 0 and m resources with capacities ci &gt; 0. Each item
j consumes an amount wij &gt; 0 from each resource i. The goal is to select a subset of the
items with maximum total profit, see (1); chosen items must, however, not exceed resource
capacities, see (2). The 0–1 decision variables xj indicate which items are selected.
A general overview on practical and theoretical results for the MKP can be found in the
monograph by Kellerer et al. [4]. Besides exact techniques for solving small to moderately
sized instances, many kinds of metaheuristics have already been applied to the MKP.
To our knowledge, the method currently yielding the best results, at least for commonly
used benchmark instances, has been described by Vasquez and Hao [7] and was recently re-
fined by Vasquez and Vimont [8]. The search space is reduced and partitioned via additional
constraints, fixing the total number of items to be packed. Bounds for these constraints are
calculated by solving a modified LP-relaxation. For each remaining part of the search space,
tabu-search is independently applied, starting with a solution derived from the LP-relaxation
of the partial problem. The improvement described in [8] lies mainly in an additional variable
fixing heuristic.
Besides this tabu search approach, various other metaheuristics have been described for
the MKP, including several variants of hybrid evolutionary algorithms (EAs); see [6] for a
recent survey and comparison of EAs for the MKP. The basics of today’s most effective EAs
go back to Chu and Beasley [1]: Candidate solutions are directly represented by their 0–1
vectors x; standard crossover and mutation operators and – most importantly – clever repair
and local improvement strategies are applied. Such combinations of EAs with problem-specific
local improvement strategies are in general also called memetic algorithms, and we adopt this
nomenclature in the following.
</bodyText>
<sectionHeader confidence="0.970171" genericHeader="method">
3 The Memetic Algorithm Part
</sectionHeader>
<bodyText confidence="0.851165166666667">
The MA, which we consider here for parallel execution with B&amp;C, is based on the principles
from Chu and Beasley and includes some improvements suggested in [5, 3, 6]. The MA
framework is steady-state. The creation of initial solutions is guided by the LP-relaxation
of the MKP, as described in [3]. Each new candidate solution is derived by selecting two
parents via binary tournaments, performing uniform crossover on their characteristic vectors
Vienna, Austria, August 22–26, 2005
</bodyText>
<equation confidence="0.714874">
Xn pj xj (1)
j=1
</equation>
<bodyText confidence="0.984567235294118">
MIC2005. The 6th Metaheuristics International Conference 777
x, flipping each bit with probability 1/n, performing repair if a capacity constraint is violated,
and always performing local improvement. If such a new candidate solution is different to all
solutions in the current population, it replaces the worst of them.
Both, repair and local improvement, are based on greedy first-fit strategies and guarantee
that any resulting candidate solution lies at the boundary of the feasible region, where optimal
solutions are always located. The repair procedure considers all items in a specific order Π
and removes selected items (xj = 1 → xj = 0) as long as any capacity constraint is violated.
Local improvement works vice-versa: It considers all items in the reverse order Π and selects
items not yet appearing in the solution as long as no capacity limit is exceeded.
Crucial for these strategies to work well is the choice of the ordering Π. Items that are likely
to be selected in an optimal solution must appear near the end of Π. Various heuristic measures
can be found in the literature for calculating utility values for estimating the likelihood with
which each item appears in an optimal solution. For the unidimensional knapsack problem
(m = 1), for example, ordering items according to increasing ratios pj/w1j is straight-forward
and works generally well. In case of the MKP, an appropriate choice is much more difficult.
As in [1], we determine Π by ordering the items according to pseudo-utility ratios
</bodyText>
<equation confidence="0.984849">
Empj ,
i=1 aiwij
</equation>
<bodyText confidence="0.9999092">
where we set the surrogate multipliers ai to the dual variable values (i.e. shadow prices of the
i-th constraints) of the solution to the LP-relaxation of the MKP.
While this ordering Π remains fixed throughout the whole optimization if the MA runs in-
dependently, we will continuously adapt the surrogate multipliers according to more promising
dual variable values when B&amp;C is performed in parallel, see Sect. 5.
</bodyText>
<sectionHeader confidence="0.955598" genericHeader="method">
4 The Branch-and-Cut Part
</sectionHeader>
<bodyText confidence="0.9997998">
The heuristics in [7, 8] exploit the property that good solutions to the MKP often lie in
the neighborhood of the solution xLP to the corresponding LP relaxation. We performed an
empirical in-depth examination on smaller instances of Chu and Beasley’s benchmark library
[1] for which we were able to compute optimal solutions x* and observed that the Hamming
distance between x* and the (possibly infeasible) rounded LP solution xRLP with
</bodyText>
<equation confidence="0.945764">
xRLP
j = rxLP
</equation>
<bodyText confidence="0.923422666666667">
j − 0.5e, j = 1,..., n,
is almost always smaller than 10% of the total number of variables. Focusing the optimization
to such a neighborhood seems therefore to be highly promising. This can be done by adding a
single constraint to the MKP similar to the local branching constraints presented by Fischetti
and Lodi [2]. The following inequality restricts the search space to a neighborhood of Hamming
distance k around the rounded LP solution xRLP:
</bodyText>
<equation confidence="0.884931333333333">
XΔ(x, xRLP) = X xj &lt; k, (6)
j∈SLP (1 − xj) +
j /∈SLP
</equation>
<bodyText confidence="0.717564">
where SLP = {j = 1, ... , n  |xRLP
</bodyText>
<equation confidence="0.764089">
j = 1} is the binary support of xRLP.
Vienna, Austria, August 22–26, 2005
uj =
778 MIC2005. The 6th Metaheuristics International Conference
</equation>
<bodyText confidence="0.99848075">
In our implementation we use CPLEX as B&amp;C system and initially partition the search
space by constraint (6) into the more promising part and by the inverse constraint Δ(x, xRLP) )
k+1 into a second, remaining part. CPLEX is forced to first completely solve the neighborhood
of xRLP before considering the remaining search space.
</bodyText>
<sectionHeader confidence="0.912405" genericHeader="method">
5 Parallel Execution and Communication
</sectionHeader>
<bodyText confidence="0.999512333333333">
The intention is to run the MA and the B&amp;C approach in parallel on two individual machines.
In our tests, however, we executed the algorithms in a pseudo-parallel way as individual
processes on a single machine. If a new so-far best solution is encountered by one of the
algorithms, it is immediately sent to the partner. If the MA receives such a solution, it is
included into the population by replacing the worst solution, as in the case of any other newly
created solution candidate. In B&amp;C, a received solution is set as new incumbent solution,
providing a new global lower bound.
When B&amp;C finds a new incumbent solution, it also sends the current dual variable values
associated to the MKP-constraints, which are devised from the LP relaxation of the currently
processed node in the B&amp;C tree. When the MA receives these dual variable values, it recal-
culates the pseudo-utility ratios and the item ordering Π for repair and local improvement as
described in Sec. 3.
</bodyText>
<sectionHeader confidence="0.995402" genericHeader="method">
6 Computational Experiments
</sectionHeader>
<bodyText confidence="0.999896055555556">
We considered four variants of the described algorithms: the independent MA, independent
B&amp;C, the cooperative approach exchanging best solutions only (CO-b), and the cooperative
approach exchanging best solutions and dual variable values (CO-bd). The MA runs for
1 000 000 iterations and then restarts, keeping only the so-far best solution. The neighborhood
size k is set to 10% of the number of variables n.
The approaches were tested on the three largest standard benchmark sets of Beasley’s
OR-Library (http://people.brunel.ac.uk/—mastjjb/jeb/info.html) consisting of a total of
90 instances with n = 500 items and m E f5, 10, 30} constraints. Each of these three in-
stance sets is divided into three subsets of 10 instances with tightness ratios α = ci/ Enj=1 wij,
α E f0.25, 0.5, 0.75}. The tested algorithms were implemented using GNU C++ 3.3.1 and
CPLEX 9.0. All experiments were performed on a 2.8GHz Pentium 4 machine.
We consider here two different computational experiments, one with shorter total CPU-
times of 850s, see Table 1, and one with longer total CPU-times of 1 800s, see Table 2. Pre-
liminary tests with the cooperative approaches indicated that due to its relatively quick con-
vergence, the MA mainly contributes to the finding of improved solutions during the early
stages of the optimization process. We therefore started the MA and B&amp;C at the same time
but terminated the MA earlier. The MA was given 250s (400s in the long runs), while B&amp;C
was performed with a time limit of 600s (1 400s).
</bodyText>
<note confidence="0.706946">
Vienna, Austria, August 22–26, 2005
MIC2005. The 6th Metaheuristics International Conference 779
</note>
<tableCaption confidence="0.999509">
Table 1: Average performance over the 90 largest OR-Library instances; CPU-times: 850s.
</tableCaption>
<table confidence="0.999696818181818">
m α MA B&amp;C CO-b CO-bd
z z z z
5 0.25 120 624 120 626 120 626 120 627
0.5 219 511 219 511 219 512 219 510
0.75 302 360 302 361 302 362 302 362
10 0.25 118 586 118 591 118 600 118 595
0.5 217 295 217 306 217 308 217 308
0.75 302 573 302 582 302 582 302 582
30 0.25 115 500 115 493 115 521 115 523
0.5 216 192 216 171 216 192 216 204
0.75 302 378 302 390 302 388 302 390
</table>
<tableCaption confidence="0.981493">
Table 2: Average performance over the 90 largest OR-Library instances; long runs.
</tableCaption>
<table confidence="0.997244636363636">
m α [7] t[h] [8] t[h] MA t[h] B&amp;C t[h] CO-bd
z z z z z t[h]
5 0.25 120 623 5 120 628 8.5 120 629 0.5 120 629 0.5 120 629 0.5
0.5 219 507 5 219 512 8.5 219 509 0.5 219 512 0.5 219 511 0.5
0.75 302 360 5 302 363 8.5 302 362 0.5 302 362 0.5 302 363 0.5
10 0.25 118 600 9 118 629 7.6 118 589 0.5 118 603 0.5 118 605 0.5
0.5 217 298 9 217 326 7.6 217 296 0.5 217 310 0.5 217 317 0.5
0.75 302 575 9 302 603 7.6 302 575 0.5 302 583 0.5 302 584 0.5
30 0.25 115 547 12 115 624 33 115 509 0.5 115 520 0.5 115 550 0.5
0.5 216 211 12 216 275 33 216 196 0.5 216 213 0.5 216 222 0.5
0.75 302 404 12 302 447 33 302 379 0.5 302 400 0.5 302 408 0.5
</table>
<bodyText confidence="0.9991854">
The results of the short runs (Table 1) show an advantage for the hybrid strategies. They
always yield solutions with better or equal average objective values than the independent
algorithms. Obviously, exchanging dual variable information is fruitful for the optimization
process since the CO-bd approach yields the best average objective values for 7 out of the 9
instance sets of the OR-Library, whereas CO-b achieves best average objective values in only
5 out of the 9 instance sets. Especially for the instances with m = 30, the benefits of CO-bd
become apparent.
The cooperative approach also outperforms the individual algorithms in the case of the
longer runs (Table 2). CO-bd yields better or equal average objective values than the the
independent MA and independent B&amp;C for 8 out of the 9 instance sets. Additionally the
results of the longer runs are compared to the results presented in [7] and [8] obtained on
different computers (a 2GHz Pentium 4 machine was used in [8]). CO-bd yields almost equally
good or better results than the algorithms presented in [7] and [8] for the instances with m = 5.
For m = 10 and m = 30, better or equally good results than in [7] are achieved, whereas the
solution quality of [8] could in general not be reached.
</bodyText>
<note confidence="0.7077125">
Vienna, Austria, August 22–26, 2005
780 MIC2005. The 6th Metaheuristics International Conference
</note>
<bodyText confidence="0.8432894">
The approaches from [7] and [8] still achieve most of the best known solutions for the tested
instances. However, the main drawbacks of these approaches are their huge running times of
up to 33 hours for the largest OR-Library instances. Running CO-bd for up to 20 hours on
one instance of each type indicated that the results of [8] can be reached by our approach in
6 of 9 cases.
</bodyText>
<sectionHeader confidence="0.990975" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999888909090909">
We presented a cooperative combination of a memetic algorithm and a branch-and-cut ap-
proach for solving the MKP. The two heterogeneous algorithms run in parallel and asynchro-
nously exchange information about the ongoing optimization process. Besides primal solutions,
also dual variable values are communicated from B&amp;C to the MA for updating its repair and
local improvement strategies. The computational experiments we performed showed the ben-
efits of the cooperative approach, which yields better results than the individually executed
algorithms. The obtained results further indicate that this research direction is promising,
since many of the best known results from the literature were achieved in substantially shorter
times. Future research will be directed towards the exchange of more information about the on-
going search, such as statistical or negative information, and also towards other combinatorial
optimization problems.
</bodyText>
<sectionHeader confidence="0.999113" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997485157894737">
[1] P. C. Chu and J. Beasley. A genetic algorithm for the multiconstrained knapsack problem. Journal
of Heuristics, 4:63–86, 1998.
[2] M. Fischetti and A. Lodi. Local Branching. Mathematical Programming Series B, 98:23–47, 2003.
[3] J. Gottlieb. On the effectivity of evolutionary algorithms for multidimensional knapsack problems.
In C. Fonlupt et al., editors, Proceedings of Artificial Evolution: Fourth European Conference,
volume 1829 of LNCS, pages 22–37. Springer, 1999.
[4] H. Kellerer, U. Pferschy, and D. Pisinger. Knapsack Problems. Springer, 2004.
[5] G. R. Raidl. An improved genetic algorithm for the multiconstrained 0–1 knapsack problem. In
D. Fogel et al., editors, Proceedings of the 5th IEEE International Conference on Evolutionary
Computation, pages 207–211. IEEE Press, 1998.
[6] G. R. Raidl and J. Gottlieb. Empirical analysis of locality, heritability and heuristic bias in evolu-
tionary algorithms: A case study for the multidimensional knapsack problem. Evolutionary Com-
putation Journal, 13(4), to appear 2005.
[7] M. Vasquez and J.-K. Hao. A hybrid approach for the 0–1 multidimensional knapsack problem.
In Proceedings of the International Joint Conference on Artificial Intelligence 2001, pages 328–333,
2001.
[8] M. Vasquez and Y. Vimont. Improved results on the 0-1 multidimensional knapsack problem.
European Journal of Operational Research, 165:70–81, 2005.
Vienna, Austria, August 22–26, 2005
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.386288">
<note confidence="0.542788">MIC2005. The 6th Metaheuristics International Conference 775</note>
<title confidence="0.998053">Cooperating Memetic and Branch-and-Cut Algorithms Solving the Multidimensional Knapsack Problem</title>
<author confidence="0.998537">Günther R Martin</author>
<affiliation confidence="0.889356">of Computer Graphics and Algorithms, Vienna University of</affiliation>
<address confidence="0.722212">Favoritenstrae 9-11/1861, 1040 Vienna,</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P C Chu</author>
<author>J Beasley</author>
</authors>
<title>A genetic algorithm for the multiconstrained knapsack problem.</title>
<date>1998</date>
<journal>Journal of Heuristics,</journal>
<volume>4</volume>
<contexts>
<context position="4297" citStr="[1]" startWordPosition="656" endWordPosition="656"> including several variants of hybrid evolutionary algorithms (EAs); see [6] for a recent survey and comparison of EAs for the MKP. The basics of today’s most effective EAs go back to Chu and Beasley [1]: Candidate solutions are directly represented by their 0–1 vectors x; standard crossover and mutation operators and – most importantly – clever repair and local improvement strategies are applied. Su</context>
<context position="6643" citStr="[1]" startWordPosition="1030" endWordPosition="1030">roblem (m = 1), for example, ordering items according to increasing ratios pj/w1j is straight-forward and works generally well. In case of the MKP, an appropriate choice is much more difficult. As in [1], we determine Π by ordering the items according to pseudo-utility ratios Empj , i=1 aiwij where we set the surrogate multipliers ai to the dual variable values (i.e. shadow prices of the i-th constra</context>
<context position="7447" citStr="[1]" startWordPosition="1160" endWordPosition="1160">he MKP often lie in the neighborhood of the solution xLP to the corresponding LP relaxation. We performed an empirical in-depth examination on smaller instances of Chu and Beasley’s benchmark library [1] for which we were able to compute optimal solutions x* and observed that the Hamming distance between x* and the (possibly infeasible) rounded LP solution xRLP with xRLP j = rxLP j − 0.5e, j = 1,...,</context>
</contexts>
<marker>[1]</marker>
<rawString>P. C. Chu and J. Beasley. A genetic algorithm for the multiconstrained knapsack problem. Journal of Heuristics, 4:63–86, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fischetti</author>
<author>A Lodi</author>
</authors>
<title>Local Branching.</title>
<date>2003</date>
<journal>Mathematical Programming Series B,</journal>
<volume>98</volume>
<contexts>
<context position="7944" citStr="[2]" startWordPosition="1247" endWordPosition="1247">ion to such a neighborhood seems therefore to be highly promising. This can be done by adding a single constraint to the MKP similar to the local branching constraints presented by Fischetti and Lodi [2]. The following inequality restricts the search space to a neighborhood of Hamming distance k around the rounded LP solution xRLP: XΔ(x, xRLP) = X xj &lt; k, (6) j∈SLP (1 − xj) + j /∈SLP where SLP = {j =</context>
</contexts>
<marker>[2]</marker>
<rawString>M. Fischetti and A. Lodi. Local Branching. Mathematical Programming Series B, 98:23–47, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gottlieb</author>
</authors>
<title>On the effectivity of evolutionary algorithms for multidimensional knapsack problems.</title>
<date>1999</date>
<booktitle>Proceedings of Artificial Evolution: Fourth European Conference,</booktitle>
<volume>1829</volume>
<pages>22--37</pages>
<editor>In C. Fonlupt et al., editors,</editor>
<publisher>Springer,</publisher>
<contexts>
<context position="4861" citStr="[5, 3, 6]" startWordPosition="740" endWordPosition="742">the following. 3 The Memetic Algorithm Part The MA, which we consider here for parallel execution with B&amp;C, is based on the principles from Chu and Beasley and includes some improvements suggested in [5, 3, 6]. The MA framework is steady-state. The creation of initial solutions is guided by the LP-relaxation of the MKP, as described in [3]. Each new candidate solution is derived by selecting two parents vi</context>
</contexts>
<marker>[3]</marker>
<rawString>J. Gottlieb. On the effectivity of evolutionary algorithms for multidimensional knapsack problems. In C. Fonlupt et al., editors, Proceedings of Artificial Evolution: Fourth European Conference, volume 1829 of LNCS, pages 22–37. Springer, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kellerer</author>
<author>U Pferschy</author>
<author>D Pisinger</author>
</authors>
<title>Knapsack Problems.</title>
<date>2004</date>
<publisher>Springer,</publisher>
<contexts>
<context position="3195" citStr="[4]" startWordPosition="484" endWordPosition="484">acities, see (2). The 0–1 decision variables xj indicate which items are selected. A general overview on practical and theoretical results for the MKP can be found in the monograph by Kellerer et al. [4]. Besides exact techniques for solving small to moderately sized instances, many kinds of metaheuristics have already been applied to the MKP. To our knowledge, the method currently yielding the best </context>
</contexts>
<marker>[4]</marker>
<rawString>H. Kellerer, U. Pferschy, and D. Pisinger. Knapsack Problems. Springer, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Raidl</author>
</authors>
<title>An improved genetic algorithm for the multiconstrained 0–1 knapsack problem.</title>
<date>1998</date>
<booktitle>Proceedings of the 5th IEEE International Conference on Evolutionary Computation,</booktitle>
<pages>207--211</pages>
<editor>In D. Fogel et al., editors,</editor>
<publisher>IEEE Press,</publisher>
<contexts>
<context position="4861" citStr="[5, 3, 6]" startWordPosition="740" endWordPosition="742">the following. 3 The Memetic Algorithm Part The MA, which we consider here for parallel execution with B&amp;C, is based on the principles from Chu and Beasley and includes some improvements suggested in [5, 3, 6]. The MA framework is steady-state. The creation of initial solutions is guided by the LP-relaxation of the MKP, as described in [3]. Each new candidate solution is derived by selecting two parents vi</context>
</contexts>
<marker>[5]</marker>
<rawString>G. R. Raidl. An improved genetic algorithm for the multiconstrained 0–1 knapsack problem. In D. Fogel et al., editors, Proceedings of the 5th IEEE International Conference on Evolutionary Computation, pages 207–211. IEEE Press, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G R Raidl</author>
<author>J Gottlieb</author>
</authors>
<title>Empirical analysis of locality, heritability and heuristic bias in evolutionary algorithms: A case study for the multidimensional knapsack problem.</title>
<date>2005</date>
<journal>Evolutionary Computation Journal,</journal>
<volume>13</volume>
<issue>4</issue>
<note>to appear</note>
<contexts>
<context position="4170" citStr="[6]" startWordPosition="631" endWordPosition="631">nal variable fixing heuristic. Besides this tabu search approach, various other metaheuristics have been described for the MKP, including several variants of hybrid evolutionary algorithms (EAs); see [6] for a recent survey and comparison of EAs for the MKP. The basics of today’s most effective EAs go back to Chu and Beasley [1]: Candidate solutions are directly represented by their 0–1 vectors x; st</context>
<context position="4861" citStr="[5, 3, 6]" startWordPosition="740" endWordPosition="742">the following. 3 The Memetic Algorithm Part The MA, which we consider here for parallel execution with B&amp;C, is based on the principles from Chu and Beasley and includes some improvements suggested in [5, 3, 6]. The MA framework is steady-state. The creation of initial solutions is guided by the LP-relaxation of the MKP, as described in [3]. Each new candidate solution is derived by selecting two parents vi</context>
</contexts>
<marker>[6]</marker>
<rawString>G. R. Raidl and J. Gottlieb. Empirical analysis of locality, heritability and heuristic bias in evolutionary algorithms: A case study for the multidimensional knapsack problem. Evolutionary Computation Journal, 13(4), to appear 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vasquez</author>
<author>J-K Hao</author>
</authors>
<title>A hybrid approach for the 0–1 multidimensional knapsack problem.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence</booktitle>
<pages>328--333</pages>
<contexts>
<context position="3493" citStr="[7]" startWordPosition="530" endWordPosition="530">euristics have already been applied to the MKP. To our knowledge, the method currently yielding the best results, at least for commonly used benchmark instances, has been described by Vasquez and Hao [7] and was recently refined by Vasquez and Vimont [8]. The search space is reduced and partitioned via additional constraints, fixing the total number of items to be packed. Bounds for these constraints</context>
<context position="7198" citStr="[7, 8]" startWordPosition="1120" endWordPosition="1121">ntly, we will continuously adapt the surrogate multipliers according to more promising dual variable values when B&amp;C is performed in parallel, see Sect. 5. 4 The Branch-and-Cut Part The heuristics in [7, 8] exploit the property that good solutions to the MKP often lie in the neighborhood of the solution xLP to the corresponding LP relaxation. We performed an empirical in-depth examination on smaller ins</context>
<context position="11824" citStr="[7]" startWordPosition="1926" endWordPosition="1926"> 30 0.25 115 500 115 493 115 521 115 523 0.5 216 192 216 171 216 192 216 204 0.75 302 378 302 390 302 388 302 390 Table 2: Average performance over the 90 largest OR-Library instances; long runs. m α [7] t[h] [8] t[h] MA t[h] B&amp;C t[h] CO-bd z z z z z t[h] 5 0.25 120 623 5 120 628 8.5 120 629 0.5 120 629 0.5 120 629 0.5 0.5 219 507 5 219 512 8.5 219 509 0.5 219 512 0.5 219 511 0.5 0.75 302 360 5 302 3</context>
<context position="13353" citStr="[7]" startWordPosition="2235" endWordPosition="2235">r equal average objective values than the the independent MA and independent B&amp;C for 8 out of the 9 instance sets. Additionally the results of the longer runs are compared to the results presented in [7] and [8] obtained on different computers (a 2GHz Pentium 4 machine was used in [8]). CO-bd yields almost equally good or better results than the algorithms presented in [7] and [8] for the instances w</context>
<context position="13833" citStr="[7]" startWordPosition="2319" endWordPosition="2319">are achieved, whereas the solution quality of [8] could in general not be reached. Vienna, Austria, August 22–26, 2005 780 MIC2005. The 6th Metaheuristics International Conference The approaches from [7] and [8] still achieve most of the best known solutions for the tested instances. However, the main drawbacks of these approaches are their huge running times of up to 33 hours for the largest OR-Libr</context>
</contexts>
<marker>[7]</marker>
<rawString>M. Vasquez and J.-K. Hao. A hybrid approach for the 0–1 multidimensional knapsack problem. In Proceedings of the International Joint Conference on Artificial Intelligence 2001, pages 328–333, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vasquez</author>
<author>Y Vimont</author>
</authors>
<title>Improved results on the 0-1 multidimensional knapsack problem.</title>
<date>2005</date>
<journal>European Journal of Operational Research,</journal>
<volume>165</volume>
<location>Vienna, Austria,</location>
<marker>[8]</marker>
<rawString>M. Vasquez and Y. Vimont. Improved results on the 0-1 multidimensional knapsack problem. European Journal of Operational Research, 165:70–81, 2005. Vienna, Austria, August 22–26, 2005</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>