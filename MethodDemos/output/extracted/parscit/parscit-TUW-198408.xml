<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000609">
<title confidence="0.9972045">
Interaktive Entscheidungsunterstützung für die Auswahl von
Software-Komponenten bei mehrfachen Zielsetzungen
</title>
<author confidence="0.963709">
Thomas Neubauer
</author>
<affiliation confidence="0.88307">
Secure Business Austria - Security Research
</affiliation>
<address confidence="0.691539">
1040 Wien
</address>
<email confidence="0.905548">
neubauer@securityresearch.at
</email>
<author confidence="0.680291">
Christian Stummer
</author>
<affiliation confidence="0.4896755">
Institut für Betriebswirtschaftslehre
Universität Wien
</affiliation>
<address confidence="0.63312">
1210 Wien
</address>
<email confidence="0.860911">
christian.stummer@univie.ac.at
</email>
<sectionHeader confidence="0.98322" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999875142857143">
In der betrieblichen Praxis kommt der komponentenbasierten Software-Entwicklung hoher Stel-
lenwert zu. Angesichts mehrfacher Zielsetzungen und vielfältiger Nebenbedingungen ist dabei
insbesondere die Auswahl der „besten“ Kombination von Komponenten ein nicht-triviales Ent-
scheidungsproblem. Bislang wurden hierfür vor allem die Nutzwertanalyse bzw. der Analytic
Hierarchy Process zur Entscheidungsunterstützung vorgeschlagen, wobei aber beide eine Reihe
von Unzulänglichkeiten aufweisen. Diese Arbeit will dazu nunmehr eine Alternative anbieten.
Darin werden in einem ersten Schritt zunächst (zulässige) Pareto-effiziente Kombinationen von
Software-Komponenten berechnet und die Entscheidungsträger dann im zweiten Schritt inter-
aktiv bei der Suche nach jener Variante unterstützt, die einen Ziele-Mix in Aussicht stellt, der
den jeweiligen individuellen Präferenzen am besten entspricht. Das neue Verfahren zeichnet
sich im Vergleich zu herkömmlichen Ansätzen insbesondere durch den Verzicht auf umfang-
reiche a priori Präferenzinformationen (wie z.B. Zielgewichtungen) aus. Darüber hinaus kann es
ohne großen Anpassungsaufwand in bestehende Vorgehensmodelle zur Auswahl von Software-
Komponenten integriert werden.
</bodyText>
<sectionHeader confidence="0.983125" genericHeader="keywords">
1 Einleitung
</sectionHeader>
<bodyText confidence="0.999973520833333">
Die komponentenbasierte Software-Entwicklung unterscheidet sich vom traditionellen Vorge-
hen insbesondere dadurch, dass (bestehende) Komponenten als Grundlage für die Entwicklung
komplexer Softwarelösungen genutzt werden. Tatsächlich kommt ihr heutzutage hoher Stellen-
wert zu [Ruhe2002], da in immer kürzeren Abständen qualitativ hochwertige und zuverlässige
Software auf den Markt gebracht werden muss. Zudem steigen die funktionalen Anforderungen
an Software, so dass insbesondere kleinere Unternehmen bei der Erfüllung ihrer Aufträge
zunehmend davon abhängig sind, auf vorhandene Komponenten zurückgreifen zu können und
das Produkt nicht in allen Details von Grund auf neu entwickeln zu müssen [Alves2003].
Empirische Studien [Alves2003, Basili1996] zeigen ferner, dass durch den Rückgriff auf
bewährte Komponenten Fehler im Gesamtsystem wesentlich reduziert werden. Und schließlich
wird die komponentenbasierte Software-Entwicklung auch durch Technologien wie CORBA,
JavaBeans/EJB, DCOM/ActiveX oder .Net sowie die Verfügbarkeit von verschiedenen Tools
für die Konfiguration und den Einsatz solcher Lösungen vorangetrieben [Andrews2005].
Allerdings müssen Software-Produkte in der Regel an spezifische Anforderungen angepasst
werden. Dementsprechend spielt bei der komponentenbasierten Software-Entwicklung die Aus-
wahl der „richtigen“ Komponenten eine wesentliche Rolle mit Auswirkungen auf alle weiteren
Phasen des Entwicklungszyklus. Ineffiziente Entscheidungen haben daher nicht nur Einfluss auf
Korrektheit und Zuverlässigkeit der komponentenbasierten Anwendung, sondern können auch
zu massiven Kostensteigerungen in der Entwicklung und/oder der nachfolgenden Wartung
führen [Maiden1998,Ruhe2002,Ruhe2003].
In der Literatur finden sich zahlreiche Vorgehensmodelle für die Evaluierung und Auswahl von
Software-Komponenten (z.B. OTSO von [Kontio1995]). Nahezu alle diese Ansätze berücksich-
tigen mehrfache Zielsetzungen (wie Kosten, Kompatibilität, Einfachheit der Installation, usw.),
wobei die meisten Autoren entweder eine Nutzwertanalyse (Weighted Scoring Method; WSM)
oder den Analytic Hierarchy Process (AHP) zur Entscheidungsfindung empfehlen (vgl. u.a.
[Alves2003,Maiden1998,Navarrete2005,Ncube2002,Wanyama2005]). Tatsächlich weisen aber
beide Verfahren wesentliche Schwachstellen auf, wie insbesondere den Bedarf an umfang-
reichen Informationen über die a priori Präferenzen der Entscheidungsträger bei der Nutzwert-
analyse, die kombinatorische Explosion der paarweisen Vergleiche bei der Verwendung des
AHP oder problematische Annahmen über die Form der Nutzenfunktion (für die regelmäßig
lineare Nutzenverläufe unterstellt werden). Des Weiteren bieten solche Ansätze dem Entschei-
dungsträger lediglich eine einzelne Lösung, während es ein interaktives Verfahren erlauben
würde, unterschiedliche Szenarien zu erkunden und zu analysieren bzw. aktiv am Entschei-
dungsprozess teilzunehmen und ihn zu kontrollieren.
In dieser Arbeit stellen wir einen entsprechenden, zweiphasigen Ansatz vor. Die erste Phase
widmet sich der Ermittlung von Lösungen (d.h. Kombinationen von Software-Komponenten),
die einerseits gegebene Nebenbedingungen (wie Ressourcenbeschränkungen oder Abhängig-
keiten zwischen zwei oder mehreren Komponenten) erfüllen und andererseits Pareto-effizient1
hinsichtlich der gegebenen Zielsetzungen sind. In der zweiten Phase werden Entscheidungs-
träger bei der interaktiven Erkundung des solcherart bestimmten Lösungsraums unterstützt, bis
sie die für sie individuell „beste“ Zusammenstellung von Komponenten mit dem für sie attrak-
tivsten Mix an Zielwerten gefunden haben. Der Ansatz kann im Übrigen problemlos in beste-
hende Vorgehensmodelle für die komponentenbasierte Software-Entwicklung integriert werden.
Diese Arbeit bietet nun im Anschluss zunächst einen Überblick zum Forschungsstand hinsicht-
lich der Auswahl von Software-Komponenten bei mehrfachen Zielsetzungen. Danach be-
schreiben wir schrittweise unseren Vorschlag zur interaktiven Entscheidungsunterstützung. Die
Arbeit schließt letztlich mit einem Resümee und einem Ausblick auf in diesem Zusammenhang
interessante weiterführende Forschungsfragen.
</bodyText>
<sectionHeader confidence="0.88543" genericHeader="introduction">
2 Die Auswahl von Software-Komponenten im Überblick
</sectionHeader>
<bodyText confidence="0.999576875">
Im Folgenden liegt das Augenmerk auf Software-Komponenten, die im Rahmen einer Wieder-
verwendung Teil eines neuen Softwareprodukts werden können und dazu in der Regel schon
von vornherein nicht spezifisch für ein bestimmtes Projekt erstellt worden sind (für eine
Diskussion vgl. [Torchiano2004]). Die komponentenbasierte Software-Entwicklung zielt nun
darauf ab, mit Hilfe solcher mehrfach nutzbarer Komponenten komplexe Software-Projekte in
kürzerer Zeit bzw. mit geringerem Budget durchführen zu können. In der Praxis werden hierbei
allerdings oftmals die Risiken unterschätzt, die mit der Evaluierung, Auswahl und Integration
der Komponenten verbunden sind, so dass mitunter beträchtliche Verzögerungen bzw. Budget-
</bodyText>
<footnote confidence="0.610362">
1 Eine Lösungsalternative gilt als „Pareto-effizient“, wenn keine andere (zulässige) Lösung existiert, die in allen
betrachteten Zielsetzungen zumindest gleich gut und in mindestens einer Zielsetzung besser abschneidet.
</footnote>
<bodyText confidence="0.999896871794872">
überschreibungen für die Entwicklung oder Wartung der Systeme zu beobachten sind
[Tran1997].
In der Vergangenheit wurden mehrere Vorgehensmodelle zur Strukturierung der komponenten-
basierten Software-Entwicklung vorgeschlagen. Obgleich sie sich über weite Strecken stark
ähneln, gibt es bislang noch kein allgemein als Standard akzeptiertes Vorgehen [Ruhe2002].
Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern,
wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE
[Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998])
sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005].
Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen be-
wertet werden müssen. Eindimensionale Kennzahlen aus der Finanzwirtschaft wie etwa der
Kapitalwert greifen aber für die komplexe Bewertung von IT-Investitionen regelmäßig zu kurz,
so dass hierfür bislang die Nutzwertanalyse oder der AHP eingesetzt worden sind. Beide
Verfahren erfordern jedoch die Bekanntgabe der Form der Nutzenfunktion (wobei meist der
Einfachheit halber Linearität unterstellt wird) sowie von Gewichtungen für jedes zu berück-
sichtigende Zielkriterium. Die Nutzwertanalyse setzt dabei voraus, dass (i) sich die Entschei-
dungsträger von vornherein vollständig über alle Gewichtungen im Klaren sind, ohne jemals
zuvor eine Lösungsalternative gesehen zu haben, und (ii) auch bereit sind, diese Präferenzen
vollständig und vorbehaltlos preiszugeben, damit mit einer auf diese Weise definierten
Zielfunktion Nutzenwerte für jede Kombination von Software-Komponenten ermittelt werden
können. Demgegenüber stützt sich der AHP auf eine Hierarchie von Zielen und errechnet die
benötigten Gewichtungen durch paarweise Vergleiche aller Kriterien je Hierarchieebene (mit
Hilfe der Eigenwertmethode). Damit können nun bei korrekter Anwendung – trotz vielfacher
methodischer Kritik – tendenziell konsistentere Ergebnisse erzielt werden als mit der Nutzwert-
analyse; dies muss allerdings mit enormem Aufwand für die in großer Zahl notwendigen paar-
weisen Vergleiche erkauft werden. Maiden illustriert das anhand einer Fallstudie zu einem
Projekt mit 130 Anforderungen, bei dem die Verwendung des AHP daran scheiterte, dass die
Entscheidungsträger mehr als 42.000 Vergleiche durchführen hätten müssen [Maiden1998].
Generell scheint jeder Versuch, die vielfältigen Aspekte der Komponentenauswahl bei der
Software-Entwicklung auf einen einzigen „Nutzenwert“ zu reduzieren, problematisch, da durch
die Aggregation verschiedener Ziele zu einem einzigen Indikator nicht zuletzt individuelle
Attribute und somit die Information über besondere Schwächen oder Stärken verloren gehen.
Daher kann eine hohe Bewertung in einem Ziel eine schlechte Leistung in einem anderen
Kriterium (gleichsam automatisch) ausgleichen und solcherart ein potentielles Risiko unent-
deckt bleiben [Ncube2002]. Forscher wie Praktiker vertreten deshalb vielfach die Auffassung,
dass traditionelle Methoden bei der Bewertung von Software-Komponenten ungeeignet sind
[Martinsons1998,Ryan2004] und Entscheidungsträger bessere Unterstützung bei der Bewertung
von Kombinationen von Software-Komponenten und der entsprechenden Verteilung von Res-
sourcen hinsichtlich der damit verbundenen Nutzen und Risiken benötigen.
</bodyText>
<sectionHeader confidence="0.99397" genericHeader="method">
3 Ein interaktives Entscheidungsunterstützungssystem
</sectionHeader>
<bodyText confidence="0.9999295">
Der nachfolgend vorgestellte neue Ansatz möchte eine geeignete Alternative bieten. Er zeichnet
sich insbesondere dadurch aus, dass Entscheidungsträger weder umfangreiche a priori Prä-
ferenzinformationen bereitstellen noch zahlreiche paarweise Vergleiche anstellen müssen.
Stattdessen wird zuerst – ohne aktives Zutun der Entscheidungsträger – die Menge der Pareto-
effizienten Kombinationen von Software-Komponenten bestimmt und im Anschluss die
Möglichkeit geboten, darin interaktiv nach jener Lösung zu suchen, die den individuellen
Präferenzen am besten entspricht. Vor einer detaillierten Diskussion der beiden Phasen des
interaktiven Entscheidungsunterstützungssystems soll zunächst noch ein typisches Vorgehens-
modell für die komponentenbasierte Software-Entwicklung skizziert werden, um zu zeigen, in
welcher Phase unser Ansatz zum Einsatz kommen würde.
</bodyText>
<subsectionHeader confidence="0.99873">
3.1 Das Vorgehensmodell OTSO
</subsectionHeader>
<bodyText confidence="0.93522856">
Das von Kontio vorgeschlagene Modell OTSO (Off-The-Shelf Option; [Kontio1995]) gliedert
sich in die nachfolgend beschriebenen fünf Phasen.
1. Definition der Kriterien: Im ersten Schritt werden die relevanten Zielkriterien bestimmt mit
besonderem Augenmerk auf die Infrastruktur der Organisation, die Applikationsarchitektur, das
Applikationsdesign, Anforderungen an die Applikation, Projektziele und -einschränkungen und
die grundsätzliche Verfügbarkeit von Software-Komponenten bzw. -bibliotheken. Die Auswahl
der Kriterien muss für jedes Vorhaben separat (z.B. unter Verwendung von GQM [Basili1987])
durchgeführt werden, da etwa funktionale Anforderungen regelmäßig für jede Applikation
unterschiedlich sind. Typische Kriterien gliedern sich grob in vier Kategorien, nämlich: (i)
Funktionale Kriterien, die auf Basis der Geschäftsprozesse definiert werden und deren
Erfüllung üblicherweise ein besonders hoher Stellenwert zukommt; (ii) Qualitätskriterien, wie
beispielsweise die Fehlerrate, Leistungsmaßzahlen, Benutzerfreundlichkeit oder Sicherheit; (iii)
Strategische Kriterien mit einem Fokus auf Kosten, Zeitaspekten oder verfügbarem Personal
und dessen Qualifikationen; und (iv) Einsatzspezifische und architekturrelevante Kriterien, die
eine Rolle spielen, sofern dadurch Vorgaben oder Einschränkungen für das zu realisierende
Softwareprodukt bedingt sind.
2. Identifikation der Komponenten: Dieser Schritt umfasst die Identifikation von potentiellen
Komponenten, die beispielsweise untergliedert werden können in (i) Betriebssysteme (etwa
AIX, FreeBSD, Linux, Microsoft Windows Server, QNX, Solaris), (ii) Middleware (BEA
Weblogic, IBM Websphere, OpenORB, Oracle Application Server, Visibroker und weitere
Komponenten wie z.B. CRM, DMS, ERP, SCM, SRM, die von unterschiedlichen Firmen
angeboten werden), (iii) Datenbanken (Hypersonic SQL, Microsoft Access, Microsoft SQL
Server, MySQL, Oracle DB, PostgreSQL) und (iv) Support Software (Agent++, Apache
Tomcat, Hypertext Preprocessor, IBM Java Runtime Environment, Intel COPS Client, Log4J,
Telia BER Coder, WebMacro, Xerces, XMLDB) [Morisio2002].
</bodyText>
<listItem confidence="0.99343">
3. Screening: In dieser Phase sollen – zunächst einmal isoliert von den anderen – vielver-
sprechende Komponenten für eine anschließende, umfassendere Evaluierung gefiltert werden.
4. Evaluierung: In der Evaluierungsphase erfolgt die Konsolidierung und gründliche Eva-
luierung der zuvor identifizierten Komponenten in Bezug auf die im ersten Schritt festgelegten
Kriterien sowie die Dokumentation der Ergebnisse.
5. Analyse: In der Analysephase bestimmen die Entscheidungsträger die für die Umsetzung der
Anforderungen „beste“ Kombination an Komponenten. Dazu wird in OTSO der AHP einge-
setzt.
</listItem>
<subsectionHeader confidence="0.998339">
3.2 Die Bestimmung effizienter Kombinationen von Software-Komponenten
</subsectionHeader>
<bodyText confidence="0.982365366666667">
Unser Ansatz ist zum Einsatz in der letzten Phase des eben umrissenen Vorgehensmodells
konzipiert und würde dort den althergebrachten AHP ersetzen. Der erste Schritt zielt dabei auf
die Ermittlung der hinsichtlich der betrachteten Ziele Pareto-effizienten Kombinationen von
Software-Komponenten. Dazu ist das zugrunde liegende multikriterielle kombinatorische Opti-
mierungsproblem (zur multiobjective combinatorial optimization (MOCO) vgl. [Ehrgott2000])
zu lösen. Binäre Entscheidungsvariablen xi ∈ { 0, 1} geben darin an, ob eine Komponente i in
einer Lösung verwendet wird oder nicht ( xi =1 falls ja, ansonsten xi = 0 ). Eine Kombination
von Komponenten wird durch einen Vektor x = (x1,..., xN ) mit Einträgen für alle N zur Wahl
stehenden Komponenten abgebildet. Im MOCO-Problem sind nun K Zielfunktionen uk (x)
(k =1,..., K ) (z.B. für die Funktionalität, Verwendbarkeit oder die Zuverlässigkeit) zu maxi-
mieren bzw. gegebenenfalls (etwa bei den Kosten) zu minimieren. Die Funktionen uk (x)
können dabei beliebige Formen annehmen, solange sie für alle zulässigen Kombinationen von
Software-Komponenten definiert sind. Dabei können auch vielfältige Abhängigkeiten zwischen
zwei oder mehreren Komponenten (bedingt z.B. durch Synergie- oder Kannibalismuseffekte)
berücksichtigt werden; vgl. [Stummer2003] für eine detaillierte Diskussion am Beispiel der
Auswahl von F&amp;E-Portfolios.
Jedweder Berechnungsalgorithmus, der in dieser ersten Phase zum Einsatz kommt, muss alle
(oder zumindest nahezu alle) effizienten MOCO-Lösungen ermitteln und dabei insbesondere
Nebenbedingungen aus zwei Gruppen berücksichtigen. Solche aus der ersten Gruppe betreffen
typischerweise Ressourcenbeschränkungen (etwa bei den Entwicklungs- oder Wartungskosten).
Sie haben daher in der Regel die Form L riqxi &lt;_ R ( q = 1,..., Q ), wobei riq für die Menge an
qi
von Komponente i nachgefragten Ressourcen vom Typ q steht und Parameter Rq das Gesamt-
budget für diesen Ressourcentyp angibt. Im Falle von Synergie- oder Kannibalismuseffekten
müssen wiederum entsprechende Korrekturterme ergänzt werden. Nebenbedingungen aus der
zweiten Gruppe gewährleistet, dass jedenfalls eine Mindestzahl bzw. nicht mehr als eine
Maximalanzahl von Komponenten aus einer vorab festgelegten Teilmenge ausgewählt werden.
Zum Beispiel könnte vorgegeben werden, dass in jeder gültigen Lösung aus jeder Architektur-
schicht mindestens eine Komponente enthalten sein muss, falls der Benutzer etwa eine
mehrschichtige Architektur abbilden möchte. Wenn das sechs Komponenten mit den Indizes 1
</bodyText>
<page confidence="0.768964">
6
</page>
<bodyText confidence="0.976474125">
bis 6 betrifft, lautet die entsprechende Nebenbedingung: L&amp;gt;_ .
xi 1
i=1
Das MOCO-Problem ist NP-schwer, da sich der Suchraum mit jeder hinzukommenden Kom-
ponente verdoppelt. Abhängig vom Umfang – bestimmt insbesondere durch die Anzahl der zur
Wahl stehenden Software-Komponenten, die Zahl an Zielen sowie Zahl und Typ der Abhängig-
keiten zwischen den Komponenten – kann es entweder exakt durch vollständige Enumeration
aller Kombinationen von Komponenten (bei 30 Komponenten wären das mehr als eine
</bodyText>
<equation confidence="0.5960895">
Milliarde ( 30
2 &amp;gt;1,07.10 9) zu evaluierende Alternativen) oder mit Hilfe von (Meta-)Heuristiken gelöst werden. Als Daumenregel gilt, dass letztere ab etwa vierzig Komponenten
</equation>
<bodyText confidence="0.9999495">
zum Einsatz kommen. Sie können zwar keine Garantie für das Auffinden aller Pareto-effizien-
ten MOCO-Lösungen geben, ermitteln aber regelmäßig in einem Bruchteil der für die voll-
ständige Enumeration benötigten Zeit bereits einen Großteil der gesuchten Lösungen; einen
Überblick zu Metaheuristiken für MOCO-Probleme bietet [Ehrgott2004], Anwendungsbeispiele
mit Leistungsvergleichen finden sich etwa bei [Doerner2006,Stummer2005]. Nichtsdestotrotz
kann die vollständige Enumeration auch bei einer höheren Anzahl an Komponenten noch in
praktikabler Zeit durchlaufen werden, sofern den Suchraum stark einschränkende Abhängig-
keiten existieren (z.B. wenn aus jeder Architekturschicht exakt eine Alternative zu wählen ist).
</bodyText>
<subsectionHeader confidence="0.993329">
3.3 Zwei Varianten für die interaktive Suche im Lösungsraums
</subsectionHeader>
<bodyText confidence="0.99995025">
In der zweiten Phase unterstützt das System den Entscheidungsträger bei der endgültigen
Auswahl jener Kombination von Software-Komponenten, die am besten seinen Präferenzen
entspricht. Angesichts eines Lösungsraums, der unter Umständen mehrere tausend Elemente
umfasst, kommt eine simple Auflistung sicherlich nicht in Frage. Stattdessen bietet das System
zwei alternative Varianten für die interaktive „Erforschung“ des Lösungsraums.
Die erste erlaubt es, sich durch Verschieben von unteren bzw. oberen Schranken für beliebige
Ziele rasch im Lösungsraum zu bewegen. Das Entscheidungsunterstützende System (EUS)
beginnt dazu mit der Anzeige von K „fliegenden“ Säulen (vgl. Abbildung 1).
</bodyText>
<subsectionHeader confidence="0.655193">
Abbildung 1: Status des EUS zu Beginn der interaktiven Auswahl
</subsectionHeader>
<bodyText confidence="0.9997778">
Für jedes Ziel (vgl. Abbildung 2) bietet das System Informationen über (i) die Zielwerte, die mit
zumindest einer der effizienten Lösungen machbar wären (die kurzen Markierungen auf der
linken Seite können dazu optisch zu schmalen Säulen zusammenwachsen, wenn sie knapp bei-
einander liegen) sowie (ii) den Zielgrößenbereich, der mit den – unter Bedachtnahme auf die
bereits gesetzten Ober- bzw. Untergrenzen – noch verbliebenen Lösungen erreicht werden kann.
</bodyText>
<subsectionHeader confidence="0.386461">
Abbildung 2: Detaillierte Darstellung
</subsectionHeader>
<bodyText confidence="0.999923875">
Die beweglichen, horizontalen Linien mit den kleinen Pfeilen auf einer Seite symbolisieren die
oberen und unteren Schranken und erlauben die schrittweise Einschränkung (z.B. durch An-
heben der unteren Schranke in einem Ziel) oder Ausweiterung (z.B. durch Hinaufsetzen einer
oberen Schranke) der Menge jener Pareto-effizienten MOCO-Lösungen, die gegen keine der
bislang gesetzten Schranken verstoßen. Damit kann der Entscheidungsträger spielerisch Vorga-
ben machen und erhält vom System unmittelbare Rückmeldung über deren Auswirkungen. So
illustriert etwa Abbildung 3 die Rückmeldung, nachdem die Obergrenze für die Entwicklungs-
kosten gesenkt worden ist.
</bodyText>
<subsectionHeader confidence="0.488868">
Abbildung 3: Status des DSS nach einer ersten Einschränkung
</subsectionHeader>
<bodyText confidence="0.999869625">
Dadurch scheiden nämlich jene Lösungsalternativen mit besonders hohen Entwicklungskosten
(häufig auch korreliert mit höherem Personalbedarf), jedoch oftmals auch niedrigeren
Wartungskosten bzw. höherer Funktionalität aus. Dementsprechend schrumpfen die, durch die
fliegenden Balken repräsentierten, Intervalle der nunmehr noch in den anderen Zielen
erreichbaren Werte. Eine anschließende Erhöhung der unteren Schranke in der Kategorie
„Funktionalität“ führt zu einer weiteren Reduktion der Alternativen auf jene, die beide Vor-
gaben (d.h. reduzierte Entwicklungskosten und höhere Mindest-Funktionalität) erfüllen, wobei
hierbei insbesondere kostengünstigere Alternativen wegfallen (vgl. Abbildung 4).
</bodyText>
<subsectionHeader confidence="0.756219">
Abbildung 4: Status des DSS nach einer zweiten Einschränkung
</subsectionHeader>
<bodyText confidence="0.985131161290323">
In weiteren Iterationen erlaubt das System dem Entscheidungsträger die spielerische Modifi-
kation beliebig vieler oberer und unterer Schranken und ermöglicht ihm damit, unmittelbar die
Konsequenzen seiner Vorgaben zu erfahren. Er gewinnt auf diese Weise ein besseres „Gefühl“
für das Entscheidungsproblem und sollte schließlich auf jene Lösung stoßen, die für ihn den
„besten“ Mix an Zielwerten bietet und bei der er nicht mehr bereit ist, weitere Kompromisse
zwischen den Zielen einzugehen. Dabei hat er – im Gegensatz zu herkömmlichen Verfahren –
weder explizit Gewichtungen für einzelne Ziele anzugeben noch muss er tausende paarweise
Vergleiche über sich ergehen lassen. Stattdessen erhält er umfassende Informationen über das
Auswahlproblem und kann sich darauf verlassen, dass jede angebotene Lösung effizient ist und
somit keine Alternative existiert, die objektiv „besser“ wäre.
Im zweiten von uns vorgeschlagene Ansatz für die interaktive Suche im Lösungsraum präsen-
tiert das EUS dem Entscheidungsträger in jeder von mehreren Runden die Zielwerte für bis zu
sieben Kombinationen von Software-Komponenten, aus denen die jeweils attraktivste zu
wählen ist (vgl. Abbildung 5 für ein Beispiel mit vier Lösungen). Die Beschränkung auf maxi-
mal sieben Alternativen ist psychologisch begründet, weil Menschen sieben plus/minus zwei
Elemente gerade noch gut vergleichen können.
Abbildung 5: Auswahl mit Hilfe von Cluster-Repräsentanten
Anfangs unterscheiden sich die Zielwerte der Lösungsvorschläge in hohem Maße, so dass hier
vor allem Richtungsentscheidungen (etwa hohe Funktionalität vs. geringe Kosten) zu treffen
sind. Später wird die Suche verfeinert und die Unterschiede zwischen den angebotenen
Lösungen werden zusehends geringer. Methodisch kommt das k-means-Clustering zum Einsatz.
Aus den damit aus der Gesamtmenge aller effizienten Lösungen bestimmten sieben Clustern
werden dem Entscheidungsträger Repräsentanten angeboten. Jenes Cluster, aus dem der dann
gewählte Vertreter stammt, wird in der nächsten Iteration weiter in Sub-Cluster unterteilt usw.,
bis sich der Entscheidungsträger letztlich für ein Cluster entscheidet, das nur mehr eine einzige
Lösung enthält. Bildlich gesprochen „taucht“ er dabei gleichsam in den Lösungsraum ein und
bewegt sich zuerst in großen, dann später immer kleineren Kreisen an die für ihn individuell
attraktivste Lösung heran. Dies funktioniert in aller Regel recht rasch, weil im Durchschnitt
jedes Cluster nur ein Siebentel der noch verbliebenen Lösungen enthält. Selbst bei etwa 20.000
effizienten Lösungen sind daher im Mittel lediglich um die fünf, mit hoher Wahrscheinlichkeit
aber jedenfalls nicht mehr als zehn Iterationen nötig.
</bodyText>
<sectionHeader confidence="0.972347" genericHeader="method">
4 Resümee und Ausblick
</sectionHeader>
<bodyText confidence="0.999959961538461">
Entscheidungsträger sehen sich bei der komponentenbasierten Software-Entwicklung regel-
mäßig mit der Herausforderung konfrontiert, aus einem großen Pool von Komponenten die
„beste“ Kombination zusammen zu stellen. Diese Aufgabe wird nicht nur durch eine oftmals
große Zahl an alternativen Komponenten (auf verschiedenen architektonischen Ebenen), son-
dern auch durch Abhängigkeiten zwischen einzelnen Komponenten bzw. nicht zuletzt durch
mehrere divergierende Zielsetzungen verkompliziert. In diesem Aufsatz haben wir einen zwei-
phasigen Ansatz zur Entscheidungsunterstützung bei der Auswahl von Software-Komponenten
entwickelt, der als Erweiterung in bestehende Vorgehensmodelle für die komponentenbasierte
Softwareentwicklung integriert werden kann und insbesondere Probleme und Unzulänglich-
keiten, die bei herkömmlichen Verfahren wie der Nutzwertanalyse oder dem AHP auftreten,
überwindet.
Wie alle anderen Verfahren hängt auch unseres von der Verfügbarkeit geeigneter Zielfunktio-
nen bzw. der Qualität der in der Evaluierungsphase erhobenen Daten ab. So ist es sicherlich
nicht trivial, eine geeignete Funktion für die Zuverlässigkeit einer Kombination von Software-
Komponenten aufzustellen. Damit wollen wir uns im Zuge weiterer Forschungsaktivitäten be-
schäftigen, wobei wir hierfür etwa das Einbeziehen der unmittelbar betroffenen Praktiker im
Rahmen von Workshops ins Auge gefasst haben (für ein Beispiel vgl. [Neubauer2006]).
Darüber hinaus gibt es eine Reihe weiterer interessanter Fragestellungen. So sollten Aspekte der
Ungewissheit berücksichtigt werden, um bei Bedarf bewusst robuste Zusammenstellungen von
Software-Komponenten erzwingen zu können, die dann weniger anfällig für sich ändernde
Systemanforderungen wären. Im MOCO-Modell ließe sich das in einem ersten Schritt mit
stochastischen Zufallsvariablen und dann über Quantilswerte als separate Ziele umsetzen (für
ein Beispiel vgl. [Medaglia2006]). Des Weiteren könnten vermehrt Ideen aus der Literatur zu
Gruppenentscheidungen bzw. der Verhandlungsanalyse übernommen werden. Und schließlich
sollen Feldstudien Aufschluss über die Eignung unterschiedlicher (grafischer) Benutzerschnitt-
stellen geben.
</bodyText>
<sectionHeader confidence="0.943101" genericHeader="method">
Literaturverzeichnis
</sectionHeader>
<reference confidence="0.999851">
[Alves2001] C. Alves, J. Castro (2001) CRE: A systematic method for COTS components
selection. Proceedings of the XV Brazilian Symposium on Software Engi-
neering.
[Alves2003] C. Alves, A. Finkelstein (2003) Investigating conflicts in COTS decisionmaking.
International Journal of Software Engineering and Knowledge Engineering, 13.
Jg., H. 5, S. 473-495.
[Andrews2005] A. A. Andrews, A. Stefik, N. Picone, S. Ghosh (2005) A COTS component
comprehension process. Proceedings of the 13th International Workshop on
Program Comprehension (IWPC’05), IEEE, S. 135-144.
[Basili1987] V. R. Basili, H. Rombach (1987) Tailoring the software process to project goals
and environments. Proceedings of the 9th International Conference on Software
Engineering. IEEE, S. 345-357.
[Basili1996] V. R. Basili, L. C. Briand, W. L. Melo (1996) How reuse influences productivity
in object-oriented systems. Communications of the ACM, 39. Jg., H. 10, S. 104-
116.
[Doerner2006] K. F. Doerner, W. J. Gutjahr, R. F. Hartl, C. Strauss, C. Stummer (2006) Nature-
inspired metaheuristics for multiobjective activity crashing. Omega, im Druck.
[Ehrgott2000] M. Ehrgott, X. Gandibleux (2000) A survey and annotated bibliography of
multiobjective combinatorial optimization. OR Spectrum, 22. Jg., H. 4, S. 425-
460.
[Ehrgott2004] M. Ehrgott, X. Gandibleux (2004) Approximative solution methods for multi-
objective combinatorial optimization. Top, 12. Jg., H. 1, S. 1-63.
[Kontio1995] J. Kontio (1995) OTSO: A systematic process for reusable software component
selection. Institute for Advanced Computer Studies and Department of
Computer Science, University of Maryland, Arbeitspapier.
[Kunda2003] D. Kunda (2003) STACE: Social technical approach to COTS software
evaluation. Component-Based Software Quality: Methods and Techniques,
Springer LNCS 2693, S. 64-84.
[LozanoTello2002] A. Lozano-Tello, A. Gomez-Perez (2002) BAREMO: How to choose the
appropriate software component using the Analytic Hierarchy Process. Pro-
ceedings of the 14th International Conference on Software Engineering and
Knowledge Engineering, ACM Proceedings 27, S. 781-788.
[Maiden1998] N. Maiden, C. Ncube (1998) Acquiring COTS software selection requirements.
IEEE Software, 15. Jg., H. 2, S. 46-56.
[Maiden2002] N. Maiden, H. Kim, C. Ncube (2002) Rethinking process guidance for selecting
software components. Proceedings of the First International Conference on
COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S. 151-
164.
[Martinsons1998] M. Martinsons, R. Davidson, D. Tse (1998) The balanced scorecard: A
foundation for the strategic management of information systems. Decision
Support Systems Journal, 25. Jg., H. 1, S. 71-78.
[Medaglia2006] A. Medaglia, S. Graves, J. Ringuest (2006) A multiobjective evolutionary
approach for linearly constrained project selection under uncertainty. European
Journal of Operational Research, im Druck.
[Morisio2002] M. Morisio, M. Torchiano (2002) Definition and classification of COTS: A
proposal. Proceedings of the First International Conference on COTS-Based
Software Systems (ICCBSS 2002). Springer LNCS 2255, S. 165-175.
[Navarrete2005] F. Navarrete, P. Botella, X. Franch (2005) How agile COTS selection methods
are (and can be)? Proceedings of the 31st EUROMICROConference on
Software Engineering and Advanced Applications (EUROMICRO-SEAA’05),
IEEE, S. 160-167.
[Ncube2002] C. Ncube, J. C. Dean (2002) The limitations of current decision-making tech-
niques in the procurement of COTS software components. Proceedings of the
First International Conference on COTS-Based Software Systems (ICCBSS
2002), Springer LNCS 2255, S. 176-187.
[Neubauer2006] T. Neubauer, C. Stummer, E. Weippl (2006) Workshop-based multiobjective
security safeguard selection. Proceedings of the First International Conference
on Availability, Reliability and Security (ARES&amp;apos;06). IEEE, S. 366-373.
[Ruhe2002] G. Ruhe (2002) Intelligent support for selection of COTS products. Revised
Papers from the Workshop on Web, Web-Services, and Database Systems
(NODe 2002), Springer LNCS 2593, S. 34-45.
[Ruhe2003] G. Ruhe (2003) Software engineering decision support: A new paradigm for
learning software organizations. Proceedings of the 4th International Workshop
on Advances in Learning Software Organizations (LSO 2002), Springer LNCS
2640, S. 104-113.
[Ryan2004] S. D. Ryan, M. S. Gates (2004) Inclusion of social sub-system issues in IT-
investment decisions: An empiricial assessment. Information Resources Mana-
gement Journal, 17. Jg., H. 1, S. 1-18.
[Torchiano2004] M. Torchiano, M. Morisio (2004) Overlooked aspects of COTS-based deve-
lopment. IEEE Software, 21. Jg., H. 2, S. 88-93.
[Tran1997] V. Tran, D.-B. Liu, B. Hummel (1997) Component-based systems development:
challenges and lessons learned. Software Technology and Engineering Practice.
IEEE, S. 452-462.
[Stummer2003] C. Stummer, K. Heidenberger (2003) Interactive R&amp;D portfolio analysis with
project interdependencies and time profiles of multiple objectives. IEEE Trans-
actions on Engineering Management, 50. Jg., H. 2, S. 175-183.
[Stummer2005] C. Stummer, M. Sun (2005) New multiobjective metaheuristic solution proce-
dures for capital investment planning. Journal of Heuristics, 11. Jg., H. 3, S. 183-
199.
[Wanyama2005] T. Wanyama, B. Homayoun (2005) Towards providing decision support for
COTS selection. Proceedings of the 18th IEEE Canadian Conference on Electri-
cal and Computer Engineering (CCECE 2005), IEEE, S. 908-911.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.061044">
<title confidence="0.7567855">Interaktive Entscheidungsunterstützung für die Auswahl Software-Komponenten bei mehrfachen Zielsetzungen</title>
<author confidence="0.999865">Thomas Neubauer</author>
<affiliation confidence="0.981616">Secure Business Austria - Security</affiliation>
<address confidence="0.998984">1040 Wien</address>
<email confidence="0.971793">neubauer@securityresearch.at</email>
<author confidence="0.999506">Christian Stummer</author>
<affiliation confidence="0.9646415">Institut für Universität</affiliation>
<address confidence="0.937266">1210</address>
<email confidence="0.958793">christian.stummer@univie.ac.at</email>
<abstract confidence="0.987887865771812">In der betrieblichen Praxis kommt der komponentenbasierten Software-Entwicklung hoher Stellenwert zu. Angesichts mehrfacher Zielsetzungen und vielfältiger Nebenbedingungen ist dabei insbesondere die Auswahl der „besten“ Kombination von Komponenten ein nicht-triviales Entscheidungsproblem. Bislang wurden hierfür vor allem die Nutzwertanalyse bzw. der Analytic Hierarchy Process zur Entscheidungsunterstützung vorgeschlagen, wobei aber beide eine Reihe von Unzulänglichkeiten aufweisen. Diese Arbeit will dazu nunmehr eine Alternative anbieten. Darin werden in einem ersten Schritt zunächst (zulässige) Pareto-effiziente Kombinationen von Software-Komponenten berechnet und die Entscheidungsträger dann im zweiten Schritt interaktiv bei der Suche nach jener Variante unterstützt, die einen Ziele-Mix in Aussicht stellt, der den jeweiligen individuellen Präferenzen am besten entspricht. Das neue Verfahren zeichnet sich im Vergleich zu herkömmlichen Ansätzen insbesondere durch den Verzicht auf umfangreiche a priori Präferenzinformationen (wie z.B. Zielgewichtungen) aus. Darüber hinaus kann es ohne großen Anpassungsaufwand in bestehende Vorgehensmodelle zur Auswahl von Software- Komponenten integriert werden. 1 Einleitung Die komponentenbasierte Software-Entwicklung unterscheidet sich vom traditionellen Vorgehen insbesondere dadurch, dass (bestehende) Komponenten als Grundlage für die Entwicklung komplexer Softwarelösungen genutzt werden. Tatsächlich kommt ihr heutzutage hoher Stellenwert zu [Ruhe2002], da in immer kürzeren Abständen qualitativ hochwertige und zuverlässige Software auf den Markt gebracht werden muss. Zudem steigen die funktionalen Anforderungen an Software, so dass insbesondere kleinere Unternehmen bei der Erfüllung ihrer Aufträge zunehmend davon abhängig sind, auf vorhandene Komponenten zurückgreifen zu können und das Produkt nicht in allen Details von Grund auf neu entwickeln zu müssen [Alves2003]. Empirische Studien [Alves2003, Basili1996] zeigen ferner, dass durch den Rückgriff auf bewährte Komponenten Fehler im Gesamtsystem wesentlich reduziert werden. Und schließlich wird die komponentenbasierte Software-Entwicklung auch durch Technologien wie CORBA, JavaBeans/EJB, DCOM/ActiveX oder .Net sowie die Verfügbarkeit von verschiedenen Tools für die Konfiguration und den Einsatz solcher Lösungen vorangetrieben [Andrews2005]. Allerdings müssen Software-Produkte in der Regel an spezifische Anforderungen angepasst werden. Dementsprechend spielt bei der komponentenbasierten Software-Entwicklung die Auswahl der „richtigen“ Komponenten eine wesentliche Rolle mit Auswirkungen auf alle weiteren Phasen des Entwicklungszyklus. Ineffiziente Entscheidungen haben daher nicht nur Einfluss auf Korrektheit und Zuverlässigkeit der komponentenbasierten Anwendung, sondern können auch zu massiven Kostensteigerungen in der Entwicklung und/oder der nachfolgenden Wartung führen [Maiden1998,Ruhe2002,Ruhe2003]. In der Literatur finden sich zahlreiche Vorgehensmodelle für die Evaluierung und Auswahl von Software-Komponenten (z.B. OTSO von [Kontio1995]). Nahezu alle diese Ansätze berücksichtigen mehrfache Zielsetzungen (wie Kosten, Kompatibilität, Einfachheit der Installation, usw.), wobei die meisten Autoren entweder eine Nutzwertanalyse (Weighted Scoring Method; WSM) oder den Analytic Hierarchy Process (AHP) zur Entscheidungsfindung empfehlen (vgl. u.a. [Alves2003,Maiden1998,Navarrete2005,Ncube2002,Wanyama2005]). Tatsächlich weisen aber beide Verfahren wesentliche Schwachstellen auf, wie insbesondere den Bedarf an umfangreichen Informationen über die a priori Präferenzen der Entscheidungsträger bei der Nutzwertanalyse, die kombinatorische Explosion der paarweisen Vergleiche bei der Verwendung des AHP oder problematische Annahmen über die Form der Nutzenfunktion (für die regelmäßig lineare Nutzenverläufe unterstellt werden). Des Weiteren bieten solche Ansätze dem Entscheidungsträger lediglich eine einzelne Lösung, während es ein interaktives Verfahren erlauben würde, unterschiedliche Szenarien zu erkunden und zu analysieren bzw. aktiv am Entscheidungsprozess teilzunehmen und ihn zu kontrollieren. In dieser Arbeit stellen wir einen entsprechenden, zweiphasigen Ansatz vor. Die erste Phase widmet sich der Ermittlung von Lösungen (d.h. Kombinationen von Software-Komponenten), die einerseits gegebene Nebenbedingungen (wie Ressourcenbeschränkungen oder Abhängigzwischen zwei oder mehreren Komponenten) erfüllen und andererseits hinsichtlich der gegebenen Zielsetzungen sind. In der zweiten Phase werden Entscheidungsträger bei der interaktiven Erkundung des solcherart bestimmten Lösungsraums unterstützt, bis sie die für sie individuell „beste“ Zusammenstellung von Komponenten mit dem für sie attraktivsten Mix an Zielwerten gefunden haben. Der Ansatz kann im Übrigen problemlos in bestehende Vorgehensmodelle für die komponentenbasierte Software-Entwicklung integriert werden. Diese Arbeit bietet nun im Anschluss zunächst einen Überblick zum Forschungsstand hinsichtlich der Auswahl von Software-Komponenten bei mehrfachen Zielsetzungen. Danach beschreiben wir schrittweise unseren Vorschlag zur interaktiven Entscheidungsunterstützung. Die Arbeit schließt letztlich mit einem Resümee und einem Ausblick auf in diesem Zusammenhang interessante weiterführende Forschungsfragen. 2 Die Auswahl von Software-Komponenten im Überblick Im Folgenden liegt das Augenmerk auf Software-Komponenten, die im Rahmen einer Wiederverwendung Teil eines neuen Softwareprodukts werden können und dazu in der Regel schon von vornherein nicht spezifisch für ein bestimmtes Projekt erstellt worden sind (für eine Diskussion vgl. [Torchiano2004]). Die komponentenbasierte Software-Entwicklung zielt nun darauf ab, mit Hilfe solcher mehrfach nutzbarer Komponenten komplexe Software-Projekte in kürzerer Zeit bzw. mit geringerem Budget durchführen zu können. In der Praxis werden hierbei allerdings oftmals die Risiken unterschätzt, die mit der Evaluierung, Auswahl und Integration Komponenten verbunden sind, so dass mitunter beträchtliche Verzögerungen bzw. Budget- 1Eine Lösungsalternative gilt als „Pareto-effizient“, wenn keine andere (zulässige) Lösung existiert, die in allen betrachteten Zielsetzungen zumindest gleich gut und in mindestens einer Zielsetzung besser abschneidet. überschreibungen für die Entwicklung oder Wartung der Systeme zu beobachten sind [Tran1997]. In der Vergangenheit wurden mehrere Vorgehensmodelle zur Strukturierung der komponentenbasierten Software-Entwicklung vorgeschlagen. Obgleich sie sich über weite Strecken stark ähneln, gibt es bislang noch kein allgemein als Standard akzeptiertes Vorgehen [Ruhe2002]. Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen bewertet werden müssen. Eindimensionale Kennzahlen aus der Finanzwirtschaft wie etwa der Kapitalwert greifen aber für die komplexe Bewertung von IT-Investitionen regelmäßig zu kurz, so dass hierfür bislang die Nutzwertanalyse oder der AHP eingesetzt worden sind. Beide Verfahren erfordern jedoch die Bekanntgabe der Form der Nutzenfunktion (wobei meist der Einfachheit halber Linearität unterstellt wird) sowie von Gewichtungen für jedes zu berücksichtigende Zielkriterium. Die Nutzwertanalyse setzt dabei voraus, dass (i) sich die Entscheidungsträger von vornherein vollständig über alle Gewichtungen im Klaren sind, ohne jemals zuvor eine Lösungsalternative gesehen zu haben, und (ii) auch bereit sind, diese Präferenzen vollständig und vorbehaltlos preiszugeben, damit mit einer auf diese Weise definierten Zielfunktion Nutzenwerte für jede Kombination von Software-Komponenten ermittelt werden können. Demgegenüber stützt sich der AHP auf eine Hierarchie von Zielen und errechnet die benötigten Gewichtungen durch paarweise Vergleiche aller Kriterien je Hierarchieebene (mit Hilfe der Eigenwertmethode). Damit können nun bei korrekter Anwendung – trotz vielfacher methodischer Kritik – tendenziell konsistentere Ergebnisse erzielt werden als mit der Nutzwertanalyse; dies muss allerdings mit enormem Aufwand für die in großer Zahl notwendigen paarweisen Vergleiche erkauft werden. Maiden illustriert das anhand einer Fallstudie zu einem Projekt mit 130 Anforderungen, bei dem die Verwendung des AHP daran scheiterte, dass die Entscheidungsträger mehr als 42.000 Vergleiche durchführen hätten müssen [Maiden1998]. Generell scheint jeder Versuch, die vielfältigen Aspekte der Komponentenauswahl bei der Software-Entwicklung auf einen einzigen „Nutzenwert“ zu reduzieren, problematisch, da durch die Aggregation verschiedener Ziele zu einem einzigen Indikator nicht zuletzt individuelle Attribute und somit die Information über besondere Schwächen oder Stärken verloren gehen. Daher kann eine hohe Bewertung in einem Ziel eine schlechte Leistung in einem anderen Kriterium (gleichsam automatisch) ausgleichen und solcherart ein potentielles Risiko unentdeckt bleiben [Ncube2002]. Forscher wie Praktiker vertreten deshalb vielfach die Auffassung, dass traditionelle Methoden bei der Bewertung von Software-Komponenten ungeeignet sind [Martinsons1998,Ryan2004] und Entscheidungsträger bessere Unterstützung bei der Bewertung von Kombinationen von Software-Komponenten und der entsprechenden Verteilung von Ressourcen hinsichtlich der damit verbundenen Nutzen und Risiken benötigen. 3 Ein interaktives Entscheidungsunterstützungssystem Der nachfolgend vorgestellte neue Ansatz möchte eine geeignete Alternative bieten. Er zeichnet sich insbesondere dadurch aus, dass Entscheidungsträger weder umfangreiche a priori Präferenzinformationen bereitstellen noch zahlreiche paarweise Vergleiche anstellen müssen. Stattdessen wird zuerst – ohne aktives Zutun der Entscheidungsträger – die Menge der Paretoeffizienten Kombinationen von Software-Komponenten bestimmt und im Anschluss die Möglichkeit geboten, darin interaktiv nach jener Lösung zu suchen, die den individuellen Präferenzen am besten entspricht. Vor einer detaillierten Diskussion der beiden Phasen des interaktiven Entscheidungsunterstützungssystems soll zunächst noch ein typisches Vorgehensmodell für die komponentenbasierte Software-Entwicklung skizziert werden, um zu zeigen, in welcher Phase unser Ansatz zum Einsatz kommen würde. 3.1 Das Vorgehensmodell OTSO Das von Kontio vorgeschlagene Modell OTSO (Off-The-Shelf Option; [Kontio1995]) gliedert sich in die nachfolgend beschriebenen fünf Phasen. Definition der Kriterien: ersten Schritt werden die relevanten Zielkriterien bestimmt mit besonderem Augenmerk auf die Infrastruktur der Organisation, die Applikationsarchitektur, das Applikationsdesign, Anforderungen an die Applikation, Projektziele und -einschränkungen und die grundsätzliche Verfügbarkeit von Software-Komponenten bzw. -bibliotheken. Die Auswahl der Kriterien muss für jedes Vorhaben separat (z.B. unter Verwendung von GQM [Basili1987]) durchgeführt werden, da etwa funktionale Anforderungen regelmäßig für jede Applikation unterschiedlich sind. Typische Kriterien gliedern sich grob in vier Kategorien, nämlich: (i) Funktionale Kriterien, die auf Basis der Geschäftsprozesse definiert werden und deren Erfüllung üblicherweise ein besonders hoher Stellenwert zukommt; (ii) Qualitätskriterien, wie beispielsweise die Fehlerrate, Leistungsmaßzahlen, Benutzerfreundlichkeit oder Sicherheit; (iii) Strategische Kriterien mit einem Fokus auf Kosten, Zeitaspekten oder verfügbarem Personal und dessen Qualifikationen; und (iv) Einsatzspezifische und architekturrelevante Kriterien, die eine Rolle spielen, sofern dadurch Vorgaben oder Einschränkungen für das zu realisierende Softwareprodukt bedingt sind. Identifikation der Komponenten: Schritt umfasst die Identifikation von potentiellen Komponenten, die beispielsweise untergliedert werden können in (i) Betriebssysteme (etwa AIX, FreeBSD, Linux, Microsoft Windows Server, QNX, Solaris), (ii) Middleware (BEA Weblogic, IBM Websphere, OpenORB, Oracle Application Server, Visibroker und weitere Komponenten wie z.B. CRM, DMS, ERP, SCM, SRM, die von unterschiedlichen Firmen angeboten werden), (iii) Datenbanken (Hypersonic SQL, Microsoft Access, Microsoft SQL Server, MySQL, Oracle DB, PostgreSQL) und (iv) Support Software (Agent++, Apache Tomcat, Hypertext Preprocessor, IBM Java Runtime Environment, Intel COPS Client, Log4J, Telia BER Coder, WebMacro, Xerces, XMLDB) [Morisio2002]. Screening: dieser Phase sollen – zunächst einmal isoliert von den anderen – vielversprechende Komponenten für eine anschließende, umfassendere Evaluierung gefiltert werden. Evaluierung: der Evaluierungsphase erfolgt die Konsolidierung und gründliche Evaluierung der zuvor identifizierten Komponenten in Bezug auf die im ersten Schritt festgelegten Kriterien sowie die Dokumentation der Ergebnisse. Analyse: der Analysephase bestimmen die Entscheidungsträger die für die Umsetzung der Anforderungen „beste“ Kombination an Komponenten. Dazu wird in OTSO der AHP eingesetzt. 3.2 Die Bestimmung effizienter Kombinationen von Software-Komponenten Unser Ansatz ist zum Einsatz in der letzten Phase des eben umrissenen Vorgehensmodells konzipiert und würde dort den althergebrachten AHP ersetzen. Der erste Schritt zielt dabei auf die Ermittlung der hinsichtlich der betrachteten Ziele Pareto-effizienten Kombinationen von Software-Komponenten. Dazu ist das zugrunde liegende multikriterielle kombinatorische Optimierungsproblem (zur multiobjective combinatorial optimization (MOCO) vgl. [Ehrgott2000]) lösen. Binäre Entscheidungsvariablen ∈ darin an, ob eine Komponente Lösung verwendet wird oder nicht ( falls ja, ansonsten = ). Eine Kombination Komponenten wird durch einen Vektor ) mit Einträgen für alle Wahl Komponenten abgebildet. Im MOCO-Problem sind nun (z.B. für die Funktionalität, Verwendbarkeit oder die Zuverlässigkeit) zu maxibzw. gegebenenfalls (etwa bei den Kosten) zu minimieren. Die Funktionen können dabei beliebige Formen annehmen, solange sie für alle zulässigen Kombinationen von Software-Komponenten definiert sind. Dabei können auch vielfältige Abhängigkeiten zwischen zwei oder mehreren Komponenten (bedingt z.B. durch Synergieoder Kannibalismuseffekte) berücksichtigt werden; vgl. [Stummer2003] für eine detaillierte Diskussion am Beispiel der Auswahl von F&amp;E-Portfolios. Jedweder Berechnungsalgorithmus, der in dieser ersten Phase zum Einsatz kommt, muss alle (oder zumindest nahezu alle) effizienten MOCO-Lösungen ermitteln und dabei insbesondere Nebenbedingungen aus zwei Gruppen berücksichtigen. Solche aus der ersten Gruppe betreffen typischerweise Ressourcenbeschränkungen (etwa bei den Entwicklungsoder Wartungskosten). haben daher in der Regel die Form wobei für die Menge an Komponente Ressourcen vom Typ und Parameter das Gesamtbudget für diesen Ressourcentyp angibt. Im Falle von Synergieoder Kannibalismuseffekten müssen wiederum entsprechende Korrekturterme ergänzt werden. Nebenbedingungen aus der zweiten Gruppe gewährleistet, dass jedenfalls eine Mindestzahl bzw. nicht mehr als eine Maximalanzahl von Komponenten aus einer vorab festgelegten Teilmenge ausgewählt werden. Zum Beispiel könnte vorgegeben werden, dass in jeder gültigen Lösung aus jeder Architekturschicht mindestens eine Komponente enthalten sein muss, falls der Benutzer etwa eine mehrschichtige Architektur abbilden möchte. Wenn das sechs Komponenten mit den Indizes 1 6 bis 6 betrifft, lautet die entsprechende Nebenbedingung: Das MOCO-Problem ist NP-schwer, da sich der Suchraum mit jeder hinzukommenden Komponente verdoppelt. Abhängig vom Umfang – bestimmt insbesondere durch die Anzahl der zur Wahl stehenden Software-Komponenten, die Zahl an Zielen sowie Zahl und Typ der Abhängigkeiten zwischen den Komponenten – kann es entweder exakt durch vollständige Enumeration aller Kombinationen von Komponenten (bei 30 Komponenten wären das mehr als eine ( 30 zu evaluierende Alternativen) oder mit Hilfe von gelöst werden. Als Daumenregel gilt, dass letztere ab etwa vierzig Komponenten zum Einsatz kommen. Sie können zwar keine Garantie für das Auffinden aller Pareto-effizienten MOCO-Lösungen geben, ermitteln aber regelmäßig in einem Bruchteil der für die vollständige Enumeration benötigten Zeit bereits einen Großteil der gesuchten Lösungen; einen Überblick zu Metaheuristiken für MOCO-Probleme bietet [Ehrgott2004], Anwendungsbeispiele mit Leistungsvergleichen finden sich etwa bei [Doerner2006,Stummer2005]. Nichtsdestotrotz kann die vollständige Enumeration auch bei einer höheren Anzahl an Komponenten noch in praktikabler Zeit durchlaufen werden, sofern den Suchraum stark einschränkende Abhängigkeiten existieren (z.B. wenn aus jeder Architekturschicht exakt eine Alternative zu wählen ist). 3.3 Zwei Varianten für die interaktive Suche im Lösungsraums In der zweiten Phase unterstützt das System den Entscheidungsträger bei der endgültigen Auswahl jener Kombination von Software-Komponenten, die am besten seinen Präferenzen entspricht. Angesichts eines Lösungsraums, der unter Umständen mehrere tausend Elemente umfasst, kommt eine simple Auflistung sicherlich nicht in Frage. Stattdessen bietet das System zwei alternative Varianten für die interaktive „Erforschung“ des Lösungsraums. Die erste erlaubt es, sich durch Verschieben von unteren bzw. oberen Schranken für beliebige Ziele rasch im Lösungsraum zu bewegen. Das Entscheidungsunterstützende System (EUS) dazu mit der Anzeige von Säulen (vgl. Abbildung 1). Abbildung 1: Status des EUS zu Beginn der interaktiven Auswahl Für jedes Ziel (vgl. Abbildung 2) bietet das System Informationen über (i) die Zielwerte, die mit zumindest einer der effizienten Lösungen machbar wären (die kurzen Markierungen auf der Seite können dazu optisch zu schmalen Säulen zusammenwachsen, wenn sie knapp beieinander liegen) sowie (ii) den Zielgrößenbereich, der mit den – unter Bedachtnahme auf die bereits gesetzten Oberbzw. Untergrenzen – noch verbliebenen Lösungen erreicht werden kann. Abbildung 2: Detaillierte Darstellung Die beweglichen, horizontalen Linien mit den kleinen Pfeilen auf einer Seite symbolisieren die oberen und unteren Schranken und erlauben die schrittweise Einschränkung (z.B. durch Anheben der unteren Schranke in einem Ziel) oder Ausweiterung (z.B. durch Hinaufsetzen einer oberen Schranke) der Menge jener Pareto-effizienten MOCO-Lösungen, die gegen keine der bislang gesetzten Schranken verstoßen. Damit kann der Entscheidungsträger spielerisch Vorgaben machen und erhält vom System unmittelbare Rückmeldung über deren Auswirkungen. So illustriert etwa Abbildung 3 die Rückmeldung, nachdem die Obergrenze für die Entwicklungskosten gesenkt worden ist. Abbildung 3: Status des DSS nach einer ersten Einschränkung Dadurch scheiden nämlich jene Lösungsalternativen mit besonders hohen Entwicklungskosten (häufig auch korreliert mit höherem Personalbedarf), jedoch oftmals auch niedrigeren Wartungskosten bzw. höherer Funktionalität aus. Dementsprechend schrumpfen die, durch die fliegenden Balken repräsentierten, Intervalle der nunmehr noch in den anderen Zielen erreichbaren Werte. Eine anschließende Erhöhung der unteren Schranke in der Kategorie „Funktionalität“ führt zu einer weiteren Reduktion der Alternativen auf jene, die beide Vorgaben (d.h. reduzierte Entwicklungskosten und höhere Mindest-Funktionalität) erfüllen, wobei hierbei insbesondere kostengünstigere Alternativen wegfallen (vgl. Abbildung 4). Abbildung 4: Status des DSS nach einer zweiten Einschränkung In weiteren Iterationen erlaubt das System dem Entscheidungsträger die spielerische Modifikation beliebig vieler oberer und unterer Schranken und ermöglicht ihm damit, unmittelbar die Konsequenzen seiner Vorgaben zu erfahren. Er gewinnt auf diese Weise ein besseres „Gefühl“ für das Entscheidungsproblem und sollte schließlich auf jene Lösung stoßen, die für ihn den „besten“ Mix an Zielwerten bietet und bei der er nicht mehr bereit ist, weitere Kompromisse zwischen den Zielen einzugehen. Dabei hat er – im Gegensatz zu herkömmlichen Verfahren – weder explizit Gewichtungen für einzelne Ziele anzugeben noch muss er tausende paarweise Vergleiche über sich ergehen lassen. Stattdessen erhält er umfassende Informationen über das Auswahlproblem und kann sich darauf verlassen, dass jede angebotene Lösung effizient ist und somit keine Alternative existiert, die objektiv „besser“ wäre. Im zweiten von uns vorgeschlagene Ansatz für die interaktive Suche im Lösungsraum präsentiert das EUS dem Entscheidungsträger in jeder von mehreren Runden die Zielwerte für bis zu sieben Kombinationen von Software-Komponenten, aus denen die jeweils attraktivste zu ist (vgl. Abbildung 5 für ein Beispiel mit vier Lösungen). Die Beschränkung auf maximal sieben Alternativen ist psychologisch begründet, weil Menschen sieben plus/minus zwei Elemente gerade noch gut vergleichen können. Abbildung 5: Auswahl mit Hilfe von Cluster-Repräsentanten Anfangs unterscheiden sich die Zielwerte der Lösungsvorschläge in hohem Maße, so dass hier vor allem Richtungsentscheidungen (etwa hohe Funktionalität vs. geringe Kosten) zu treffen sind. Später wird die Suche verfeinert und die Unterschiede zwischen den angebotenen Lösungen werden zusehends geringer. Methodisch kommt das k-means-Clustering zum Einsatz. Aus den damit aus der Gesamtmenge aller effizienten Lösungen bestimmten sieben Clustern werden dem Entscheidungsträger Repräsentanten angeboten. Jenes Cluster, aus dem der dann gewählte Vertreter stammt, wird in der nächsten Iteration weiter in Sub-Cluster unterteilt usw., bis sich der Entscheidungsträger letztlich für ein Cluster entscheidet, das nur mehr eine einzige Lösung enthält. Bildlich gesprochen „taucht“ er dabei gleichsam in den Lösungsraum ein und bewegt sich zuerst in großen, dann später immer kleineren Kreisen an die für ihn individuell attraktivste Lösung heran. Dies funktioniert in aller Regel recht rasch, weil im Durchschnitt jedes Cluster nur ein Siebentel der noch verbliebenen Lösungen enthält. Selbst bei etwa 20.000 effizienten Lösungen sind daher im Mittel lediglich um die fünf, mit hoher Wahrscheinlichkeit aber jedenfalls nicht mehr als zehn Iterationen nötig. 4 Resümee und Ausblick Entscheidungsträger sehen sich bei der komponentenbasierten Software-Entwicklung regelmäßig mit der Herausforderung konfrontiert, aus einem großen Pool von Komponenten die „beste“ Kombination zusammen zu stellen. Diese Aufgabe wird nicht nur durch eine oftmals große Zahl an alternativen Komponenten (auf verschiedenen architektonischen Ebenen), sondern auch durch Abhängigkeiten zwischen einzelnen Komponenten bzw. nicht zuletzt durch mehrere divergierende Zielsetzungen verkompliziert. In diesem Aufsatz haben wir einen zweiphasigen Ansatz zur Entscheidungsunterstützung bei der Auswahl von Software-Komponenten entwickelt, der als Erweiterung in bestehende Vorgehensmodelle für die komponentenbasierte Softwareentwicklung integriert werden kann und insbesondere Probleme und Unzulänglichkeiten, die bei herkömmlichen Verfahren wie der Nutzwertanalyse oder dem AHP auftreten, überwindet. Wie alle anderen Verfahren hängt auch unseres von der Verfügbarkeit geeigneter Zielfunktionen bzw. der Qualität der in der Evaluierungsphase erhobenen Daten ab. So ist es sicherlich nicht trivial, eine geeignete Funktion für die Zuverlässigkeit einer Kombination von Software- Komponenten aufzustellen. Damit wollen wir uns im Zuge weiterer Forschungsaktivitäten beschäftigen, wobei wir hierfür etwa das Einbeziehen der unmittelbar betroffenen Praktiker im Rahmen von Workshops ins Auge gefasst haben (für ein Beispiel vgl. [Neubauer2006]). Darüber hinaus gibt es eine Reihe weiterer interessanter Fragestellungen. So sollten Aspekte der Ungewissheit berücksichtigt werden, um bei Bedarf bewusst robuste Zusammenstellungen von Software-Komponenten erzwingen zu können, die dann weniger anfällig für sich ändernde Systemanforderungen wären. Im MOCO-Modell ließe sich das in einem ersten Schritt mit stochastischen Zufallsvariablen und dann über Quantilswerte als separate Ziele umsetzen (für ein Beispiel vgl. [Medaglia2006]). Des Weiteren könnten vermehrt Ideen aus der Literatur zu Gruppenentscheidungen bzw. der Verhandlungsanalyse übernommen werden. Und schließlich sollen Feldstudien Aufschluss über die Eignung unterschiedlicher (grafischer) Benutzerschnittstellen geben.</abstract>
<note confidence="0.994102578313253">Literaturverzeichnis [Alves2001] C. Alves, J. Castro (2001) CRE: A systematic method for COTS components selection. Proceedings of the XV Brazilian Symposium on Software Engineering. [Alves2003] C. Alves, A. Finkelstein (2003) Investigating conflicts in COTS decisionmaking. International Journal of Software Engineering and Knowledge Engineering, 13. Jg., H. 5, S. 473-495. [Andrews2005] A. A. Andrews, A. Stefik, N. Picone, S. Ghosh (2005) A COTS component comprehension process. Proceedings of the 13th International Workshop on Program Comprehension (IWPC’05), IEEE, S. 135-144. [Basili1987] V. R. Basili, H. Rombach (1987) Tailoring the software process to project goals and environments. Proceedings of the 9th International Conference on Software Engineering. IEEE, S. 345-357. [Basili1996] V. R. Basili, L. C. Briand, W. L. Melo (1996) How reuse influences productivity in object-oriented systems. Communications of the ACM, 39. Jg., H. 10, S. 104- 116. [Doerner2006] K. F. Doerner, W. J. Gutjahr, R. F. Hartl, C. Strauss, C. Stummer (2006) Natureinspired metaheuristics for multiobjective activity crashing. Omega, im Druck. [Ehrgott2000] M. Ehrgott, X. Gandibleux (2000) A survey and annotated bibliography of multiobjective combinatorial optimization. OR Spectrum, 22. Jg., H. 4, S. 425- 460. [Ehrgott2004] M. Ehrgott, X. Gandibleux (2004) Approximative solution methods for multiobjective combinatorial optimization. Top, 12. Jg., H. 1, S. 1-63. [Kontio1995] J. Kontio (1995) OTSO: A systematic process for reusable software component selection. Institute for Advanced Computer Studies and Department of Computer Science, University of Maryland, Arbeitspapier. [Kunda2003] D. Kunda (2003) STACE: Social technical approach to COTS software evaluation. Component-Based Software Quality: Methods and Techniques, Springer LNCS 2693, S. 64-84. [LozanoTello2002] A. Lozano-Tello, A. Gomez-Perez (2002) BAREMO: How to choose the appropriate software component using the Analytic Hierarchy Process. Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering, ACM Proceedings 27, S. 781-788. [Maiden1998] N. Maiden, C. Ncube (1998) Acquiring COTS software selection requirements. IEEE Software, 15. Jg., H. 2, S. 46-56. [Maiden2002] N. Maiden, H. Kim, C. Ncube (2002) Rethinking process guidance for selecting software components. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S. 151- 164. [Martinsons1998] M. Martinsons, R. Davidson, D. Tse (1998) The balanced scorecard: A foundation for the strategic management of information systems. Decision Support Systems Journal, 25. Jg., H. 1, S. 71-78. [Medaglia2006] A. Medaglia, S. Graves, J. Ringuest (2006) A multiobjective evolutionary approach for linearly constrained project selection under uncertainty. European Journal of Operational Research, im Druck. [Morisio2002] M. Morisio, M. Torchiano (2002) Definition and classification of COTS: A proposal. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002). Springer LNCS 2255, S. 165-175. [Navarrete2005] F. Navarrete, P. Botella, X. Franch (2005) How agile COTS selection methods are (and can be)? Proceedings of the 31st EUROMICROConference on Software Engineering and Advanced Applications (EUROMICRO-SEAA’05), IEEE, S. 160-167. [Ncube2002] C. Ncube, J. C. Dean (2002) The limitations of current decision-making techniques in the procurement of COTS software components. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S. 176-187. [Neubauer2006] T. Neubauer, C. Stummer, E. Weippl (2006) Workshop-based multiobjective security safeguard selection. Proceedings of the First International Conference on Availability, Reliability and Security (ARES&amp;apos;06). IEEE, S. 366-373. [Ruhe2002] G. Ruhe (2002) Intelligent support for selection of COTS products. Revised Papers from the Workshop on Web, Web-Services, and Database Systems (NODe 2002), Springer LNCS 2593, S. 34-45. [Ruhe2003] G. Ruhe (2003) Software engineering decision support: A new paradigm for learning software organizations. Proceedings of the 4th International Workshop on Advances in Learning Software Organizations (LSO 2002), Springer LNCS 2640, S. 104-113. [Ryan2004] S. D. Ryan, M. S. Gates (2004) Inclusion of social sub-system issues in ITinvestment decisions: An empiricial assessment. Information Resources Management Journal, 17. Jg., H. 1, S. 1-18. [Torchiano2004] M. Torchiano, M. Morisio (2004) Overlooked aspects of COTS-based development. IEEE Software, 21. Jg., H. 2, S. 88-93. [Tran1997] V. Tran, D.-B. Liu, B. Hummel (1997) Component-based systems development: challenges and lessons learned. Software Technology and Engineering Practice. IEEE, S. 452-462. [Stummer2003] C. Stummer, K. Heidenberger (2003) Interactive R&amp;D portfolio analysis with project interdependencies and time profiles of multiple objectives. IEEE Transactions on Engineering Management, 50. Jg., H. 2, S. 175-183. [Stummer2005] C. Stummer, M. Sun (2005) New multiobjective metaheuristic solution procedures for capital investment planning. Journal of Heuristics, 11. Jg., H. 3, S. 183- 199. [Wanyama2005] T. Wanyama, B. Homayoun (2005) Towards providing decision support for COTS selection. Proceedings of the 18th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE 2005), IEEE, S. 908-911.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C Alves</author>
<author>J Castro</author>
</authors>
<title>CRE: A systematic method for COTS components selection.</title>
<date>2001</date>
<booktitle>Proceedings of the XV Brazilian Symposium on Software Engineering.</booktitle>
<contexts>
<context position="7317" citStr="[Alves2001]" startWordPosition="878" endWordPosition="878">riebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen bewertet werden müssen. Eindimensionale Kennzahlen aus der Finanzwirt</context>
</contexts>
<marker>[Alves2001]</marker>
<rawString>C. Alves, J. Castro (2001) CRE: A systematic method for COTS components selection. Proceedings of the XV Brazilian Symposium on Software Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Alves</author>
<author>A Finkelstein</author>
</authors>
<title>Investigating conflicts in COTS decisionmaking.</title>
<date>2003</date>
<journal>International Journal of Software Engineering and Knowledge Engineering, 13. Jg., H.</journal>
<volume>5</volume>
<pages>473--495</pages>
<contexts>
<context position="2263" citStr="[Alves2003]" startWordPosition="270" endWordPosition="270">nehmen bei der Erfüllung ihrer Aufträge zunehmend davon abhängig sind, auf vorhandene Komponenten zurückgreifen zu können und das Produkt nicht in allen Details von Grund auf neu entwickeln zu müssen [Alves2003]. Empirische Studien [Alves2003, Basili1996] zeigen ferner, dass durch den Rückgriff auf bewährte Komponenten Fehler im Gesamtsystem wesentlich reduziert werden. Und schließlich wird die komponentenba</context>
</contexts>
<marker>[Alves2003]</marker>
<rawString>C. Alves, A. Finkelstein (2003) Investigating conflicts in COTS decisionmaking. International Journal of Software Engineering and Knowledge Engineering, 13. Jg., H. 5, S. 473-495.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A A Andrews</author>
<author>A Stefik</author>
<author>N Picone</author>
<author>S Ghosh</author>
</authors>
<title>A COTS component comprehension process.</title>
<date>2005</date>
<booktitle>Proceedings of the 13th International Workshop on Program Comprehension (IWPC’05), IEEE, S.</booktitle>
<pages>135--144</pages>
<contexts>
<context position="2695" citStr="[Andrews2005]" startWordPosition="320" endWordPosition="320">wicklung auch durch Technologien wie CORBA, JavaBeans/EJB, DCOM/ActiveX oder .Net sowie die Verfügbarkeit von verschiedenen Tools für die Konfiguration und den Einsatz solcher Lösungen vorangetrieben [Andrews2005]. Allerdings müssen Software-Produkte in der Regel an spezifische Anforderungen angepasst werden. Dementsprechend spielt bei der komponentenbasierten Software-Entwicklung die Auswahl der „richtigen“ K</context>
<context position="7357" citStr="[Andrews2005]" startWordPosition="883" endWordPosition="883">Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen bewertet werden müssen. Eindimensionale Kennzahlen aus der Finanzwirtschaft wie etwa der Kapitalwert greifen </context>
</contexts>
<marker>[Andrews2005]</marker>
<rawString>A. A. Andrews, A. Stefik, N. Picone, S. Ghosh (2005) A COTS component comprehension process. Proceedings of the 13th International Workshop on Program Comprehension (IWPC’05), IEEE, S. 135-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V R Basili</author>
<author>H Rombach</author>
</authors>
<title>Tailoring the software process to project goals and environments.</title>
<date>1987</date>
<booktitle>Proceedings of the 9th International Conference on Software Engineering. IEEE, S.</booktitle>
<pages>345--357</pages>
<contexts>
<context position="11570" citStr="[Basili1987]" startWordPosition="1408" endWordPosition="1408">ktziele und -einschränkungen und die grundsätzliche Verfügbarkeit von Software-Komponenten bzw. -bibliotheken. Die Auswahl der Kriterien muss für jedes Vorhaben separat (z.B. unter Verwendung von GQM [Basili1987]) durchgeführt werden, da etwa funktionale Anforderungen regelmäßig für jede Applikation unterschiedlich sind. Typische Kriterien gliedern sich grob in vier Kategorien, nämlich: (i) Funktionale Kriter</context>
</contexts>
<marker>[Basili1987]</marker>
<rawString>V. R. Basili, H. Rombach (1987) Tailoring the software process to project goals and environments. Proceedings of the 9th International Conference on Software Engineering. IEEE, S. 345-357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V R Basili</author>
<author>L C Briand</author>
<author>W L Melo</author>
</authors>
<title>How reuse influences productivity in object-oriented systems.</title>
<date>1996</date>
<journal>Communications of the ACM,</journal>
<volume>39</volume>
<pages>104--116</pages>
<marker>[Basili1996]</marker>
<rawString>V. R. Basili, L. C. Briand, W. L. Melo (1996) How reuse influences productivity in object-oriented systems. Communications of the ACM, 39. Jg., H. 10, S. 104-116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K F Doerner</author>
<author>W J Gutjahr</author>
<author>R F Hartl</author>
<author>C Strauss</author>
<author>C Stummer</author>
</authors>
<title>Natureinspired metaheuristics for multiobjective activity crashing. Omega,</title>
<date>2006</date>
<location>im Druck.</location>
<marker>[Doerner2006]</marker>
<rawString>K. F. Doerner, W. J. Gutjahr, R. F. Hartl, C. Strauss, C. Stummer (2006) Natureinspired metaheuristics for multiobjective activity crashing. Omega, im Druck.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ehrgott</author>
<author>X Gandibleux</author>
</authors>
<title>A survey and annotated bibliography of multiobjective combinatorial optimization.</title>
<date>2000</date>
<journal>OR Spectrum,</journal>
<volume>22</volume>
<pages>425--460</pages>
<contexts>
<context position="14188" citStr="[Ehrgott2000]" startWordPosition="1729" endWordPosition="1729">reto-effizienten Kombinationen von Software-Komponenten. Dazu ist das zugrunde liegende multikriterielle kombinatorische Optimierungsproblem (zur multiobjective combinatorial optimization (MOCO) vgl. [Ehrgott2000]) zu lösen. Binäre Entscheidungsvariablen xi ∈ { 0, 1} geben darin an, ob eine Komponente i in einer Lösung verwendet wird oder nicht ( xi =1 falls ja, ansonsten xi = 0 ). Eine Kombination von Kompone</context>
</contexts>
<marker>[Ehrgott2000]</marker>
<rawString>M. Ehrgott, X. Gandibleux (2000) A survey and annotated bibliography of multiobjective combinatorial optimization. OR Spectrum, 22. Jg., H. 4, S. 425-460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ehrgott</author>
<author>X Gandibleux</author>
</authors>
<title>Approximative solution methods for multiobjective combinatorial optimization.</title>
<date>2004</date>
<journal>Top,</journal>
<volume>12</volume>
<pages>1--63</pages>
<contexts>
<context position="17284" citStr="[Ehrgott2004]" startWordPosition="2168" endWordPosition="2168">teln aber regelmäßig in einem Bruchteil der für die vollständige Enumeration benötigten Zeit bereits einen Großteil der gesuchten Lösungen; einen Überblick zu Metaheuristiken für MOCO-Probleme bietet [Ehrgott2004], Anwendungsbeispiele mit Leistungsvergleichen finden sich etwa bei [Doerner2006,Stummer2005]. Nichtsdestotrotz kann die vollständige Enumeration auch bei einer höheren Anzahl an Komponenten noch in p</context>
</contexts>
<marker>[Ehrgott2004]</marker>
<rawString>M. Ehrgott, X. Gandibleux (2004) Approximative solution methods for multiobjective combinatorial optimization. Top, 12. Jg., H. 1, S. 1-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kontio</author>
</authors>
<title>OTSO: A systematic process for reusable software component selection.</title>
<date>1995</date>
<institution>Institute for Advanced Computer Studies and Department of Computer Science, University of Maryland, Arbeitspapier.</institution>
<contexts>
<context position="3411" citStr="[Kontio1995]" startWordPosition="401" endWordPosition="401">/oder der nachfolgenden Wartung führen [Maiden1998,Ruhe2002,Ruhe2003]. In der Literatur finden sich zahlreiche Vorgehensmodelle für die Evaluierung und Auswahl von Software-Komponenten (z.B. OTSO von [Kontio1995]). Nahezu alle diese Ansätze berücksichtigen mehrfache Zielsetzungen (wie Kosten, Kompatibilität, Einfachheit der Installation, usw.), wobei die meisten Autoren entweder eine Nutzwertanalyse (Weighted</context>
<context position="7173" citStr="[Kontio1995]" startWordPosition="861" endWordPosition="861">islang noch kein allgemein als Standard akzeptiertes Vorgehen [Ruhe2002]. Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist </context>
<context position="11047" citStr="[Kontio1995]" startWordPosition="1346" endWordPosition="1346">tware-Entwicklung skizziert werden, um zu zeigen, in welcher Phase unser Ansatz zum Einsatz kommen würde. 3.1 Das Vorgehensmodell OTSO Das von Kontio vorgeschlagene Modell OTSO (Off-The-Shelf Option; [Kontio1995]) gliedert sich in die nachfolgend beschriebenen fünf Phasen. 1. Definition der Kriterien: Im ersten Schritt werden die relevanten Zielkriterien bestimmt mit besonderem Augenmerk auf die Infrastruktur</context>
</contexts>
<marker>[Kontio1995]</marker>
<rawString>J. Kontio (1995) OTSO: A systematic process for reusable software component selection. Institute for Advanced Computer Studies and Department of Computer Science, University of Maryland, Arbeitspapier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kunda</author>
</authors>
<title>STACE: Social technical approach to COTS software evaluation.</title>
<date>2003</date>
<booktitle>Component-Based Software Quality: Methods and Techniques, Springer LNCS 2693, S.</booktitle>
<pages>64--84</pages>
<contexts>
<context position="7223" citStr="[Kunda2003]" startWordPosition="866" endWordPosition="866">s Vorgehen [Ruhe2002]. Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschie</context>
</contexts>
<marker>[Kunda2003]</marker>
<rawString>D. Kunda (2003) STACE: Social technical approach to COTS software evaluation. Component-Based Software Quality: Methods and Techniques, Springer LNCS 2693, S. 64-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lozano-Tello</author>
<author>A Gomez-Perez</author>
</authors>
<title>BAREMO: How to choose the appropriate software component using the Analytic Hierarchy Process.</title>
<date>2002</date>
<booktitle>Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering, ACM Proceedings 27,</booktitle>
<pages>781--788</pages>
<contexts>
<context position="7199" citStr="[LozanoTello2002]" startWordPosition="863" endWordPosition="863">emein als Standard akzeptiertes Vorgehen [Ruhe2002]. Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irg</context>
</contexts>
<marker>[LozanoTello2002]</marker>
<rawString>A. Lozano-Tello, A. Gomez-Perez (2002) BAREMO: How to choose the appropriate software component using the Analytic Hierarchy Process. Proceedings of the 14th International Conference on Software Engineering and Knowledge Engineering, ACM Proceedings 27, S. 781-788.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Maiden</author>
<author>C Ncube</author>
</authors>
<title>Acquiring COTS software selection requirements.</title>
<date>1998</date>
<journal>IEEE Software,</journal>
<volume>15</volume>
<pages>46--56</pages>
<contexts>
<context position="7294" citStr="[Maiden1998]" startWordPosition="875" endWordPosition="875">r-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen bewertet werden müssen. Eindimensionale Kennza</context>
<context position="9063" citStr="[Maiden1998]" startWordPosition="1108" endWordPosition="1108"> das anhand einer Fallstudie zu einem Projekt mit 130 Anforderungen, bei dem die Verwendung des AHP daran scheiterte, dass die Entscheidungsträger mehr als 42.000 Vergleiche durchführen hätten müssen [Maiden1998]. Generell scheint jeder Versuch, die vielfältigen Aspekte der Komponentenauswahl bei der Software-Entwicklung auf einen einzigen „Nutzenwert“ zu reduzieren, problematisch, da durch die Aggregation ve</context>
</contexts>
<marker>[Maiden1998]</marker>
<rawString>N. Maiden, C. Ncube (1998) Acquiring COTS software selection requirements. IEEE Software, 15. Jg., H. 2, S. 46-56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Maiden</author>
<author>H Kim</author>
<author>C Ncube</author>
</authors>
<title>Rethinking process guidance for selecting software components.</title>
<date>2002</date>
<booktitle>Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S.</booktitle>
<pages>151--164</pages>
<contexts>
<context position="7256" citStr="[Maiden2002]" startWordPosition="870" endWordPosition="870">nterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst und SCARLET [Maiden2002] (als Nachfolger von PORE [Maiden1998]) sowie CRE [Alves2001] zur zweiten Gruppe zählen [Andrews2005]. Gemeinsam ist den Verfahren, dass an irgendeiner Stelle verschiedene Lösungsalternativen bewertet</context>
</contexts>
<marker>[Maiden2002]</marker>
<rawString>N. Maiden, H. Kim, C. Ncube (2002) Rethinking process guidance for selecting software components. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S. 151-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Martinsons</author>
<author>R Davidson</author>
<author>D Tse</author>
</authors>
<title>The balanced scorecard: A foundation for the strategic management of information systems.</title>
<date>1998</date>
<journal>Decision Support Systems Journal,</journal>
<volume>25</volume>
<pages>71--78</pages>
<marker>[Martinsons1998]</marker>
<rawString>M. Martinsons, R. Davidson, D. Tse (1998) The balanced scorecard: A foundation for the strategic management of information systems. Decision Support Systems Journal, 25. Jg., H. 1, S. 71-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Medaglia</author>
<author>S Graves</author>
<author>J Ringuest</author>
</authors>
<title>A multiobjective evolutionary approach for linearly constrained project selection under uncertainty.</title>
<date>2006</date>
<journal>European Journal of Operational Research, im Druck.</journal>
<contexts>
<context position="25067" citStr="[Medaglia2006]" startWordPosition="3198" endWordPosition="3198">nde Systemanforderungen wären. Im MOCO-Modell ließe sich das in einem ersten Schritt mit stochastischen Zufallsvariablen und dann über Quantilswerte als separate Ziele umsetzen (für ein Beispiel vgl. [Medaglia2006]). Des Weiteren könnten vermehrt Ideen aus der Literatur zu Gruppenentscheidungen bzw. der Verhandlungsanalyse übernommen werden. Und schließlich sollen Feldstudien Aufschluss über die Eignung untersc</context>
</contexts>
<marker>[Medaglia2006]</marker>
<rawString>A. Medaglia, S. Graves, J. Ringuest (2006) A multiobjective evolutionary approach for linearly constrained project selection under uncertainty. European Journal of Operational Research, im Druck.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Morisio</author>
<author>M</author>
</authors>
<title>Torchiano (2002) Definition and classification of COTS: A proposal.</title>
<booktitle>Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002). Springer LNCS 2255, S.</booktitle>
<pages>165--175</pages>
<contexts>
<context position="13074" citStr="[Morisio2002]" startWordPosition="1588" endWordPosition="1588">QL, Oracle DB, PostgreSQL) und (iv) Support Software (Agent++, Apache Tomcat, Hypertext Preprocessor, IBM Java Runtime Environment, Intel COPS Client, Log4J, Telia BER Coder, WebMacro, Xerces, XMLDB) [Morisio2002]. 3. Screening: In dieser Phase sollen – zunächst einmal isoliert von den anderen – vielversprechende Komponenten für eine anschließende, umfassendere Evaluierung gefiltert werden. 4. Evaluierung: In </context>
</contexts>
<marker>[Morisio2002]</marker>
<rawString>M. Morisio, M. Torchiano (2002) Definition and classification of COTS: A proposal. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002). Springer LNCS 2255, S. 165-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Navarrete</author>
<author>P Botella</author>
<author>X Franch</author>
</authors>
<title>How agile COTS selection methods are (and can be)?</title>
<date>2005</date>
<booktitle>Proceedings of the 31st EUROMICROConference on Software Engineering and Advanced Applications (EUROMICRO-SEAA’05), IEEE, S.</booktitle>
<pages>160--167</pages>
<marker>[Navarrete2005]</marker>
<rawString>F. Navarrete, P. Botella, X. Franch (2005) How agile COTS selection methods are (and can be)? Proceedings of the 31st EUROMICROConference on Software Engineering and Advanced Applications (EUROMICRO-SEAA’05), IEEE, S. 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ncube</author>
<author>J C Dean</author>
</authors>
<title>The limitations of current decision-making techniques in the procurement of COTS software components.</title>
<date>2002</date>
<booktitle>Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S.</booktitle>
<pages>176--187</pages>
<contexts>
<context position="9627" citStr="[Ncube2002]" startWordPosition="1179" endWordPosition="1179">en gehen. Daher kann eine hohe Bewertung in einem Ziel eine schlechte Leistung in einem anderen Kriterium (gleichsam automatisch) ausgleichen und solcherart ein potentielles Risiko unentdeckt bleiben [Ncube2002]. Forscher wie Praktiker vertreten deshalb vielfach die Auffassung, dass traditionelle Methoden bei der Bewertung von Software-Komponenten ungeeignet sind [Martinsons1998,Ryan2004] und Entscheidungstr</context>
</contexts>
<marker>[Ncube2002]</marker>
<rawString>C. Ncube, J. C. Dean (2002) The limitations of current decision-making techniques in the procurement of COTS software components. Proceedings of the First International Conference on COTS-Based Software Systems (ICCBSS 2002), Springer LNCS 2255, S. 176-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Neubauer</author>
<author>C Stummer</author>
<author>E Weippl</author>
</authors>
<title>Workshop-based multiobjective security safeguard selection.</title>
<date>2006</date>
<booktitle>Proceedings of the First International Conference on Availability, Reliability and Security (ARES&amp;apos;06).</booktitle>
<pages>366--373</pages>
<publisher>IEEE, S.</publisher>
<contexts>
<context position="24582" citStr="[Neubauer2006]" startWordPosition="3137" endWordPosition="3137">im Zuge weiterer Forschungsaktivitäten beschäftigen, wobei wir hierfür etwa das Einbeziehen der unmittelbar betroffenen Praktiker im Rahmen von Workshops ins Auge gefasst haben (für ein Beispiel vgl. [Neubauer2006]). Darüber hinaus gibt es eine Reihe weiterer interessanter Fragestellungen. So sollten Aspekte der Ungewissheit berücksichtigt werden, um bei Bedarf bewusst robuste Zusammenstellungen von Software-Ko</context>
</contexts>
<marker>[Neubauer2006]</marker>
<rawString>T. Neubauer, C. Stummer, E. Weippl (2006) Workshop-based multiobjective security safeguard selection. Proceedings of the First International Conference on Availability, Reliability and Security (ARES&amp;apos;06). IEEE, S. 366-373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ruhe</author>
</authors>
<title>Intelligent support for selection of COTS products.</title>
<date>2002</date>
<booktitle>Revised Papers from the Workshop on Web, Web-Services, and Database Systems (NODe 2002), Springer LNCS 2593, S.</booktitle>
<pages>34--45</pages>
<contexts>
<context position="1841" citStr="[Ruhe2002]" startWordPosition="212" endWordPosition="212">onellen Vorgehen insbesondere dadurch, dass (bestehende) Komponenten als Grundlage für die Entwicklung komplexer Softwarelösungen genutzt werden. Tatsächlich kommt ihr heutzutage hoher Stellenwert zu [Ruhe2002], da in immer kürzeren Abständen qualitativ hochwertige und zuverlässige Software auf den Markt gebracht werden muss. Zudem steigen die funktionalen Anforderungen an Software, so dass insbesondere kle</context>
<context position="7033" citStr="[Ruhe2002]" startWordPosition="846" endWordPosition="846"> Strukturierung der komponentenbasierten Software-Entwicklung vorgeschlagen. Obgleich sie sich über weite Strecken stark ähneln, gibt es bislang noch kein allgemein als Standard akzeptiertes Vorgehen [Ruhe2002]. Andrews unterscheidet dazu zwischen „architektur-“ und „anforderungsgetriebenen“ Vertretern, wobei die erste Gruppe etwa OTSO [Kontio1995], BAREMO [LozanoTello2002], oder STACE [Kunda2003] umfasst u</context>
</contexts>
<marker>[Ruhe2002]</marker>
<rawString>G. Ruhe (2002) Intelligent support for selection of COTS products. Revised Papers from the Workshop on Web, Web-Services, and Database Systems (NODe 2002), Springer LNCS 2593, S. 34-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ruhe</author>
</authors>
<title>Software engineering decision support: A new paradigm for learning software organizations.</title>
<date>2003</date>
<booktitle>Proceedings of the 4th International Workshop on Advances in Learning Software Organizations (LSO 2002), Springer LNCS 2640, S.</booktitle>
<pages>104--113</pages>
<marker>[Ruhe2003]</marker>
<rawString>G. Ruhe (2003) Software engineering decision support: A new paradigm for learning software organizations. Proceedings of the 4th International Workshop on Advances in Learning Software Organizations (LSO 2002), Springer LNCS 2640, S. 104-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Ryan</author>
<author>M S Gates</author>
</authors>
<title>Inclusion of social sub-system issues in ITinvestment decisions: An empiricial assessment.</title>
<date>2004</date>
<journal>Information Resources Management Journal,</journal>
<volume>17</volume>
<pages>1--18</pages>
<marker>[Ryan2004]</marker>
<rawString>S. D. Ryan, M. S. Gates (2004) Inclusion of social sub-system issues in ITinvestment decisions: An empiricial assessment. Information Resources Management Journal, 17. Jg., H. 1, S. 1-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Torchiano</author>
<author>M Morisio</author>
</authors>
<title>Overlooked aspects of COTS-based development.</title>
<date>2004</date>
<journal>IEEE Software,</journal>
<volume>21</volume>
<pages>88--93</pages>
<contexts>
<context position="6031" citStr="[Torchiano2004]" startWordPosition="722" endWordPosition="722"> Wiederverwendung Teil eines neuen Softwareprodukts werden können und dazu in der Regel schon von vornherein nicht spezifisch für ein bestimmtes Projekt erstellt worden sind (für eine Diskussion vgl. [Torchiano2004]). Die komponentenbasierte Software-Entwicklung zielt nun darauf ab, mit Hilfe solcher mehrfach nutzbarer Komponenten komplexe Software-Projekte in kürzerer Zeit bzw. mit geringerem Budget durchführen</context>
</contexts>
<marker>[Torchiano2004]</marker>
<rawString>M. Torchiano, M. Morisio (2004) Overlooked aspects of COTS-based development. IEEE Software, 21. Jg., H. 2, S. 88-93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Tran</author>
<author>D-B Liu</author>
<author>B Hummel</author>
</authors>
<title>Component-based systems development: challenges and lessons learned. Software Technology and Engineering Practice.</title>
<date>1997</date>
<pages>452--462</pages>
<publisher>IEEE, S.</publisher>
<contexts>
<context position="6765" citStr="[Tran1997]" startWordPosition="814" endWordPosition="814">, die in allen betrachteten Zielsetzungen zumindest gleich gut und in mindestens einer Zielsetzung besser abschneidet. überschreibungen für die Entwicklung oder Wartung der Systeme zu beobachten sind [Tran1997]. In der Vergangenheit wurden mehrere Vorgehensmodelle zur Strukturierung der komponentenbasierten Software-Entwicklung vorgeschlagen. Obgleich sie sich über weite Strecken stark ähneln, gibt es bisla</context>
</contexts>
<marker>[Tran1997]</marker>
<rawString>V. Tran, D.-B. Liu, B. Hummel (1997) Component-based systems development: challenges and lessons learned. Software Technology and Engineering Practice. IEEE, S. 452-462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Stummer</author>
<author>K Heidenberger</author>
</authors>
<title>Interactive R&amp;D portfolio analysis with project interdependencies and time profiles of multiple objectives.</title>
<date>2003</date>
<journal>IEEE Transactions on Engineering Management,</journal>
<volume>50</volume>
<pages>175--183</pages>
<contexts>
<context position="15041" citStr="[Stummer2003]" startWordPosition="1855" endWordPosition="1855">e-Komponenten definiert sind. Dabei können auch vielfältige Abhängigkeiten zwischen zwei oder mehreren Komponenten (bedingt z.B. durch Synergie- oder Kannibalismuseffekte) berücksichtigt werden; vgl. [Stummer2003] für eine detaillierte Diskussion am Beispiel der Auswahl von F&amp;E-Portfolios. Jedweder Berechnungsalgorithmus, der in dieser ersten Phase zum Einsatz kommt, muss alle (oder zumindest nahezu alle) effi</context>
</contexts>
<marker>[Stummer2003]</marker>
<rawString>C. Stummer, K. Heidenberger (2003) Interactive R&amp;D portfolio analysis with project interdependencies and time profiles of multiple objectives. IEEE Transactions on Engineering Management, 50. Jg., H. 2, S. 175-183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Stummer</author>
<author>M Sun</author>
</authors>
<title>New multiobjective metaheuristic solution procedures for capital investment planning.</title>
<date>2005</date>
<journal>Journal of Heuristics,</journal>
<volume>11</volume>
<pages>183--199</pages>
<marker>[Stummer2005]</marker>
<rawString>C. Stummer, M. Sun (2005) New multiobjective metaheuristic solution procedures for capital investment planning. Journal of Heuristics, 11. Jg., H. 3, S. 183-199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wanyama</author>
<author>B</author>
</authors>
<title>Homayoun (2005) Towards providing decision support for COTS selection.</title>
<date>2005</date>
<booktitle>Proceedings of the 18th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE</booktitle>
<pages>908--911</pages>
<publisher>IEEE, S.</publisher>
<marker>[Wanyama2005]</marker>
<rawString>T. Wanyama, B. Homayoun (2005) Towards providing decision support for COTS selection. Proceedings of the 18th IEEE Canadian Conference on Electrical and Computer Engineering (CCECE 2005), IEEE, S. 908-911.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>