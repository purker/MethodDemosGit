<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta />
    <article-meta>
      <title-group>
        <article-title>An Evaluation of Symbol Elimination for Generating First-Order Loop Invariants MASTER'S THESIS</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <string-name>Computational Intelligence</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <contrib contrib-type="author">
          <string-name>Ioana Jucu Registration Number</string-name>
          <xref ref-type="aff" rid="aff0">0</xref>
        </contrib>
        <contrib contrib-type="editor">
          <string-name>Advisor: Priv.-Doz. Dr. Laura Kovacs</string-name>
        </contrib>
        <aff id="aff0">
          <label>0</label>
          <institution>to the Faculty of Informatics at the Vienna University of Technology</institution>
        </aff>
      </contrib-group>
      <pub-date>
        <year>2013</year>
      </pub-date>
      <fpage>18</fpage>
      <lpage>59</lpage>
      <kwd-group>
        <kwd>by</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-226016.images\img_1_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-226016.images\img_11_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-226016.images\img_14_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-226016.images\img_17_1.png" />
    </fig>
    <sec id="sec-1">
      <title>-</title>
      <p>(Signature of Advisor)
in</p>
    </sec>
    <sec id="sec-2">
      <title>Erklarung zur Verfassung der</title>
    </sec>
    <sec id="sec-3">
      <title>Arbeit</title>
      <p>Ioana Jucu
Martir Herman Sporer, Timisoara, Timis, Romania</p>
      <p>Hiermit erklare ich, dass ich diese Arbeit selbstandig verfasst habe, dass
ich die verwendeten Quellen und Hilfsmittel vollstandig angegeben habe
und dass ich die Stellen der Arbeit - einschlie lich Tabellen, Karten und
Abbildungen -, die anderen Werken oder dem Internet im Wortlaut oder
dem Sinn nach entnommen sind, auf jeden Fall unter Angabe der Quelle als
Entlehnung kenntlich gemacht habe.</p>
      <p>(Ort, Datum)
(Unterschrift Verfasserin)</p>
    </sec>
    <sec id="sec-4">
      <title>Acknowledgements</title>
      <p>I would like to express my very great appreciation to Dr. Laura Kovacs
for her valuable and constructive suggestions during the planning and
development of this research work. Her willingness to give her time so generously
has been very much appreciated.</p>
      <p>I would also like to thank Mr. Ioan Dragan for his support with one of
the tools needed.
Invariant genereation is a critical problem in proving di erent properties for
programs with loops, properties including correctnes. The problem becomes
harder with the incresing numbers of quanti ers in the property to be proven.
In this paper we study and combine di erent methods of invariant generation
in order to obtain stronger properties.</p>
    </sec>
    <sec id="sec-5">
      <title>Kurzfassung</title>
      <p>Invariant generiert ist ein kritische Problem fur Programmen mit Schleife
zum Beweisen der Eigenschaften, inclusive die Richtigkeit. Die problem wird
schwerer bei hohe Anzhal des Quantoren in die geprufte Eigenschaft. In diese
arbeit wir studiere diese Problem und versuchen combinieren verschieden
Methoden fur schwarer invariants zu beweisen.
3 Overview of Invariant Generation Methods 13
3.1 GinPink . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
3.2 Lingva . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
3.3 CppInv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
Contents
1 Introduction</p>
      <sec id="sec-5-1">
        <title>6 Conclusions</title>
      </sec>
      <sec id="sec-5-2">
        <title>7 References</title>
      </sec>
    </sec>
    <sec id="sec-6">
      <title>Contents</title>
      <p>1
55
57</p>
      <sec id="sec-6-1">
        <title>Introduction</title>
        <p>The complexity of software systems is in a continuous grow. Making sure
that di erent pieces of the same system will work together properly is a
hard task. The development of software systems imply the work of more
people working at di erent parts of it, using computer, networks, physical
devices, and over millions of lines of code in various languages. Integrating,
understanding and ensuring the reliability of such a system are necessary
task in order to make it useful.</p>
        <p>In this paper we give attention to the task of ensuring reliability. In the
past years a lot of interest was given to this task and there were developed
di erent methods to do it, but one challenge that was not yet overcome is
the analysis of loops. In particular programs dealing with arrays use loops
to process the elements, and on the strength to the unbounded nature of
this data structures analyzing and inferring properties for elements becomes
a challenging problem on its own.</p>
        <p>One way to approach this problem is to bound the loop [BCC+03],
unfolding it just a limited number of times and afterwards analyzing the new
obtained program as if no loop would occur in it. Although this approach is
successfully used in model checking techniques, the limitations of applying
it consist in the loss of completeness of the algorithm. An informal
explanation of this fact is that obtaining a proof that a bounded subset of elements
do not have a certain property is a result strong enough to consider that the
property does not hold for the entire loop, but if the property holds for the
rst n unrollings of the loop it may be the case that it will be falsi ed in
one of the following iterations that were cut o by the bound.</p>
        <p>Another approach to reason about program loops is to statically analyze
the code and extract loop properties automatically. In this thesis we follow
this approach. We are going to analyze and compare three methods that
automatically extract properties for loops. These methods are the symbol
elimination method of [KV09], the constraint-based invariant generation
approach of [LRCR13], and the postcondition-based method of [FM10]. We
analyze and compare these approaches on series of challenging academic
examples which are considered di cult to reason about.</p>
        <p>The symbol elimination technique is an automatically mechanism that
generates invariants based on the static analysis of programs, that does not
require other information from the user about the code analyzed. For this
method we use a saturation theorem prover and we choose Vampire not only
for it's capability to reason with di erent theories but also due to the fact
that is one of the fastest provers awarded several times in competitions.</p>
        <p>The constraint-based method rst analyses the code discovering every
possible path and checking if properties hold in some key points along them.
In the next chapters we are going to explain where and why a point in the
path becomes such a key point. Properties that are checked are constructed
based on a template following some rules that will also be presented later in
the paper.</p>
        <p>The third method is the only one from the three presented that needs
additional input from the user, namely a postcondition in the form of a
formula. The program makes certain changes in the formula, that will be
described later on, in order to nd valid invariants for the program.</p>
        <p>Using the invariants discovered by the constraint-based and
postconditionbased methods, in this thesis we further extend the power of symbol
elimination in order to reason about more complex loops and invariants than
in [KV09]. For doing so, we strengthen the underlining rst-order theory
reasoning engine of symbol elimination and add additional mathematical
theorems and axioms to the symbol elimination problem. The symbol
elimination problem is then further fed into a saturation theorem prover and
is successfully used to prove the intended loop invariants and properties of
the program. Our results show that theory reasoning in rst-order theorem
proving is a very challenging problem and requires a good understanding of
the necessary theory axiomatizations.</p>
      </sec>
      <sec id="sec-6-2">
        <title>Preliminaries</title>
        <p>In this section we give a brief overview of SAT solving, SMT solving and
Saturation theorem prover. Also we give insight of the mechanism of Boogie
theorem prover. These are necessary for further understanding the
mechanism of the tools we are studying in this paper, and since all of them have
at their core rst-order logic we also present its syntax and semantics.</p>
        <p>We present all the above in a step wise manner starting with
propositional logic. Based on the syntax and semantic of propositional logic it is
easier to understand the ones of rst-order logic, since the latter one
extends the expressive power of the former by introducing new characters and
concepts.</p>
        <p>In the same step wise manner we present SAT-solving and SMT-solving.
The rst problem is related to propositional logic, while the second one
makes use of the results obtained in SAT-solving as a subroutine in the
algorithm for solving problems encoded in rst-order logic.</p>
        <p>Also we present the mechanism of a saturation theorem prover, The
understanding of this concept is necessary in order to understand the di
erences between the methods of invariant generation and the properties that
make them e cient in di erent types of problems.</p>
        <p>Another point that is touched in this chapter is the higher order logic
theorem prover Boogie, that has more expressive power than the other tools
introduced in this paper and also uses a language specially created for it
that has a syntax harder to understand than the others.</p>
        <p>We are going to present how these concept interact to each other and
with the underlying theory, relating their results with the concept of program
veri cation.
2.1</p>
        <p>Propositional logic
Is a part of mathematics important for program veri cation. The least
complex component in the syntax of propositional [DW50] logic is an atom.
Every atom has a truth value, either true or false, and it represents a
statement (such as \ Roses are red.") without taking into account its internal
structure.</p>
        <p>In order to get more complex propositions the atoms can be connected
with connectives. The propositional syntax is de ned as follows:
1. If p is an atom, then p is a proposition;
2. &gt; and ? are propositions;
3. If p is a proposition, :p is a proposition;
4. if p and q are propositions, then p
f^; _; ); ,g
q is a proposition, where</p>
        <p>2</p>
        <p>Given two propositions, p and q, the following statements hold for the
described connectives:
: (\negation"), if :p is true if p is false, and false otherwise;
^(\and"), if p is true and q is true then p ^ q is true, otherwise p ^ q
is false;
_ (\or"), if one of the the two propositions are set to true then p _ q
is true, otherwise p _ q is false;
) (\if...then"), if p is true and q is true, or if q is false p ) q is true,
otherwise is false;
, (\if and only if...then"), if p and q are set to the same truth value
then p , q is true, otherwise is false;</p>
        <p>To make the propositions easier to read and write, and to save
parentheses the connectives have priorities as follows: :, ^, _, ), ,(meaning that
: binds stronger than ^, ^ binds stronger than _, etc.).</p>
        <p>The problem of determining if the atoms that form a proposition can be
given truth values in such a way that the proposition would evaluate to true
is called satis ability problem (abbreviated as SAT).</p>
        <p>Example: p; r; q are atoms in propositional logic, and p _ q ) r _ q
is a syntax correct formula. Choosing the values as follows: p ! f alse,
r ! f alse and q ! true will cause the formula to evaluate to true (since
p _ q evaluates to true, r _ q evaluates to true).</p>
        <p>Satis ability problem is an NP-complete problem[Coo71]. The
complexity and nature of this problem makes it useful in modeling di erent problems
such as digital circuits, constraint satisfaction problems, reasoning about
speci cations.
2.2</p>
        <p>SAT solvers
These are tools that are constructed to solve SAT problems [ES04]. Despite
the high complexity of the problem, very good results were obtained in
practice with yearly improvements of the solving algorithms and heuristics
for the SAT-solving contest.</p>
        <p>In gure 1 we present a scheme on how a SAT solver is used to solve a
problem.</p>
        <p>The rst step is to abstract the problem into a set of propositions.
Usually the problem can not be abstracted straightforward so some simpli
cation is needed. After nding a suitable representation of the problem as a
set of formulae use a SAT solver to nd a solution. If a solution is not nd
speci c improvements are made in order to get a more e cient search.</p>
        <p>The SAT solvers take the input formulae in a special form named
conjunctive normal form. Every propositional formula can be transformed in
an equi-satis able formula that satis es the conditions of the CNF [G.S83].
A formula is said to be in conjunctive normal form if it is a conjunction
of clauses, where a clause is a disjunction form from atoms or negation of
atoms.</p>
        <p>The next algorithm called boolean constant propagation(BCP) [TH06]
is a part of the algorithm that stays at the basis of a lot of modern SAT
solvers.This is a very short algorithm with three steps that repeat as long
as possible:
1. nd clause that contains a single literal (also named unit clause);
2. eliminate all clauses that contain the literal;
3. in all other clauses eliminate the occurrence of the negation of the
literal;</p>
        <p>The DPLL[DL62] algorithm was developed in 1962 and still used to this
day in the state of the art SAT solvers. One variant of the algorithm is this:
DPLL(F)</p>
        <p>F := BCP(F)
i f F =&gt;</p>
        <p>r e t u r n s a t i s f i a b l e
i f ? 2 F</p>
        <p>r e t u r n u n s a t i s f i a b l e
p i c k r e m a i n i n g v a r i a b l e x and l i t e r a l l 2 fx , : xg
i f DPLL(F ^ f l g ) r e t u r n s s a t i s f i a b l e</p>
        <p>r e t u r n s a t i s f i a b l e
r e t u r n DPLL(F ^ f: l g )</p>
        <p>The idea of the algorithm is simple and e cient. First boolean constant
propagation is applied, if there are no more clauses remaining, the algorithm
returns satis able, if a clause becomes empty after this step the algorithm
returns unsatis able. Otherwise a literal is selected from the remaining clauses
and DPLL is called on these clauses plus an extra unit clause containing the
selected literal.</p>
        <p>The selection of the literal has a great signi cance in the e ciency of
the SMT solver. A lot of heuristics were developed an studied in order to
get better results. These are a few ideas that were used for the heuristics:
Dynamic Largest Individual Sum[MSS99]: the literal that appears
most often in the unsatis ed clauses at the current point is chosen;
Jeroslov-Wang heuristic[Wan95]: the choices are made such that a unit
clause is soon obtained;
VSIDS[MMZ+11]: is a complex heuristic that takes into account
partial assignments that are unsatis able, and based on a directed acyclic
graph of the solution it chooses a literal that is part of the unsatis ed
clause;</p>
        <p>Although SAT cover a signi cant range of problems, propositional logic
is not expressive enough to cover other problems of practical interest, this
is why rst order logic got attention for this purpose. Since the problem of
satis ability is harder in this logic there were restrictions made with respect
to some theory. This new problem is referred to as Satis ability Modulo
Theory (SMT)[dMB11].</p>
        <p>The rst order logic (FOL) syntax is more complex[And02]. There are
two extra logical symbols to propositional logic: the quanti ers 8
(universalfor representing judgments that are true for all objects) and 9
(existentialfor representing particular judgments). There are also two other types of
symbols: functions and predicates. Function symbols together with the
predicates symbols along with their arity form the signature.</p>
        <p>Terms in FOL are de ned inductively as follows:
every variable is a term;
if t1; t2:::tn are terms and f is a function symbol with arity n then
f (t1; t2; :::tn) is a term;</p>
        <p>The signature is a countably set of predicate symbols and function
symbols together with their arity.</p>
        <p>The set of formulas are de ned inductively in the following way:
&gt; and ? are formulae;
if t1; t2:::tn are terms and p is a function symbol with arity n then
p(t1; t2; :::tn) is a formula;
if
is a formula then : is a formula;
if and ' are formulae then also
; ,g;
' is a formula where
2 f^; _; )
if</p>
        <p>is a formula and x a variable then 9x and 8x are formulae;
A variable is called free if it is not bounded by a quanti er (9, 8).</p>
        <p>Example: 8x; p(x) ) p(y), x is bounded by the existential quanti er
while y is a free variable.</p>
        <p>The semantics of a rst order logic formula is given by an interpretation.
The interpretation consist of an non-empty domain U and an interpretation
function I().</p>
        <p>The interpretation function maps in the following way given the domain
U :
every function symbol of arity 0 (constant symbol ) with a element from
the domain;
every for every function symbol f with arity &gt; 0 I(f ) : U n ! U
(for every n combination of terms the value of the function for the
combination is a value in the domain);
for every predicate symbol p with arity n I(p) : U n ! f1; 0g (for every
n combination of terms the value of the function for the combination is
a value in the set f1; 0g, 1 representing true and 0 representing f alse)
The free variables can be interpreted in two ways: either universally
quantify the formula or bound the variable to a constant in the domain.</p>
        <p>A theory in rst order logic is considered any set of formulae that do
not contain free variables[DP60]. A formula without any free variables is
also called sentence.</p>
        <p>A SMT-solver is a tool that takes as input a set of rst order formulae
and gives as output the answer satis able or unsatis able, taking into
account information and methods of some rst order theories when needed.
In gure 2 there is the structure of a modern SMT-solver [DdM06]. The
core solver in the gure refers to a solver that can solve the satis ability
problem for equality and uninterpreted functions theory, while the satellite
solver handles other theories such as arithmetical, arrays, bit vectors, or
data types. Let there be observed that the satellite solver exchanges
information only with the core solver, the core solver communicates both with
the satellite solver and the SAT-solver, and the SAT solver communicates
only with the core solver.</p>
        <p>A general algorithm for SMT solver [AAR09]is presented in the following
lines:</p>
        <p>SAT v a l u e SMT solver (T f o r m u l a
0 = converttocnf ( )
) f</p>
        <p>The algorithm takes as input a a formula in the theory T an outputs
satis able or unsatis able. The rst step is to convert the formula in it's
CNF form and store this form in a new variable 0 . 0 is abstracted into
its propositional form (by the (T 2P ) function) and stores the new
propositional formula in p. The DPLL algorithm takes as input the propositional
formula and either returns unsatis able which makes the initial algorithm
to return unsatis able, or it returns a satisfying assignment on the literals
of the formula. The T solver then checks the mapping of the formula back
to the theory (with the assignment proposed by SAT-solver) and either
returns satis able, which causes the main algorithm to exit with the status
satis able, or it returns a set of literals that caused an inconsistency in the
theory. is abstractive to propositional logic and its negation is conjuncted
with the rest of the abstractisation of the formula formula, and DPLL is
called again on the new obtained formula.</p>
        <p>Given a hypotheses (in this case this is the formula) if we can reach the
empty set (refutation) by using an inference system, this would give us a
refutation proof. An inference system is a set of inference rules. An inference
rule is can be described as being an n-ary relation on formulas, with n 0.
The elements of such relations are called inferences and usually written as
F1:::Fn .</p>
        <p>F</p>
        <p>Algorithms were developed in order to obtain interpolants and invariants
from the proofs of unsatis ability outputted by an SMT-solver.</p>
        <p>A theorem prover is a tool used to prove theorems in di erent logics. A
speci c type of theorem provers are the saturation theorem provers. We say
that a set of formulas is saturated with respect to an inference system I if
we can nd another set of formulas containing the initial one that is closed
under inference with respect to I[KV09].</p>
        <p>The saturation theorem prover.Vampire, used for this study is using a
superposition inference system. In order to give a brief description of this
system rst we introduce the notion of simpli cation ordering on terms[KVar].
If an ordering has the following properties it is considered a simpli cation
ordering:
is well-founded, that is there exists no in nite sequence of terms t0; t1; : : :
such that t0 t1 : : :;
is monotonic: if l
r, then s[l]</p>
        <p>s[r] for all terms s; l; r;
is stable under substitutions: if l r, then l r (where a
substitution is considered a simultaneously replacement of all occurrences of
a set of terms with another corresponding set of terms,respectively, in
a formula);
has the subterm property: if r is a subterm of l and l 6= r, then l</p>
        <p>A selection function is a function that selects one or more literals from
a non-empty clause. In what follows, selected literals will be underlined (if
L is a selected literal then it would be written as L). A uni er of two
expression is a substitution that would make the expressions equal. The
inference rules for a superposition inference system are the following:
Resolution:
where is a mgu of A and A0.</p>
        <p>Factoring :
where is a mgu of A and A0.</p>
        <p>Superposition:</p>
        <p>A _ C1</p>
        <p>:A0 _ C2
(C1 _ C2)
A _ A0 _ C
(A _ C)
l = r _ C1</p>
        <p>L[s] _ C2 l = r _ C1</p>
        <p>t[s] = t0 _ C2
(L[r] _ C1 _ C2)
l = r _ C1
(t[r] = t0 _ C1 _ C2)
t[s] 6= t0 _ C2
(t[r] 6= t0 _ C1 _ C2)
where the following hold: is an mgu for l and s, s is not a variable,
l , in the rst rule L[s] is not an quality literal, in the last two rules
t[s] .</p>
        <p>Equality Resolution:
where is the mgu of s and t.</p>
        <p>Equality factoring :
s 6= t _ C</p>
        <p>C
s = t _ s0 = t0 _ C
(s = t _ t 6= t0 _ C)
where is an mgu of s and s0, t s , t0 t .</p>
        <p>A set S of clauses is saturated with respect to an inference system if for
every possible combination of the clauses and for every rule in the system,
a clause that is already in the system is inferred. A saturation algorithm
is considered fair if all possible combinations of clauses and every rule get
a chance to be applied at one point. In order for such an algorithm to be
useful in practice it needs to besound and complete. A complete saturation
algorithm will eventually derive the empty clause if the set of clauses is
unsatis able, and a sound saturation algorithm will correctly conclude that
the set of clauses is unsatis able if the empty clause is derivable from it. A
complete and sound saturation algorithm can have the following outputs in
practice:
unsatis able, if the empty clause is generated;
satis able, if the set of clauses is saturated;
unknown, if the algorithm runs forever (until it runs out of resources)
and the empty clause is not derived.
2.3</p>
        <p>Boogie
Is a modular reusable veri er for object-oriented Programs [BCD+05]. This
tool is made from di erent components: a source programming language, its
usage rules and formal semantics, a logical encoding suitable for automatic
reasoning, abstract domains for program analysis and property inference,
decision procedures for discharging proof obligations, and a user interface
that lets a user understand the results of the veri cation process[BMSW10].</p>
        <p>A representation of how all the components of Boogie interact is
represented in gure 3.</p>
        <p>The source programming language, Spec#, is a high-level, strong typed
language. It is a superset of the C# programming language, giving also
the possibility to write preconditions, postconditions and object invariants.
Apart from the compilers checks for static types, it also creates conditions
for the dynamic types as part of the target code. Boogie tries to checks
statically also the dynamic types properties enforced by the compiler along
with the ones provided by the user and those de ned by the virtual machine.
The source code is compiled into CIL language.</p>
        <p>The CIL code is obtained from an abstract syntax tree either directly
from the compiler, which enables Boogie to work as part of the compiler and
o er information to the user in a design-time manner, or from an already
compiled .dll or .exe le.</p>
        <p>The intermediate language is obtained by translating the CIL code in
BoogiePL code. This process enables the writing of new statements:
assert and assume. The assert statements are encode conditions that will be
checked by the program veri er, and the assume statements encode
properties that can be used by the veri er, these properties being enforced by
the source language and the veri cation process. Also BoogiePL permits
the encoding of theories and mathematical symbols. Since BoogiePL has a
textual representation small changes can be made in this le without
damaging the Spec# code. Also the textual representation makes Boogie useful
for other veri er, making the veri cation conditions reusable. At this point
the code is replaced with the proof task.</p>
        <p>The BoogiePL code is transformed into rst order logic properties. For
this process loop invariants are needed, and since providing this by hand
is troublesome and sometimes impossible, Boogie o ers a framework that
automatically infers loop invariants from BoogiePL code, written in the
form of \assume" statements.</p>
        <p>The next step is to get veri cation condition from every basic block of
the program. These are written in rst order logic with arithmetic, and since
there are more ways to write the same condition, the chosen form a ects
the performance of the theorem prover. Also the encoding of the conditions
are made in such a way that if the veri cation fails a trace of failure can be
mapped back in the original input language. A failure in veri cation can
also be only spurious since the theorem prover is incomplete, and also it
might be the case the the theorem prover could not do the task due to the
fact that there were not enough resources.</p>
      </sec>
      <sec id="sec-6-3">
        <title>Overview of Invariant Generation Methods</title>
        <p>There is a large variety of invariant generation approaches researched in the
past years. In this chapter we present three of this methods which cover a
large area of invariants that can be inferred and represent the state of the art
in their representative domain. The tools implementing this methods were
made available by their respective researchers. Although other methods were
considered for this thesis the tools implementing them were not available at
the moment from di erent reasons. The approach suggested has one of the
following starting points for obtaining the result: post-conditions, saturation
theorem proving, use of prede ned templates. In what follows we are going
to give an insight of the idea used in each of the three methods.
This method makes use of the postconditions provided by the user in order
to nd an invariant for a certain loop in the procedure [FM10].</p>
        <p>There are four di erent heuristics that are used to weaken the
postcondition: constant relaxation, variable aging, uncoupling, term dropping.</p>
        <p>Constant relaxation replaces a constant in the postcondition with a
variable. A constant is considered a variable that is not modi ed by the loop,
and a variable - in this context- is a variable modi ed by the loop. An
example were this heuristic is used is:
procedure ArrayInit &lt;tt&gt; ( A: array tt, left: int,</p>
        <p>right: int, index: int) returns (i:int)
requires left &lt;= right;
ensures (forall k: int :: k != n ==&gt; A[k] == 0);
{ var i: int;
i:= left; index:= left; A[left]=0;
while(i&lt;= right)
invariant (index &lt;= i);
{
i=i+1;
A[i]:=0;
}
}</p>
        <p>In this program all elements of an array are initialized with the value
0. By relaxing the constant n in the postcondition by the variable i an
invariant is obtained.</p>
        <p>In some cases just substituting a constant with a variable does not yield
an invariant, depending on the update time of the variable. Variable aging
replaces a constant with an expression involving a variable.
{ var i: int;
i:= left; index:= left;
while(i&lt;= right)
invariant (index &lt;= i);
{
A[i]:=0;
i:= i+1;
}
}</p>
        <p>Although the above example is similar to the one given for constant
relaxation heuristic we observe that the same invariant no longer holds,
because of the updating manner of the</p>
        <p>When invariants are conjunctions of formulas there might be the case
that substituting a constant with one variable on both sides of the
conjunction does not result in an invariant.Uncoupling is the heuristic that replaces
one constant with di erent variables at di erent occurrences in the
postcondition resulting in an invariant.</p>
        <p>partition (A: ARRAY [T]; n: INTEGER; pivot: T): INTEGER
require A.length = n 1
local low index, high index : INTEGER
do
from low index := 1; high index := n
until low index = high index
loop
from | no loop initialization</p>
        <p>until low index = high index _ A[low index] &gt; pivot
loop low index := low index + 1 end
from | no loop initialization
until low index = high index _ pivot &gt; A[high index]
loop high index := high index 1 end</p>
        <p>A.swap (A, low index, high index)
end
if pivot A[low index] then
low index := low index 1
high index := low index
end
Result := low index
i + 1. Since this property needed reasoning about a position that was not
reached yet, this did not meet the requirements for the template used by
Cpp inv. For the invariant P artitionInit the invariant that were discovered
did not give insight on the relation between the elements of the three arrays
processed in the loop. All other invariants that were concluded for the
respective loops were the invariant of interest. The tool was able to extract
useful information about the usage of the array in the loop and yield formulas
of great usage in order for the user to understand the task done in the snippet
of code.</p>
        <p>What seems to be the drawback of this method is the fact that one can
not independently use it to check a certain property of interest if it is not
already inferred by the tool. One can not add new information that can
not be automatically inferred in order to get a result about the property
of interest. On the other hand if a user decides to check for properties a
piece of code seen for the rst time, this tool might give useful information
regarding the elements of the processed array.</p>
        <p>In the case of Gin pink there is a large set of invariants that can be
inferred from the postcondition and proved by Boogie. The advantage of
using postconditions is that the invariants that will be derived from them
are usually useful for understanding the program. Since the program has as
starting point for searching an invariant a property that is of interest for the
user it is natural that the invariant found by weakening the formula would
also be of interesting when the code is analyzed by the user. On the other
hand it might the case that the invariant would contain auxiliary variables
that are not part of the postcondition. In this case the invariant of interest
is not going to be derived by the tool.</p>
        <p>Although Gin pink is not able to infer (without any interference from
the user) an invariant containing auxiliary variables with respect to the
postcondition there are walk-arounds this problems. One variant to work
this problem out is to augment postconditions with one clause that speci es
properties of the auxiliary variable. At this point Gin pink might have a
chance to derive the wanted invariant by weakening the new postcondition.
One of this loops is the one tagged with M aximum which was modi ed in
order to see if the tool would successfully infer the invariant we were looking
for.</p>
        <p>Another type of invariants that cause problems to this tool is the one
that include product operation. In this case the problem comes from the
theorem prover that is embedded in the tool, namely Z3. This theorem
prover does not have the background theory necessary to handle formulas
that have product of numeric in their composition. Unfortunately for this
case there is no workaround to make the tool infer the invariant since there
is no way to include new theories that could be used for processing such
formulas.</p>
        <p>From the experiments seen above we can see that there are a lot of
useful invariants derived by this tool, and making use of the method that
helps derive invariants with auxiliary variables would give the user better
results.</p>
        <p>For the tool Lingva we observe from the experiments that it obtains a lot
of properties from analyzing the code. To get an idea of how precise the code
is analyzed, the number of invariants that are outputted after eliminating
the trivial ones is somewhere around 150, for a piece of code with 10 lines.
Also the invariants that are inferred can also express properties between
di erent variables and also between initial values and new values of the
variables, feature that was not present for the other two tools.</p>
        <p>The drawback of this method is that some loops that contain more that
have more than one condition to be checked can not be analyzed because
the tool has not yet implemented the analysis of &amp;&amp; and jj operators from
C programming language. This problem can be solved if the loop does not
contain any if : : : then : : : else statements, because at the moment the loop
can be successfully analyzed if it is not nested and does not contain nested
if statements.</p>
        <p>An operation from which is hard to infer invariants is the product over
integer. This method is able to infer such invariants from the direct analysis
of the loop. In order to see the e ciency of this feature of the tool we
modied some of the above loops and processed them with Lingva. Although the
invariants obtained were expressing properties that need the multiplication
operation we could not get any interesting invariants (since also the loops
were not have a real purpose in processing an array).</p>
        <p>In the set of loops that we studied there was a signi cant number that
had as invariants of interest invariants that needed induction in order to
be proven. Unfortunately the theory of induction is not yet implemented
in V ampire so even though the invariants inferred by Lingva were enough
to prove them this did not happen. In the next section we show how we
can nevertheless infer this invariants if we study the properties deduced by
Lingva and add the missing properties in order for the induction to be
complete.</p>
        <p>This method has the advantage that if the user knows some information
about the analyzed loop, or any theory that might not be implemented in
V ampire yet it can easily encode the formulas representing the rules in
V ampire and run the theorem prover in order to see if a proof of refutation
for the invariant of interest is possible, with the new information. We took
advantage of this fact and use it to prove all the invariants that were not
automatically proved. In the next chapter we show in detail how the proof
of refutation were obtained for each invariant.</p>
        <p>The three methods have di erent strong points, Cpp inv can infer
induction properties without any supplementary information from the user,
while for Lingva this is not a trivial task, although it is achievable. Gin
pink can also deduce such invariants as long as the postcondition mentions
the variable used as an index, otherwise the task is impossible because it
does not have a method to add information about other variables.</p>
        <p>Lingva is the only one from the three tools that can infer properties
about the initial values and the modi ed values of the variables, by
introducing a new variable name for the initial value of the variable. This feature
o ers the user a more expressive way to reason about the program. It brings
more information to the output as it can infer that starting with one
position of the array the elements don't further change, information that can
not be rendered by the other two tools.</p>
        <p>Lingva is more exible in the sens that knowing that some information
can not be inferred from the loop ( such as if the array is sorted) the use can
add this information to the output of lingva in order to obtain a possibly
better result from V ampire. Gin pink also accepts in the input new
information from the user, in the form of assume statements, but in this
case the type of formula that one can provide is not as expressible as rst
order logic.</p>
        <p>Gin pink has a great advantage by being a goal oriented method.
The invariants inferred by this tool are certainly of interest for the user,
since they have as starting point the postcondition that is interesting for the
program. From this point of view Lingva tries to infer as many invariants as
possible, to make sure it covers as many properties that might be of interest
as possible, while Cpp inv looks for properties that fall in a certain pattern,
between speci c point of the program analyzed.</p>
      </sec>
      <sec id="sec-6-4">
        <title>Invariant Speci c Theory Extensions to First</title>
      </sec>
      <sec id="sec-6-5">
        <title>Order Theorem Prover</title>
        <p>In this chapter we proceed to analyze the programs for which the properties
of interest could not be proven by Lingva/Vampire and try to nd additional
properties of the variables in these programs that we could add such that
the computing power of the prover is increased.</p>
        <p>Comparison of invariants strength
The Maximum Example. The rst program to be analyzed is the one
with the name \Maximum". In plain English what this program does is
to put the value of the rst element of an array aa into the variable max
and iterate through the rest of the array comparing max with the rest of
elements and changing the current value of max with the greater value of
the elements if it is the case. The followings are the lines in the loop:
int i=1;
int max = aa[0];
while (i&lt;m)
{
if (max&lt;aa[i]) {</p>
        <p>max = aa[i];
}
}
++i;</p>
        <p>Analyzing the output of Lingva we observe that the properties with
respect to the iterator i are not strong enough so we add one to assure that
the initial value of i is 0:
Property. 1 t (prop1,axiom, i0=0).
and one to make ensure that i is increasing:
Property. 2 t (prop2,axiom, $less(i0,i) ).</p>
        <p>These two axioms are necessary to ensure that the rst part of the
implication will not be invalidated by a false positive.</p>
        <p>We also add two properties regarding the variable max. The rst one
ensures that the initial value for max is equal with the value of the rst
element in aa:
Property. 3 t (prop3, axiom, max0=aa(0) ).</p>
        <p>While the second one ensures that max takes its values only from the values
of elements in aa:
Property. 4 t (prop4, axiom, ?[Z:$int]: $lesseq(0,Z) &amp; $lesseq(Z,n)
&amp; max=aa(Z)).</p>
        <p>Since the properties inferred by Lingva did not show any relation between
the variable max and the elements in the array it is hard to infer such a
property. The two axioms above have the role to make this connection in
order for the reasoning to be possible.</p>
        <p>With the above properties added to the output of Lingva the theorem
prover can prove that all elements in the array that were already examined
have the value at most the value of max expressed in the following formula:
Property. 5 t (implication, conjecture, ![X: $int]: ($lesseq(0,X) &amp; $less(X,i)
=&gt;$lesseq(aa(X),max) )).</p>
        <p>The proof of refutation outputted by Vampire is given in the following lines:
155. $sum(X0,0) = X0 (0:5) [theory axiom]
153. $sum(X0,X1) = $sum(X1,X0) (0:7) [theory axiom]</p>
        <p>From inv137 inferred by Lingva and the property 1 V ampire deduces
that either i is less or equal to 1 or 1 is smaller than 0. At proposition
903 a new splitting component in a disjunction with i smaller than 1. From
this formula and the negation of the invariant V ampire infers sP 5. From
the negated conjunction also the fact that X0 is greater than 0 is inferred
and use this to deduce sP 5. The refutation can now be completed.</p>
        <p>Although Vampire could not automatically nd a refutation proof for
the formula representing the property of max, the extra-formulae that were
added by hand was just information about the variables and not new
theories.</p>
        <p>The Partial Initialization Example. The second loop we are going to
look at is \ Partial Initialization ". This program has as input two arrays,
aa and bb, and saves the indexes for which the element in aa equals the one
in bb in the array cc.</p>
        <p>int aa[m], bb[m], cc[m];
int i=0, c=0;
while (i&lt;m)
{
if (aa[i] == bb[i])
{
cc[c] = i;
c++;
}
i++;
}
}</p>
        <p>We add properties that give information about the initial values of the
iterators a and c:
Property. 6 t (prop2, axiom, a0=0).</p>
        <p>Property. 7 t (prop4, axiom, c0=0).</p>
        <p>The properties inferred by Lingva with respect to these iterators are
too weak and it can not be inferred that all their values start with the same
value, and that the value at which they start is non-negative.</p>
        <p>We also limit the the execution of the programs to the situation when
the number of elements in the array aa, m, is greater than 0:
Property. 8 t (prop5, axiom, $lesseq(0, m))
This property is necessary because from the static analysis of the program
it can not be inferred that the array has a positive number of elements, but
we know that any other case would not make sense.</p>
        <p>We also add a property that expresses the upper and lower limit of
that an element in cc can get, and also a property that establish a relation
between the elements in the array cc and the value of c for the corresponding
element:
Property. 9 t (prop1, axiom, ![Y:$int]: $lesseq(0,cc(Y))&amp; $less(cc(Y),m)).
Property. 10 t (prop6, axiom, ![Y0:$int]:($lesseq(0,Y0)&amp; $less(Y0,c)=&gt;
$lesseq(Y0,cc(Y0)))).</p>
        <p>With this new axioms added although Vampire can not prove the initial
property: 8X; 0 X ^ X &lt; c ) aa[cc[X]] == bb[cc[X]], it can prove
another formula with one quanti er alternation: 8X; 9Y; 0 X ^ X &lt;
m ^ 0 Y ^ Y &lt; c ^ aa(X) = bb(X) ) cc(Y ) = X.</p>
        <p>Here is the proof of refutation that was outputted by Vampire:
1611. ~$lesseq(c,a) | a = $sum(c,0) (0:8)</p>
        <p>[forward demodulation 1545,316]
1545. ~$lesseq($sum(c,0),a) | a = $sum(c,0) (0:10)</p>
        <p>[evaluation 1115]
1115. ~$lesseq(0,0) | ~$lesseq($sum(c,$uminus(0)),a) |
a = $sum(c,$uminus(0))(0:15)</p>
        <p>[definition unfolding 801,1054,1053,1053]
801. ~$lesseq(a0,0) | ~$lesseq($sum(c,$uminus(c0)),a) |
a = $sum(c,$uminus(c0)) (0:15) [cnf transformation 381]
381. a = $sum(c,$uminus(c0)) | ~$lesseq($sum(c,$uminus(c0)),a) |
~$lesseq(a0,0) [flattening 55]
55. a = $sum(c,$uminus(c0)) | ~$lesseq($sum(c,$uminus(c0)),a) |
~$lesseq(a0,0) [input inv54]
1374. ~$lesseq(a,0) | ~$lesseq(1,$sum(c,0)) (0:8) [evaluation 1350]
1350. ~$lesseq(a,0) | ~$lesseq(1,$sum(c,$uminus(0))) (0:9)
[definition unfolding 1036,1054,1053]
1036. ~$lesseq(a,a0) | ~$lesseq(1,$sum(c,$uminus(c0))) (0:9)
[cnf transformation 720]
720. ~$lesseq(1,$sum(c,$uminus(c0))) | ~$lesseq(a,a0)</p>
        <p>[flattening 290]
290. ~$lesseq(1,$sum(c,$uminus(c0))) | ~$lesseq(a,a0)</p>
        <p>[input inv289]
2061. $lesseq(c,0) (1:3) [resolution 1852,1057]
1057. $lesseq(0,X1) (0:3) [cnf transformation 746]
1852. ~$lesseq(0,$uminus(c)) | $lesseq(c,0) (0:7)
[forward demodulation 1256,1732]
1732. $sum(0,X0) = X0 (0:5) [backward demodulation 1731,1648]
1648. $sum(0,X0) = $sum(c,$sum(0,$sum($uminus(c),X0))) (0:12)
[forward demodulation 1129,1613]
1129. $sum(0,X0) = $sum(a,$sum(0,$sum($uminus(c),X0))) (0:12)
[definition unfolding 815,1054,1053]
815. $sum(a0,X0) = $sum(a,$sum(c0,$sum($uminus(c),X0))) (0:12)
[cnf transformation 396]
396. ! [X0] : $sum(a0,X0) = $sum(a,$sum(c0,$sum($uminus(c),X0)))
[rectify 69]
69. ! [X1] : $sum(a0,X1) = $sum(a,$sum(c0,$sum($uminus(c),X1)))
[input inv68]
1731. $sum(c,$sum(0,$sum($uminus(c),X0))) = X0 (0:10)
[forward demodulation 1730,316]
1730. $sum(X0,0) = $sum(c,$sum(0,$sum($uminus(c),X0))) (0:12)
[forward demodulation 1195,1613]
1195. $sum(X0,0) = $sum(a,$sum(0,$sum($uminus(c),X0))) (0:12)
[definition unfolding 881,1054,1053]
881. $sum(X0,a0) = $sum(a,$sum(c0,$sum($uminus(c),X0))) (0:12
) [cnf transformation 501]
501. ! [X0] : $sum(X0,a0) = $sum(a,$sum(c0,$sum($uminus(c),X0)))
[rectify 135]
135. ! [X28] : $sum(X28,a0) = $sum(a,$sum(c0,$sum($uminus(c),X28)))
[input inv134]
1256. $lesseq(c,0) | ~$lesseq(0,$sum(0,$uminus(c))) (0:9)
[definition unfolding 942,1053,1053]
942. $lesseq(c,0) | ~$lesseq(c0,$sum(c0,$uminus(c))) (0:9)
[cnf transformation 604]
604. ~$lesseq(c0,$sum(c0,$uminus(c))) | $lesseq(c,0)</p>
        <p>[flattening 196]
196. ~$lesseq(c0,$sum(c0,$uminus(c))) | $lesseq(c,0)
[input inv195]</p>
        <p>Starting from inv54 inferred by Lingva stating that either a is equal to
c c0 or c is not less or equal to a or the initial value of a is greater than
0 and with the two properties enforcing the initial values of the iterators
V ampire infers formula (1611) stating that either c is grater than a or a
equals c. Due to the fact that a is at least equal to c, property enforced by
formula (1580). From the input inv289 expressing the fact that either c is
greater than c0 or a is greater than a0 and the property stating the equality
between a and c, V ampire infers that either c is equal to 0 or is greater or
equal to 1(2019). From this formula and the negation of the invariant we
are trying to prove 0 c (2048) is inferred. From input invariants inv195
and inv68 V ampire infers that c is less or equal to 0. Applying resolution
on the two formulas we obtain a refutation.</p>
        <p>The Sum of Pairs Example. The next loop we analyze is \Sum of
pairs".</p>
        <p>int m;
int *aa;
int x=getX(),
l=0, u=m-1;
else break;
}
This loop is particularly di cult to analyze with this method because it is
constructed with a nested if : : : then : : : else statement, which makes it
difcult for Lingva to extract properties - as speci ed in the previous chapter,
and the invariant we want to infer is inductive, type of property that can not
be inferred straight forward by V ampire. For this speci c loop we introduce
the invariants inferred by Cpp inv and check if the theorem prover can
deduce the invariant:
Property. 11 aa[l] + aa[u] x + 1 0</p>
        <p>The proof obtained by V ampire is shown as follows:
Refutation found. Thanks to Tanya!
1898. $false (2:0) [subsumption resolution 1897,355]
355. $lesseq(0,l) (2:3) [resolution 208,103]
103. $lesseq(0,sK0) (0:3) [cnf transformation 80]
80. $lesseq(0,sK0) &amp; $lesseq(sK0,l) &amp;
~$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0)
[skolemisation 79]
79. ? [X0] : ($lesseq(0,X0) &amp; $lesseq(X0,l) &amp;
~$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0))
[flattening 78]
78. ? [X0] : (($lesseq(0,X0) &amp; $lesseq(X0,l)) &amp;
~$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0))
[ennf transformation 59]
59. ~! [X0] : (($lesseq(0,X0) &amp; $lesseq(X0,l)) =&gt;
$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0))
[rectify 24]
24. ~! [X3] : (($lesseq(0,X3) &amp; $lesseq(X3,l)) =&gt;
$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0))
[negated conjecture 23]
23. ! [X3] : (($lesseq(0,X3) &amp; $lesseq(X3,l)) =&gt;
$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0))
[input implication]
208. ~$lesseq(X16,sK0) | $lesseq(X16,l) (1:6) [resolution 31,104]
104. $lesseq(sK0,l) (0:3) [cnf transformation 80]
31. ~$lesseq(X1,X2) | ~$lesseq(X0,X1) | $lesseq(X0,X2) (0:9)
[theory axiom]
1897. ~$lesseq(0,l) (2:3) [subsumption resolution 1889,30]
30. $lesseq(X0,X0) (0:3) [theory axiom]
1889. ~$lesseq(l,l) | ~$lesseq(0,l) (2:6) [resolution 390,309]
309. ~$lesseq($sum(1,$sum($uminus(x),$sum(aa(u),aa(l)))),0) (0:12)
[forward demodulation 308,25]
25. $sum(X0,X1) = $sum(X1,X0) (0:7) [theory axiom]
308. ~$lesseq($sum(1,$sum($uminus(x),$sum(aa(l),aa(u)))),0) (0:12)
[forward demodulation 307,25]
307. ~$lesseq($sum(1,$sum($sum(aa(l),aa(u)),$uminus(x))),0) (0:12)
[forward demodulation 306,279]
279. $sum(X7,$sum(X8,X9)) = $sum(X9,$sum(X7,X8)) (1:11)
[superposition 26,25]
26. $sum(X0,$sum(X1,X2)) = $sum($sum(X0,X1),X2) (0:11)
[theory axiom]
306. ~$lesseq($sum($uminus(x),$sum(1,$sum(aa(l),aa(u)))),0) (0:12)
[forward demodulation 305,279]
305. ~$lesseq($sum($uminus(x),$sum(aa(l),$sum(aa(u),1))),0) (0:12)
[forward demodulation 304,25]
304. ~$lesseq($sum($uminus(x),$sum($sum(aa(u),1),aa(l))),0) (0:12)
[forward demodulation 296,279]
296. ~$lesseq($sum(aa(l),$sum($uminus(x),$sum(aa(u),1))),0) (0:12)
[backward demodulation 279,143]
143. ~$lesseq($sum(aa(l),$sum(aa(u),$sum(1,$uminus(x)))),0) (0:12)
[forward demodulation 105,25]
105. ~$lesseq($sum(aa(l),$sum(aa(u),$sum($uminus(x),1))),0) (0:12)
[cnf transformation 80]
390. $lesseq($sum(1,$sum($uminus(x),$sum(aa(u),aa(X0)))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (1:18) [superposition 314,25]
314. $lesseq($sum(1,$sum($uminus(x),$sum(aa(X0),aa(u)))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 313,25]
313. $lesseq($sum(1,$sum($sum(aa(X0),aa(u)),$uminus(x))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 312,279]
312. $lesseq($sum($uminus(x),$sum(1,$sum(aa(X0),aa(u)))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 311,279]
311. $lesseq($sum($uminus(x),$sum(aa(u),$sum(1,aa(X0)))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 310,26]
310. $lesseq($sum($uminus(x),$sum($sum(aa(u),1),aa(X0))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 297,279]
297. $lesseq($sum(aa(X0),$sum($uminus(x),$sum(aa(u),1))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [backward demodulation 279,140]
140. $lesseq($sum(aa(X0),$sum(aa(u),$sum(1,$uminus(x)))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [forward demodulation 100,25]
100. $lesseq($sum(aa(X0),$sum(aa(u),$sum($uminus(x),1))),0) |
~$lesseq(X0,l) | ~$lesseq(0,X0) (0:18) [cnf transformation 73]
73. ! [X0] : (~$lesseq(0,X0) | ~$lesseq(X0,l) |
$lesseq($sum(aa(X0),$sum(aa(u),$sum($uminus(x),1))),0))</p>
        <p>[flattening 72]
72. ! [X0] : ((~$lesseq(0,X0) | ~$lesseq(X0,l)) |
$lesseq($sum(aa(X0),$sum(aa(u),$sum($uminus(x),1))),0))
[ennf transformation 56]
56. ! [X0] : (($lesseq(0,X0) &amp; $lesseq(X0,l)) =&gt;
$lesseq($sum(aa(X0),$sum(aa(u),$sum($uminus(x),1))),0))</p>
        <p>[rectify 20]
20. ! [X3] : (($lesseq(0,X3) &amp; $lesseq(X3,l)) =&gt;
$lesseq($sum(aa(X3),$sum(aa(u),$sum($uminus(x),1))),0))
[input pro3]</p>
        <p>From the input property that represents one of the invariants discovered
by Cpp inv, 8X3((0 X3 ^ X3 l ) aa(X3) + aa(u) + 1 x 0)) using
forward demodulation in combination with theory axioms V ampire infers
that $lesseq(0; l). But in the negated conjecture we have the negation of
this clause resulting into a refutation.</p>
        <p>This result is not surprising, taking into account that Cpp inv can
infer most of the invariants that are inductive so the formulas added to
Lingvas result cover the V ampires lack using induction. The great number
of theories that are implemented in the theorem prover makes the inference
of the invariant possible, the formula introduced as an axiom being processed
and modeled by this theorems to take the form we were looking for.
The Sequential Initialization Example. Also in the case of the loop
for the program \Sequential initialization " proving the property of interest
is not straight forward.</p>
        <p>int main()
{
int m;
int *aa;
aa[0]=7;
int i=1;
while (i&lt;m)
{
}
}
aa[i]=aa[i-1]+1;
++i;
Since in the program there are speci ed initial values for the iterator i and for
the rst element in the array aa but Lingva did not infer them automatically
we introduce them by hand in the form of two properties:
and
Property. 13 t (prop3, axiom, aa0(0)=7).</p>
        <p>We observe that Lingva managed to infer some very useful invariants
stating that the value of an element in aa that is in a position beyond the
boundaries (less than 0, or greater than i, greater than m) the value of the
element does not change. We introduce a property expressing the fact that
if the element lies between the boundaries of the processed array its value
is changed:
Property. 14 t (propx, axiom, ![X:$int]:
( ($lesseq($sum(i,$uminus(i0)),sK0(X)) &amp; $sum(i0,sK0(X)) = X
&amp; $lesseq(0,sK0(X)) &amp; $lesseq(m,$sum(i0,sK0(X))))=&gt; :aa(X)=aa0(X)
)).</p>
        <p>Since there is no property inferred about the way a value is changed by this
loop (although we already have this information from the output of Cpp-inv)
we introduce a new formula stating this relation:
Property. 15 t (prop10, axiom, ![X:$int]: (aa(X)=aa0(X) j
aa(X)=$sum(aa($sum(X,$uminus(1))),1) )).</p>
        <p>With these new formulae added Vampire can prove that: 8X; (0 X) ^
(X &lt; i) ) aa(X) == aa(X 1) + 1. The proof outputted is give as follows:
[subsumption resolution 5503,545]
545. ~$lesseq(0,sK0(sK0)) (0:4) [cnf transformation 388]
5503. $lesseq(0,sK0(sK0)) | $sum(1,sK0(sK0)) = sK0 (1:10)
[subsumption resolution 5497,696]
696. $lesseq(m,$sum(1,sK0(sK0))) (0:6)
[definition unfolding 546,539]
546. $lesseq(m,$sum(i0,sK0(sK0))) (0:6) [cnf transformation 388]
5497. ~$lesseq(m,$sum(1,sK0(sK0))) | $lesseq(0,sK0(sK0)) |
$sum(1,sK0(sK0)) = sK0 (1:16) [resolution 909,912]
912. $lesseq($sum(-1,i),sK0(sK0)) (0:6)
[forward demodulation 703,157]
157. $sum(X0,X1) = $sum(X1,X0) (0:7) [theory axiom]
703. $lesseq($sum(i,-1),sK0(sK0)) (0:6) [evaluation 698]
698. $lesseq($sum(i,$uminus(1)),sK0(sK0)) (0:7)
[definition unfolding 543,539]
543. $lesseq($sum(i,$uminus(i0)),sK0(sK0)) (0:7)
[cnf transformation 388]
909. ~$lesseq($sum(-1,i),sK0(X0)) | ~$lesseq(m,$sum(1,sK0(X0))) |
$lesseq(0,sK0(X0)) | $sum(1,sK0(X0)) = X0 (0:22)
[forward demodulation 908,157]
908. ~$lesseq(m,$sum(1,sK0(X0))) | $lesseq(0,sK0(X0)) |
$sum(1,sK0(X0)) = X0 | ~$lesseq($sum(i,-1),sK0(X0)) (0:22)
[subsumption resolution 705,548]
548. ~$lesseq(m,$sum(1,sK0(X0))) | aa(X0) = aa0(X0) (0:11)
[definition unfolding 389,539]
389. ~$lesseq(m,$sum(i0,sK0(X0))) | aa(X0) = aa0(X0) (0:11)
[cnf transformation 170]
170. ! [X0] : (aa(X0) = aa0(X0) | ~$lesseq(m,$sum(i0,sK0(X0))))
[flattening 1]
1. ! [X0] : (aa(X0) = aa0(X0) | ~$lesseq(m,$sum(i0,sK0(X0))))
[input inv0]
705. aa(X0) != aa0(X0) | ~$lesseq(m,$sum(1,sK0(X0))) |
$lesseq(0,sK0(X0)) | $sum(1,sK0(X0)) = X0 |
~$lesseq($sum(i,-1),sK0(X0)) (0:27) [evaluation 695]
154. ! [X37] : (($lesseq($sum(i,$uminus(i0)),sK0(X37)) &amp;
~$sum(i0,sK0(X37)) = X37 &amp; ~$lesseq(0,sK0(X37)) &amp;
$lesseq(m,$sum(i0,sK0(X37)))) =&gt; ~aa(X37) = aa0(X37))
[input propx]</p>
        <p>V ampire infers from the input negated implication, from the invariant
inv0 deduced by Lingva, stating the connection between the relation
between the values of i and m and not modifying the values in array aa,
property (5504) $sum(1; sK0(sK0)) = sK0. From this formula and
:sP 2($sum(1; sK0(sK0))) (701), which is an inequality splitting name
introduction, formula sP 2(sK0)(5508) is inferred. From this formula and the
negated invariant V ampire obtains a refutation.</p>
        <p>The Insertion Example. The loop Insertion requires an invariant that
is inductive so V ampire can not prove this invariant without some extra
knowledge added to the invariants inferred by Lingva.</p>
        <p>x=aa[i];
j = i-1;
while (j &gt;= 0 and</p>
        <p>aa[j] &gt; x) do
aa[j+1] = aa[j];
--j;
end do
We observe a few properties that were already discovered by Lingva : there
are four properties that express the fact that if the position in the array is
out of the bounds (smaller than 0, greater than j) the value of the elements
is not modi ed. There is also a property communicating the fact that if
j is greater than 0, than for the element at the initial value of j (at j0)
the property that the value is shifted one to the right holds. Based on this
formulas we take the decision of introducing the following property stating
that all elements that are at a position higher than j are greater than the
element at this position.</p>
        <p>Property. 16 t (prop4, axiom, ![X:$int]:( $lesseq(j,X)j $lesseq(X,j0)j
$less(aa(j),aa(X)))).</p>
        <p>The proof found by V ampire for the invariant is reproduced in the
following lines:</p>
        <p>Refutation found. Thanks to Tanya!
1299. $false (1:0) [subsumption resolution 1298,160]
160. $lesseq(X0,X0) (0:3) [theory axiom]
1298. ~$lesseq(j,j) (1:3) [subsumption resolution 1295,856]
856. ~$lesseq(X0,j) | $lesseq(X0,j0) (3:6) [resolution 839,161]
161. ~$lesseq(X1,X2) | ~$lesseq(X0,X1) | $lesseq(X0,X2) (0:9)
[theory axiom]
839. $lesseq(j,j0) (2:3) [resolution 809,639]
639. $lesseq(j,sK0) (1:3) [resolution 162,530]
530. ~$lesseq(sK0,j) (0:3) [cnf transformation 379]
379. ~$lesseq(sK0,j) &amp; $lesseq(sK0,j0) &amp; $lesseq(aa(sK0),x)
[skolemisation 378]</p>
        <p>The proof for this invariant is less complex than the other proofs. From
the formula 839 stating that j j0 V ampire infers that X is either grater
than j or smaller than j0(856). From this and negated invariant j &gt; j is
inferred which is in contradiction with the property introduced above.</p>
        <p>Discussions and Conclusions
We seen that every one of the studied tools has its own advantage regarding
the strength or type of inferred invariant. We observe that we get signi
cantly better results when we use the invariant inferred by one tool as input
for the others in order to get even stronger invariants. One remark is in
order at this step and that is that the form of the formula that we try to
infer with V ampire is important with respect to the set of formulas that are
provided as input. Although using human intuition the invariant may be
found just as hard to infer regardless of the form that it has, for the theorem
prover a decision must be made on how many times should the basic
theorems (such as commutativity, associativity) be applied on a formula and
in which order. An important step in this eld is the automatization of the
inference process and the combination of techniques.</p>
      </sec>
      <sec id="sec-6-6">
        <title>Conclusions</title>
        <p>We have provide an extensive evaluation of the state of the art in invariant
generation techniques. Although the techniques are not mutually exclusive,
in the sens that the same invariant can be generated by more than one
technique, we found a pattern of invariants that can or can't be generated
by a certain method. In order to infer certain properties about programs,
this classi cation can point to the user the method that is most likely to
infer it.</p>
        <p>The set of programs for which we studied the behavior of these tools
were chosen from a series of loops on which either one of the tools had
di culties analyzing, the loops were representative for the type of invariants
that a certain tool could infer or the invariants of interest for the loop had an
interesting structure. Although this set is not large, the invariants that were
inferred cover a series of patterns that occur often in program veri cation.</p>
        <p>We further studied the disadvantages of Lingva and V ampire and
improve their functionality by either combining the result of Lingva with
results of other methods or by adding properties that are easy to observe by
the user. We choose the set of properties to add for each loop depending on
its structure and also on the known functionality of the tool. To this end
we managed to infer invariants of interest for every loop studied only with
the cost of writing theorems hard to infer by this tool.</p>
        <p>Invariants of interest for the user are hard to ned since there might be a
large number of properties between two or more variables from the program.
Nevertheless the three tools managed to infer invariants that would help the
user understand the program better. Also the saturation theorem prover
and post-condition weakening methods are goal oriented since both require
input from the user, having an advantage of inferring the invariant the user
is interested in.</p>
        <p>Due to program veri cation undecidability the task of inferring
invariants is hard. Selecting a suitable benchmark for an evaluation of techniques
developed for this task is not trivial since the programs come in a large
variety of languages and combination of statements. We seen in our evaluation
that combining such techniques have a positive in uence on the result. This
observation take as to the conjecture that a promising path for future work
is to combine methods that have di erent advantages and evaluate them on
loops that have a more complicated behavior.</p>
        <p>We also observed that there is signi cant amount of cases in which
human interfering with the procedure (such as adding theorems or stating
postconditions) provides a better result from the users point of view. This
information provides the intuition that combining human intuition can play
an important part in solving the invariant generation task. Algorithms used
in machine learning, that simulate human rationality can be an asset for this
section of program veri cation. To the best of our knowledge this concept
was not used yet so for future work this is an interesting path that could be
followed.</p>
      </sec>
      <sec id="sec-6-7">
        <title>References</title>
        <p>Cimatti A., Griggio A., and Sebastiani R. E cient
Generation of Craig Interpolants in Satis ability Modulo Theories. In
ACM Transactions on Computational Logic , volume 12,
October 2009.</p>
        <p>Peter B. Andrews. An Introduction to Mathematical Logic and
Type Theory: To Truth Through Proof. 2002.
[BCC+03] Armin Biere, Alessandro Cimatti, Edmund M. Clarke, Ofer
Strichman, and Yunshan Zhu. Bounded Model Checking . 58,
2003.
[BCD+05] Michael Barnett, Bor-Yuh Evan Chang, Robert DeLine, Bart
Jacobs, and K. Rustan M. Leino. Boogie: A Modular Reusable
Veri er for Object-Oriented Programs . FMCO, 4111:364{387,
2005.
[BMSW10] Sascha Bohme, Michal Moskal, Wolfram Schulte, and Burkhart
Wol . HOL-Boogie|An Interactive Prover-Backend for the
Verifying C Compiler. 44:111{144, February 2010.
[CC77]
[Coo71]
[DdM06]
[Dij75]
[DL62]
[dMB11]
[DP60]
[DW50]</p>
        <p>Patrick Cousot and Radhia Cousot. Abstract Interpretation: A
Uni ed Lattice Model for Static Analysis of Programs by
Construction or Approximation of Fixpoints . pages 238{252, 1977.
Stephen A. Cook. The complexity of theorem-proving
procedures. pages 151{158, 1971.</p>
        <p>Bruno Dutertre and Leonardo de Moura. A Fast
LinearArithmetic Solver for DPLL(T) . pages 81{94, 2006.</p>
        <p>E.W. Dijkstra. Guarded Commands, Nondeterminacy and
Formal Derivation of Programs. 18:453{457, 1975.</p>
        <p>Martin Davis, George Logemann , and Donald Loveland. A
machine program for theorem-proving. 5:394{397, July 1962.
Leonardo de Moura and Nikolaj Bj rner. Satis ability modulo
theories: introduction and applications. 54:69{77, 2011.</p>
        <p>Martin Davis and Hilary Putnam. A Computing Procedure for
Quanti cation Theory. 7:201{215, July 1960.</p>
        <p>Hilbert D. and Ackermann W. Principles of Mathematical Logic.
Chelsea Publishing Company, 1950.
[HKV11]
[KV09]
[KVar]</p>
        <p>Niklas Een and Niklas Sorensson. An Extensible SAT-solver.
2919:502{518, 2004.</p>
        <p>Carlo A. Furia and Bertrand Meyer. Inferring Loop Invariants
using Postconditions . In Fields of Logic and Computation:
Essays Dedicated to Yuri Gurevich on the Occasion of His 70th
Birthday. 2010.</p>
        <p>G.S.Tseitin. On the Complexity of Derivation in Propositional
Calculus. pages 466{483, 1983.
[HHKR10] Thomas A. Henzinger, Thibaud Hottelier, Laura Kovacs, and
Andrey Rybalchenko. Aligators for Arrays (Tool Paper) . 6397:
348{356, 2010.</p>
        <p>Krystof Hoder, Laura Kovacs, and Andrei Voronkov. Case
Studies on Invariant Generation Using a Saturation Theorem Prover.
In 10th Mexican International Conference on Arti cial
Intelligence, MICAI, 2011.</p>
        <p>Laura Kovacs and Andrei Voronkov. Finding Loop Invariants for
Programs over Arrays Using a Theorem Prover. In International
Symposium on Symbolic and Numeric Algorithms for Scienti c
Computing, SYNASC, 2009.</p>
        <p>Laura Kovacs and Andrei Voronkov. First-Order Theorem
Proving and Vampire. In Proceedings of the International Conference
on Computer Aided Veri cation (CAV), LNCS, 2013 to appear.
[LRCR13] Daniel Larraz, Enric Rodriguez-Carbonell, and Albert Rubio.</p>
        <p>SMT-Based Array Invariant Generation. In 14th International
Conference Veri cation, Model Checking, and Abstract
Interpretation, VMCAI, 2013.
[MMZ+11] Matthew W. Moskewicz, Conor F. Madigan, Ying Zhao, Lintao
Zhang, and Sharad Malik. Cha : Engineering an E cient SAT
Solver . 2011.
[MP92]
[MSS99]
[SS09]
[TH06]</p>
        <p>Z. Manna and A. Pnueli. The Temporal Logic of Reactive and
Concurrent Systems. Springer, 1992.</p>
        <p>J. Marques-Silva and K. Sakallah. GRASP: a search algorithm
for propositional satis ability . pages 506{521, May 1999.</p>
        <p>Strivastava S. and Gulwani S. Program Veri cation using
Template over Predicate Abstraction. In Proc. of PLDI, 2009.</p>
        <p>Dmitry Tsarkov and Ian Horrocks. FaCT++ Description Logic
Reasoner: System Description. 4130:292{297, 2006.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          <source>2 Preliminaries 3 2</source>
          .1 Propositional
          <string-name>
            <surname>logic . . . . . . . . . . . . . . . . . . . . . . . . 3</surname>
          </string-name>
          <year>2</year>
          .2 SAT
          <string-name>
            <surname>solvers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4</surname>
          </string-name>
          <year>2</year>
          .3
          <string-name>
            <surname>Boogie . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>10 4 Experiments 22 4.1 Experiments with Gin-Pink and</article-title>
          <string-name>
            <surname>Cpp-Inv . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>22 4.2 Experiments with</article-title>
          <string-name>
            <surname>Lingva . . . . . . . . . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>28 4.3 Discussions of Experimental</article-title>
          <string-name>
            <surname>Results . . . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>37 5 Invariant Speci c Theory Extensions to First Order Theorem Prover 41 5.1 Comparison of invariants strength</article-title>
          <string-name>
            <surname>. . . . . . . . . . . . . . .</surname>
          </string-name>
          <article-title>41 5.2 Discussions and</article-title>
          <string-name>
            <surname>Conclusions . . . . . . . . . . . . . . . . . . . 53</surname>
          </string-name>
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>