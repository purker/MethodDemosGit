<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink">
  <front>
    <journal-meta />
    <article-meta>
      <title-group>
        <article-title>Eine generische Bibliothek fu¨r Metaheuristiken und ihre Anwendung auf das Quadratic Assignment Problem</article-title>
      </title-group>
      <contrib-group>
        <aff id="aff0">
          <label>0</label>
          <institution>Technischen Universita ̈t Wien</institution>
        </aff>
        <aff id="aff1">
          <label>1</label>
          <institution>durch Daniel Wagner Schauleithenstraße 9 3363 Ulmerfeld-Hausmening</institution>
        </aff>
        <aff id="aff2">
          <label>2</label>
          <institution>unter Anleitung von a.o. Univ.-Prof. Dipl.-Ing. Dr.techn. Gu ̈nther Raidl</institution>
        </aff>
      </contrib-group>
      <fpage>32</fpage>
      <lpage>73</lpage>
    </article-meta>
  </front>
  <body>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-139785.images\img_17_1.png" />
    </fig>
    <fig>
      <graphic xlink:href="D:\output\methods\cermine\cermine-TUW-139785.images\img_17_2.png" />
    </fig>
    <sec id="sec-1">
      <title>Datum</title>
    </sec>
    <sec id="sec-2">
      <title>Unterschrift</title>
      <p>In this master thesis a generic libray of efficient metaheuristics for combinatorial
optimization is presented. In the version at hand classes that feature local search,
simulated annealing, tabu search, guided local search and greedy randomized
adaptive search procedure were implemeted.</p>
      <p>Most notably a generic implementation features the advantage that the problem
dependent classes and methods only need to be realized once without targeting a
specific algorithm because these parts of the sourcecode are shared among all present
algorithms contained in EAlib.</p>
      <p>This main advantage is then exemplarily demonstrated with the quadratic
assignment problem. The sourcecode of the QAP example can also be used as an
commented reference for future problems.</p>
      <p>Concluding the experimental results of the individual metaheuristics reached
with the presented implementation are presented.</p>
      <sec id="sec-2-1">
        <title>Kurzfassung</title>
        <p>In dieser Diplomarbeit wird eine generische Bibliothek von effizienten
Metaheuristiken fu¨r kombinatorische Optimierungsprobleme vorgestellt. In der vorliegenden
Version entha¨lt sind lokale Suche, Simulated Annealing, Tabusearch, Guided Local
Search und Greedy Randomized Adaptive Search Procedure implementiert worden.</p>
        <p>Eine generische Implementierung bietet vorallem den Vorteil das bei einem neuen
zu lo¨sendem Problem nur einige bestimmte problemabha¨ngige Klassen und
Methoden realisiert werden mu¨ssen ohne sich schon im Vorhinein einen speziellen
Algorithmus festzulegen, da diese Klassen und Methoden von allen in der EAlib vorhanden
Metaheuristiken verwendet werden.</p>
        <p>Die Vorteile dieser Bibliothek werden anschließend anhand des Quadratic
Assignment Problems ausfu¨hrlich dargestellt. Dieses Beispiel dient zusa¨tzlich auch noch
als kommentierte Referenz fu¨r zuku¨nftige Problemimplentierungen.</p>
        <p>Abschließend werden die Resulate der Experimente mit den verschiedenen
Metaheuristiken pra¨sentiert.</p>
      </sec>
      <sec id="sec-2-2">
        <title>Danksagung</title>
        <p>An dieser stelle mo¨chte ich mich bei allen Menschen bedanken die zum Gelingen
dieser Diplomarbeit beigetragen haben.</p>
        <p>Dieser Dank gilt meinem Betreuer Prof. Raidl, der mich mit großer Geduld am
Weg zum Abschluß begleitet hat und mit mir in den vielen Treffen oft nu¨tzliche
Ideen entwickelt hat.</p>
        <p>Meinen Eltern und meinem Bruder Ronald danke ich fu¨r ein sorgloses Studium
und die moralische Unterstu¨tzung wenn die Motivation einmal nicht so groß war.</p>
        <p>Bei meinen Studienkollegen, besonders bei Harry und Zamb, bedanke ich mich
fu¨r die Freundschaft, den Spaß und die gegenseitige Unterstu¨tzung.</p>
        <p>Last but not least mo¨chte ich mich auch bei meinen Mitbewohnern Sic0 und Leo
bedanken, die mir wa¨hrend meiner Arbeit die no¨tige Ruhe zukommen ließen, aber
natu¨rlich auch ab und zu fu¨r willkommene Ablenkung gesorgt haben.</p>
        <p>Natascha danke ich fu¨r die scho¨ne gemeinsame Zeit.
Table of Contents
1 Introduction 5
1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.2 Combinatorial Optimization and Metaheuristics . . . . . . . . . . . . 5
1.3 Guide to the thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
5.2.3 Class lsbase . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
5.2.4 Class localSearch . . . . . . . . . . . . . . . . . . . . . . . . . 39
5.2.5 Class simulatedAnnealing . . . . . . . . . . . . . . . . . . . . 39
5.2.6 Class tabuSearch . . . . . . . . . . . . . . . . . . . . . . . . . 40
5.2.7 Class guidedLS . . . . . . . . . . . . . . . . . . . . . . . . . . 40
5.2.8 Class GRASP . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
5.2.9 Class feature . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
5.2.10 Class tabuAttribute . . . . . . . . . . . . . . . . . . . . . . . . 42
5.2.11 Class tabulist . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
5.2.12 Class move and childs . . . . . . . . . . . . . . . . . . . . . . 43
5.2.13 Class qapChrom . . . . . . . . . . . . . . . . . . . . . . . . . 43
5.2.14 Class qapInstance . . . . . . . . . . . . . . . . . . . . . . . . . 44
5.2.15 Class qapFeature . . . . . . . . . . . . . . . . . . . . . . . . . 44
5.2.16 Class qapTabuAttribute . . . . . . . . . . . . . . . . . . . . . 45
5.2.17 Parameter handling . . . . . . . . . . . . . . . . . . . . . . . . 45
5.3 Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
5.3.1 Interface aObjProvider . . . . . . . . . . . . . . . . . . . . . . 47
5.3.2 Interface tabulistProvider . . . . . . . . . . . . . . . . . . . . 47
5.3.3 Interface featureProvider . . . . . . . . . . . . . . . . . . . . . 48
5.3.4 Interface gcProvider . . . . . . . . . . . . . . . . . . . . . . . 48
5.3.5 Interface tabuProvider . . . . . . . . . . . . . . . . . . . . . . 48
5.3.6 Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49</p>
        <sec id="sec-2-2-1">
          <title>6 Experimental Results 52</title>
          <p>6.1 Test Cases . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
6.2 Test Setup and Procedure . . . . . . . . . . . . . . . . . . . . . . . . 53
6.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54</p>
        </sec>
        <sec id="sec-2-2-2">
          <title>7 Conclusions</title>
        </sec>
        <sec id="sec-2-2-3">
          <title>List of Algorithms</title>
        </sec>
        <sec id="sec-2-2-4">
          <title>List of Figures</title>
        </sec>
        <sec id="sec-2-2-5">
          <title>List of Tables</title>
          <p>All men by nature desire knowledge.
Aristotle
Chapter 1
Introduction
1.1</p>
        </sec>
      </sec>
      <sec id="sec-2-3">
        <title>Motivation</title>
        <p>Metaheuristics are a popular approach to handle computationally intractable
optimization problems. In the course of this master thesis an existing library dedicated
to evolutionary algorithms was extended substantially by several common known
and used metaheuristics. These metaheuristics are implemented in a generic
manner so that their application to a widespread variety of combinatorial optimization
problems is supported.</p>
        <p>A generic implementation of metaheuristics is desirable because common
portions of many metaheuristics can be implemented problem independent and also
a significant amount of problem dependent sourcecode can be shared between the
metaheuristics, e.g. efficient evaluation of the objective value or neighborhood
relevant methods.</p>
        <p>The basis for the implementation of the metaheuristics is the EAlib library which
is developed at the Vienna University of Technology, Institute of Computergraphics
and Algorithms. At the beginning of this master thesis it already contained
particular classes for evolutionary algorithms and some supporting infrastructure which
was also useful for our project. The aim of this master thesis the was to extend this
existing library while trying to keep changes to the existing parts to a minimum to
maintain compatibility with present applications.
1.2</p>
      </sec>
      <sec id="sec-2-4">
        <title>Combinatorial Optimization and Metaheuristics</title>
        <p>An optimization problem can be characterized as the selection of a “best”
configuration or set of parameters to achieve some objective criteria. If the entities to
CHAPTER 1. INTRODUCTION
be optimized are discrete, the number of feasible solutions is finite. We call such
problems combinatorial optimization problems.</p>
        <p>A combinatorial optimization problem is specified formally by a set of problem
instances and is either a minimization problem or a maximization problem. An
instance of a combinatorial minimization problem is a pair (X , f ), where the solution
set X is the set of all feasible solutions and the cost function f is a mapping f :
X ← R. The problem is to find a globally optimal solution, i.e. an x∗ ∈ X such that
f (x∗) ≤ f (x) for all x ∈ X . Maximization problems can be trivially transformed
into minimization problems by changing the sign of the cost function f .</p>
        <p>Salient examples are the traveling sales problem and related routing and
transportation problems, scheduling and time-tabling, cutting and packing tasks. Most
of these problems are NP-hard. However NP-hardness does not necessarily mean
that all practically relevant instances are not solveable within acceptable time. Vice
versa, an algorithm for a polynomial-time solvable problem might be too expensive
in practice.</p>
        <p>Many different algorithmic strategies exist to deal with this problems and the
metaheuristics, which are the main topic of this work, are among of them.
Traditionally metaheuristics are considered as solution methods utilizing an interaction
between local improvement procedures and higher level strategies to overcome local
optima leading to a robust search process. In general metaheuristics contain are not
designed for a specific optimization problem. They rather can be applied to a wide
range of problems. Therefore many metaheuristics can be implemented in a generic
manner straighforward.</p>
        <p>For the library at hand five initial metaheuristics were chosen for implementation
which are local search, simulated annealing, tabu search, guided local search and
greedy randomized adaptive search procedures.
1.3</p>
      </sec>
      <sec id="sec-2-5">
        <title>Guide to the thesis</title>
        <p>The thesis at hand describes the quadratic assignment problem in Chapter 2 which
we chose as an example problem to demonstrate the application of EAlib to a new
task and to illustrate the pros and cons of the implemented metaheuristics. In
Chapter 3 all featured algorithms are explained. The requirements of functionality,
design and usability of the targeted library are specified in Chapter 4 while the details
of the implemented library are stated in Chapter 5. Finaly experimental results of
solving the quadratic assignment problem using the new EAlib are presented in
Chapter 6.</p>
        <p>Science is organized knowledge. Wisdom is organized life.</p>
        <p>
          Imanuel Kant
Chapter 2
Quadratic Assignment Problem
Since the quadratic assignment problem (QAP) was mentioned first by Koopmans
and Beckmann [23] in 1957, they used the QAP to model economic activities, many
authors contributed to it, see Loiola et al. [
          <xref ref-type="bibr" rid="ref7">27</xref>
          ] for a recent survey article about
the QAP. The major attraction points of the QAP are its practical and theoretical
importance and its computational complexity — it is one of the most difficult
combinatorial optimization problems. In general problem instances of size n ≥ 30 can not
be solved in reasonable time. Sahni and Gonzales [39] had first shown that the QAP
is a member of the class of NP-hard problems and that, unless P = NP, it is not
possible to find a polynomial -approximation algorithm, for a constant .
Nevertheless recent results (Gutin and Yeo [20]) proved that, in the case of QAP, polynomial
approximations with factorial domination number exist. For more information on
the theory of NP-completeness Garey and Johnson [
          <xref ref-type="bibr" rid="ref3">14</xref>
          ] is recommended.
        </p>
        <p>
          Since the QAP is very versatile, several other NP-hard combinatorial
optimization problems such as traveling salesman problem (TSP), graph partitioning, the
bin-packing problem (BPP) or the max clique problem can be formulated and solved
using QAPs [
          <xref ref-type="bibr" rid="ref7">5, 27</xref>
          ].
        </p>
        <p>Prior to an exact definition of the QAP, a simpler related problem, the linear
assignment problem (LAP), is presented as a smoother introduction assignment.
After a short description of the LAP, a comprehensive explanation of the QAP, which
will cover a problem definition and various mathematical formulation approaches,
resolution methods and finally applications, will be provided.
2.1</p>
      </sec>
      <sec id="sec-2-6">
        <title>Problem</title>
      </sec>
      <sec id="sec-2-7">
        <title>Description</title>
        <p>Assigning objects is a common task for econimic or techinical staff. Therefore it
is not a surprise that assigment problems are among the greatest challanges in the
area of combinatorial optimization.</p>
        <p>As an introduction the linear assignment problem (LAP) is presented here.
Assume there are two equal sized sets of objects, e.g. persons and jobs, and they are
assigned to each other by making up pair of those objects, taking one from each set
for a pair. Additionally every possible pair is given a value, which results in a n × n
matrix with n2 elements. The problem now is to find an assignment of all objects
for which the sum of the values is minimized. An example application for the LAP
is the assignment of persons to jobs.</p>
        <p>Mathematically this problem can be formulated as follows.</p>
        <p>
          n
min X ai,π(i)
π∈Π i=1
(2.1)
where A = [ai,π(i)] is the matrix of values for assigning object i to π(i) and further
Π is the set of all permutations of the n elements {1, . . . , n}. The LAP is polynomial
and is easily solved by the Hungarian method [
          <xref ref-type="bibr" rid="ref7">27</xref>
          ] which was proposed by Harold
W. Kuhn in 1955 [24].
        </p>
        <p>Reconsidering the above description the question arises if it really true that
an assignment of two objects does not have any sideeffects on other assignments.
If this assumption does not hold, the quadratic assignemnt problem may give an
appropriate formal description of the real-world problem.</p>
        <p>QAP is a generalization of in the linear assignment problem in a manner that
assignment can affect each another. Therefore, in addition to the value matrix —
when using QAPs it is called distance matrix — a flow matrix of same dimension
is introduced. As an example that is related to the previous mentioned one with
persons and jobs, the distance matrix can be interpreted as the distance between
the offices and the flow as the amount of interaction between these persons.</p>
      </sec>
      <sec id="sec-2-8">
        <title>Formulations</title>
        <p>
          Nowadays many different formulations are used. Loiola et al. [
          <xref ref-type="bibr" rid="ref7">27</xref>
          ] and Commander
and Pardalos [9] give a good survey over the existing formulations of the quadratic
assignment problem, different resolution methods, lower bound calculation and
applications.
2.2.1
        </p>
        <p>Permutation Formulation
As an introduction the popular and very intuitive formulation is based on
permutations is given. Thereby the QAP can be stated as follows. Let A, B and C be n × n
matrices representing flows between objects, distances between locations and costs
for assigning objects to locations, further let Π be the set of all possible permutations
of the n elements {1, . . . , n}.</p>
        <p>n n n
min X X ai,j bπ(i),π(j) + X ci,π(i)
π∈Π i=1 j=1 i=1
ai,j is the flow between objects i and j, bπ(i),π(j) is the distance between locations
π(i) and π(j) and ci,π(i) is the fixed cost of assigning object i to location π(i).</p>
        <p>The formulation given contains a linear part to model fixed assignment cost.
However many authors neglect this term of the equation, since it is a LAP and thus
easy to be solved, e.g. with the Hungarian method, or because they do not need this
term for their considerations; the resulting formulation is stated below:
n n
min X X ai,jbπ(i),π(j)
π∈Π i=1 j=1
(2.2)
(2.3)</p>
        <p>In the implementation of this master thesis we used the term to be minimized in
the above formula as objective function. Consequently our solution representation
consists of the permutation vector π.
2.2.2</p>
        <p>Integer Linear Programming
Koopmans and Beckman [23] used a different formulation in their initial statement
of the quadratic assignment problem; the so-called integer linear programming (IP)
formulation. It is still of great use, since IP is a topic of ongoing research. In this
formulation the reader also can see why the problem is called quadratic, which is
not so obsious in some of the other formulations.</p>
        <p>The general IP formulation is as follows. Let A = [ai,j] be a matrix of flows
between objects i and j and further B = [bk,p] a matrix of the distances between
positions k and p and lastly C = [ci,k] a matrix of costs for assigning object i to
position k:</p>
        <p>n n
min X X ai,jbk,pxi,jxk,p +
i,j=1 k,p=1</p>
        <p>n
s.t. X xi,j = 1
i=1
n
X xi,j = 1
j=1
xi,j ∈ {0, 1}</p>
        <p>n
X ci,kxi,k
i,k=1
1 ≤ j ≤ n,
1 ≤ i ≤ n,
1 ≤ i, j ≤ n.
(2.4)
(2.5)
(2.6)
(2.7)
(2.8)
(2.9)
(2.10)</p>
        <p>The actual QAP is the problem of minizing equation above, by proper choice of
the permutation matrix X = [xi,j]. The minimand contains a term of second degree
in the unknown permutation matrix X and therefor the problem is called quadratic.</p>
        <p>For the same reason as in the prior section the linear term regarding the fixed
costs of assigning objects to locatinos can be neglected, leading to the following
formulation:</p>
        <p>n n
min X X ai,j bk,p xi,j xk,p</p>
        <p>i,j=1 k,p=1
s.t. (2.5), (2.6) and (2.7).
2.2.3</p>
        <p>Trace Formulation
Since the essential information about an actual QAP instance is represented usually
with matrices it is not surprising that a formulation evolved which takes advantage of
this; the trace formulation is an approach to mathematically describe the QAP that
uses the trace of a matrix which is defined by trace A = Pn
i ai,i. It was introduced
by Edwards [10]. Again consider A = [ai,j] a matrix of flows from object i to object
j, B = [bk,p] distances of location k and p and C = [ci,k] costs of assigning object i
to location k.</p>
        <p>min trace (AXBT + C)XT</p>
        <p>X∈Π
repectively with the linear term of the problem omitted:
min trace (AXBT )XT</p>
        <p>X∈Π
where Π is the set of all n × n permutation matrices. It is often used in lower
bounds related publications.
2.3</p>
      </sec>
      <sec id="sec-2-9">
        <title>Lower Bounds</title>
        <p>The knowledge of lower bounds is fundamental when developing optimization
algorithms to solve combinatorial or other mathematical problems. This importance of
lower bounds is two-fold. At first they are an essential part of exact algorithms,
e.g. branch-and-bound procedures. These methods, while attempting to guarantee
the global optimum, also try to avoid the total enumeration of the complete search
space. Therefore the performance of such methods depends strongly on the
computational quality and efficiency of the utilized lower bounding techniques. An other
application of lower bounds is the evaluation of the quality of solutions obtained by
some heuristic algorithms (see Section 6.1 on page 52).</p>
        <p>The quality of the lower bound can be measured by the gap between the
computed bound with the known optimal solution, this referred to as the tightness of
the bound, i.e. good lower bounds are closer to the global optimum. For an exact
algorithm a good bounding technique, which can find the bounds quickly1, should be
used. When used in heuristics, lower bound quality is the most important property.</p>
        <p>
          One of the first suggested and best known lower bounds for the quadratic
assignment problem is the one presented by Gilmore [
          <xref ref-type="bibr" rid="ref4">15</xref>
          ] and Lawler [25]. The
GilmoreLawler-Bound (GLB) is given by the solution of linear assignment problem whose
cost matrix is gained by special inner products of the flow- and distance-matrix of
the original QAP. The advantage of the GLB is that is simple and it can be
computed efficiently. However, its drawback is that the gap to the optimal solution
grows with the size of problem. For this reason the GLB is a weak bound for larger
problem instances.
        </p>
        <p>Due to an intensive research activity many other lower bounds have been
discoverd. Bounds based on mixed integer linear programming (MILP) relaxations,
eigenvalues of the flow- and distance matrix, reformulations of the above mentioned
GLB exist. Some of them, e.g. eigenvalue based bounds, really outperform the
original GLB so far tightness is concerned, but they suffer from high computation
requirements. The most recent and promising research trends are based on semidefinite
programming (SDP), reformulation linearization. Anstreicher and Brixius [1]
presented a lower bound for the QAP based on semidefinite and convex quadratic
programming, a bound using the bundle method is proposed by Rendl and Sotirov [36].</p>
        <p>1Up to now no bound that features both advantages, tightness and computational cheapness
has been discovered.
2.4</p>
      </sec>
      <sec id="sec-2-10">
        <title>Solution Methods</title>
        <p>Since its statement, many different approaches were applied to solve the quadratic
assignment problem. These can be categorized in either exact or heuristic methods.
In this section we an overview about some of the most successfull or frequent used
methods of these categories are presented.
The oldest and simplest way, to resolve the quadratic assignment problem, is
enumeration. This causes evaluation of the objective function for all n! possible
permutations and memorizing the best found solutions; note that there is not necesssarily
only oneoptimal solution. The computational effort for evaluating the cost of a
permutation requires O(n2) steps, which has to be computed O(n!) times yielding
exponentially sized computation times. Enumeration is very simple to code and has
small memory requirements, on the other hand its use is very limited and not of
practical relevance.</p>
        <p>Other methods include quadratic programming, which reformulates the problem
as a 0–1 program (see Section 2.2.2 on page 9) and linear programming, which
linearizes the QAP by introducing new variables, the resulting linear program can
be solved e.g. with mixed integer linear programming methods.</p>
        <p>Many of the above methods share the same problem; they vastly examine the
complete search space and therefore, as mentioned, only small problem instances
can be solved within a reasonable amount time.</p>
        <p>The most successful exact resolution methods for the quadratic assignment
problem incorporate branch-and-bound (BB) algorithms. Essential for BB is a good
bounding technique, because this directly affects the extent to which the search
space must be enumerated; the thighter the used bound, the more solutions can be
excluded from the exploration.</p>
        <p>
          Branch-and-bound methods attract many researchers due to their potential. For
example Frazer [
          <xref ref-type="bibr" rid="ref2">13</xref>
          ] and Brixius and Anstreicher [5] describe a BB implementation
and Anstreicher et al. [2] describe a grid enabled BB implementation which was used
to solve a problem instance of size 30 to optimality. They report the utilization of
an average of 650 worker machines over a one-weekend period, which provides the
equivalent of almost 7 years of computation on one single HP9000 C3000
workstation. For an other instance of the same size they utilized the equivalent of 15 years
on a single C3000. These examples show the potential of parallelization, which is
currently one of the major fields of interest.
2.4.2
        </p>
        <p>Heuristics
Heuristic algorithms, contrary to exact algorithms, can not provide any guarantee
of optimality for the best solution obtained. The reason for the current research
on suboptimal solution methods is the fact that many of them can provide good
solutions within reasonable time constraints, which is often necessary real-world
application environments. Heuristic methods include the following categories:
constructive, enumeration and improvement methods.</p>
        <p>
          Constructive methods, which are among the earliest heuristics to solve the QAP,
try to complete a permutation with each iteration of the algorithm. The
selection of each assignment is based on a heuristic selection criterion. For example
Gilmore [
          <xref ref-type="bibr" rid="ref4">15</xref>
          ] introduced one of the first constructive algorithms. Nowadays
this category of heuristics focuses new interest because metaheuristics, such as
the greedy randomized adaptive search procedure (see Section 3.5 on page 27)
incorporate them.
        </p>
        <p>Enumerative methods are motivated by the expectation that an acceptable
solution can be found early during a brute force exploration of the search space.
For interesting problems these methods do not enumerate the all feasible
solutions and therefore different termination criteria are used. Usually the number
of total iterations, or iterations between successive improvements is used, other
common criteria include a limit on the total execution time or lowering the
upper bound when no further improvements are possible after a number of
iterations. It is important to remind that any of these termination criteria can
prohibit the finding of an optimal solution.</p>
        <p>Improvement methods correspond to local search algorithms (see Section 3.1 on
page 19. Most of the heuristics for the QAP are part of this category.</p>
        <p>An other worthy to mention category of methods are approximate algorithms,
which are heuristics provinding quality guarantees for their solutions.
2.4.3</p>
        <p>Metaheuristics
Metaheuristics are, as their name suggests, heuristic algorithms too, but usually
they can be adapted straighforward to a wide range of different problems; this is in
general not possible for traditional heuristics. However, as the main focus of this
master thesis lays on metaheuristcs we address them extensively in the next chapter.
2.4.4</p>
        <p>Research Trends
Current state of the art algorithms can be divided into two major categories, at one
side the search for optimal solutions and exact algorithms which can provide them,
and on the other side methods that can provide solutions that are good enough in
reasonable time. Of course also theoretical developments are of interest.</p>
        <p>The main research focus for the QAP is generated by the growing interest on
metaheuristics since the end of the 1980’s because it is a popular benchmark to
compare algorithms. With recent generations of computer technology the QAP attracted
new attention, which lead to honorable developments in parallel algorithms.</p>
        <p>Promising future developments seem to be possible through the hybridization of
several algorithms, which generated some interest in the past, together with
parallelization.
2.5</p>
      </sec>
      <sec id="sec-2-11">
        <title>Applications</title>
        <p>The initial motivation that lead to the formulation of the quadratic assignment
problem was:</p>
        <p>In the light of the practical and theoretical importance of
indivisibilities, it may seem surprising that we possess so little in the way of
successful formal analysis of production problems involving indivisible
resources. (Koopmans and Beckmann [23])
[...]</p>
        <p>The assumption that the benefit from an economic activity at some
location does not depend on the uses of other locations is quite
inadequate to the complexities of locational decisions.</p>
        <p>As the quoted statement suggests, a main field applications is allocation of
resources with complex interactions of the individual resources. Koopmans and
Beckmann were economists and therefore their focus was on economic activities. Example
applications are scheduling of jobs or production lines, facility organization,
hospital layout. Nevertheless the QAP is also of practical use where it is not so obvious
like dartboard design or typewriter layout. Not to forget many engineering
applications. In the remainder of this section we illustrate two applications of the quadratic
assignment problem in detail.
2.5.1</p>
        <p>Steinberg Wiring Problem
In a 1961 paper [40], Leon Steinberg proposed a backboard wiring problem. The
problem is about the optimal placement of computer components on a backboard in
such a manner, that the total interconnecting wiring length is minimized. Improved
wiring length has two main advantages, most important it increases the performance
of the designed system, not less attractive are the decreased manufacturing costs.
The original problem instance consisted of 34 components with a total of 2625
interconnections which were to be placed on a backboard with 36 open positions (circles
in Figure 2.2).</p>
        <p>1
2
3
4
5
6
7
8</p>
        <p>9
10 11 12 13 14 15 16 17 18
19 20 21 22 23 24 25 26 27
28 29 30 31 32 33 34 35 36</p>
        <p>Two dummy components, with no connections to any other components, are
added so that the number of components equals the number of open positions. The
use of dummy elements is a common trick to be able to formulate real-world problems
as QAPs. With this addition the mathematical formulation can be given
where ai,k is the number of wires interconnection components i and k, bj,l is the
distance between positions j and l on the backboard and xi,j = 1 if component
i is placed at position j. Special attention is payed on the choice of the bj,l. In
the original paper Steinberg considered using 1-norm, 2-norm or squared 2-norm
distances. He further concentrated on obtaining good solutions for the 2-norm and
squared 2-norm versions of the problem. However, research interest has been directed
to the 1-norm version, which was also used by Brixius and Anstreicher [6] who
solved the initial problem instance to optimality with an exact branch-and-bound
algorithm, 40 years after its statement. The solution required approximately 186
hours of CPU time on a single Pentium III personal computer.
2.5.2</p>
        <p>Antenna Assembly Sequence Problem
At the National Aeronautics and Space Administration (NASA) another
interesting application of the quadratic assignment problem is reported by Padula and
Kincaid [33]. It is known that NASA often has to design and erect antennas (see
Figure 2.3(a)) in space for different purposes like communication with spacecrafts
(Deep Space Network). Such an antenna consists of a very large number n of truss
elements. For research purposes, the antenna structure is designed as a tetrahedral
truss with a flat top surface, which means that all nodes in the top surface of the
finite-element model are coplanar (see Figure 2.3(b)). To minimize surface
distortions and to the avoid internal forces during the assembly process of the antenna,
the truss elements have to be of identical length. However, due to limitations in the
manufacturing process, the length is never precisely identical. Each truss element
j has a small but measurable error ej. To overcome the impact of these errors, the
truss elements are assembled in such a way, that the errors offset each other.
(a) Antenna configuration
(b) Finite element model</p>
        <p>For a mathematical formulation of the described problem of arranging the truss
elements first, an objective value has to be defined. The objective value of a concrete
arrangement is stated as the squared L2 norm of the surface distortion:
d2 = eT U T D U e
= eT H e
(2.12)
where e is the vector of measured errors, U is the influence matrix such that ui,j
gives the influence of a truss length error in element j on the surface at node i and
D is a positive semidefinite weighting matrix that denotes the relative importance
of each node i at which distortion is measured. The calculation of matrix U is can
be done with any structural analysis software package and the matrix D is often
the identity matrix. Summarizing this, the combinatorial optimization problem for
minimizing antenna distortions is stated as:</p>
        <p>n n
min X X ei hi,j ej
e∈E j=1 i=1
(2.13)
where E are all possible permutations of the error vector e. Clearly the
formulation above is a quadratic assignment problem, although it is not a common
formulation; compare the permutation formulation in equation 2.3 on page 9.</p>
        <p>In case of the antenna assembly sequence problem simulated annealing and tabu
search where applied successfully to solve the problem. Prior to this attempts a
pairwise interchange heuristic was suggested, which was based on a simple basic
local search algorithm. It is not very surprising that the results achieved with local
search where inferior to the ones obtained by simulated annealing or tabu search.</p>
        <p>The main advantage for NASA gained by metaheuristically optimized assembling
of the truss elements standard precision is adequate which decreases the overall costs
since cost for truss elements increase dramatically when unusual precision in length
is required.</p>
        <p>This example shows that an engineering description of a problem can lead directly
to a convenient solution method; however this is not the usual case.</p>
        <p>For a successful technology, reality must take precedence over
public relations, for Nature cannot be fooled.</p>
        <p>
          Richard Feynman
Chapter 3
Metaheuristics
During the last decades a new kind of heuristic algorithms has emerged which tries
to use lower-level heuristic approaches to build higher-level frameworks targeted at
efficiently and effectively exploring a search space. The name metaheuristic, first
introduced in Glover [
          <xref ref-type="bibr" rid="ref5">16</xref>
          ], stems from the composition of two Greek words. Heuristic
derives from the verb heuriskein ( υρισκ ιν) which means “to find” and the prefix
meta means “beyond, in an upper level”.
        </p>
        <p>This category of algorithms includes1 Evolutionary Computing (EC) and Genetic
Algorithms (GA), Guided Local Search (GLS), Greedy Randomized Adaptive Search
Procedure (GRASP), Iterated Local Search (ILS), Simulated Annealing (SA), Tabu
Search (TS), Variable Neighborhood Search (VNS) and many more.</p>
        <p>For example, Glover and Kochenberger [19] and Blum and Roli [4] provide a
survey on metaheuristics and related topics and current state of the art in the
area. In this chapter we focus on the concepts and fundamental principles of the
metaheuristics implemented during this master thesis.</p>
        <p>But before we start off some some terms need to be clearyfied. We consider a
neighborhood structure as a function N : X → 2X , which assigns each valid solution
x ∈ X a set of neighbors N (x) ⊆ X . The set N (x) is commonly named the
neighborhood of x. It is usually defined implicity through valid changes (moves) on
the solutions x ∈ X .</p>
        <p>Furthermore we introduce a search space, i.e. a solution representation and an
objective function. In other words a search space is a collection of possible solutions
to the problem at hand, incorporation some notion of distance between the candidate
solutions.</p>
        <p>1In alphabetical order.
CHAPTER 3. METAHEURISTICS
3.1</p>
      </sec>
      <sec id="sec-2-12">
        <title>Basic Local Search</title>
        <p>Basic local search (LS) is also called iterative improvement or hill-climbing because
at each iteration a move is only performed when the new solution is better than the
current solution, regarding to a defined objective function. A move is defined as the
selection of a solution s0 out of a neighborhood N (s) of a solution s.
procedure Basic Local Search
s ← GenerateInitialSolution()
repeat
s0 ← ChooseNeighbor(N (s))
if f (s0) ≤ f (s) then</p>
        <p>s ← s0
end if
until termination conditions met
end procedure</p>
      </sec>
    </sec>
    <sec id="sec-3">
      <title>Algorithm 1: Basic Local Search</title>
      <p>In Algorithm 1 the basic algorithm is outlined in pseudocode. First of all the most
important task is to define a search space. This means a representation of real-world
objects and an objective function f are needed. Regarding the chosen representation
an appropriate neighborhood structure has to be found. A popular choice for many
combinatorial optimization problems is the 2-opt 2 neighborhood because it can be
applied easy to many problems. Nevertheless, despite some exemptions, 2-opt tends
to get stuck in local optima. Some other neighborhoods are k-flip for binary strings
where the neigborhood consits of all solutions that have a Hamming-Distance less
or equal to k. A generalized 2-opt, k-opt is also known.</p>
      <p>The GenerateInitialSolution function is needed to generate an initial solution at
which the search begins. This could happen simply by a completely random choice
or a more sophisticated construction method. As ChooseNeighbor(N (s)) function,
also called step function, theoretically any function that chooses a solution s0 out of
a neighborhood N (s) of solution s is possible, but it has turned out that only a few
are commonly used:
random neighbor picks a neighboring solution out of N (s) at random.
first improvement systematically searches N (s) and chooses the first neighboring
solution that is better than s.
best improvement completely explores N (s) and takes the best neighboring
solution.</p>
      <p>2A 2-opt move consists of removing two edges of a given solution and reconnect them in a
different way.</p>
      <p>By far the best proof is experience.</p>
      <p>Sir Francis Bacon
Chapter 6
Experimental Results
To be able to compare the results from this different methods many internet available
QAP instances are used, the probably most important collection of instances is the
QAPLIB [7].</p>
      <p>Of special interest are problem instances with a known optimal solution,
especially if they are of larger size. To address this requirement some algorithms for
construction of such instances where proposed, for example the by Palubeckis [34].
6.1</p>
      <sec id="sec-3-1">
        <title>Test Cases</title>
        <p>Because the larger quadratic assignment problem instances are computationally
intractable, suboptimal algorithms such as the previous mentioned heuristics and
metaheuristics are very popular and enjoy wide use. However, when dealing with
new methods the quality and other properties such as robustness are important to
know before they can be applied in daily business or other critical environments.</p>
        <p>Usually new algorithms are tested on QAP instances from the QAPLIB (see
Burkard, Karisch and Rendl [7]) which is a public internet available collection of
well known instances which allows to compare algorithms with each other. However,
the problem when using especially larger benchmark problems from QAPLIB is that
the optimal solutions are not known in general and one has to rely on lower bounds
(see Section 2.3 on page 11).</p>
        <p>To overcome this problem an other set of test cases can be used. Those are
generated by special algorithms whose output are not only the matrices which the
define the problem but also with a provable known optimal solution. It has been
shown that instances generated by such algorithms are rather hard to solve for some
metaheuristics, namely simulated annealing, tabu search and others [34].
6.2</p>
      </sec>
      <sec id="sec-3-2">
        <title>Test Setup and Procedure</title>
        <p>Our tests were performed on an ordinary desktop computer with GNU Linux
installed. The key data of this testing system is listed below:</p>
        <p>CPU
OS</p>
      </sec>
    </sec>
    <sec id="sec-4">
      <title>Compiler</title>
    </sec>
    <sec id="sec-5">
      <title>Intel Pentium 4 2.8 GHz</title>
      <p>Linux 2.4.21
GNU Libc 2.3.2
GCC 3.3.1
binutils 2.14.90.0.5</p>
      <p>We compiled EAlib and our test application for the quadratic assignment problem
with all documented speed optimizations enabled, i.e. with switch -O4.</p>
      <p>The test instances are all included in the already mentioned QAPLIB problem
library. Each algorithm had to solve each instance 25 times, whereat each run had
a time limit of five minutes to complete. The parameter settings for the
particular instances were made upon our knowledge which we obtained during preceeding
experiments.</p>
      <p>In the following tables the parameter settings for each algorithm are given which
were not at their default value.</p>
      <p>During the testruns of local search the tcgen parameter was set so that the
search process could terminate if now improvement was made for 5000 iterations,
which occurred quite of often. However, this parameter setting did not affect the
achieved results significantly.</p>
      <p>For simulated annealing the parameters controlling the temperature schedule
were set to estimated values dependig on the size of the problem instance to solve
and the order of magnitude of the corresponding objective value.</p>
      <p>The parameter tlsize which controls the length of the tabulist was set depending
on the actual problem instance. The value chosen was in order of magnitude of the
size of instance to solve.</p>
      <p>Additionally the tobj parameter has been set accordingly so that each testrun
at which global optimum was found was terminated as soon as this global optimum
was reached. This parameter setting did not change the results but sped up the
experiments significant.
6.3</p>
      <sec id="sec-5-1">
        <title>Results</title>
        <p>For the comparison of the individual algorithms which were implemented and
interpretation of the results four different charaterisic values are used, which in
combination give a good insight into the data obtained during the experiments.
• count of reached optima per problem instance. It is a measure for stability of
the search process. For the overall statistics the sum of the particular instances
is used,
• best objective value per problem instance indicates primarily the potential
quality of the search process,
• mean objective value is a measure for both quality and stability of an algorithm.</p>
        <p>However, outliers can have great influence on its value,
• deviation of objective value indicates the robustness of the search process.</p>
        <p>Obviously the latter three indicators can not be compared directly among
different problem instances. Therefore they are presented in %-gap notation relative to
the known global optimal solution. The %-gap of an objective value x relative to
the global optimum opt is calculated as follows:
% − gap(x, opt) = x −opotpt × 100%
(6.1)</p>
        <p>At first table 6.7 and accordingly figures 6.1 and 6.2 show the overall results of
each algorithm for all test instances together, i.e. the sum of the number of reached
optimas and the mean %-gap across all testruns. With the obtained results no
definitive winning algorithm can be declared. Nevertheless the results show clearly
which of the implemented methods are well suited to solve quadratic assignment
problems.</p>
        <p>Algorithm
Local Search
Simulated Annealing
Tabu Search
Guided Local Search
GRASP
# Opt Mean %-gap</p>
        <p>2 9.22
132 3.47
186 0.91
494 0.29
485 0.12</p>
        <p>Looking at the detailed results presented in follwing tables (6.8, 6.9, 6.10, 6.11
and 6.12) show that guided local search and GRASP are indeed clearly
outperforming the other algorithms.</p>
        <p>This is not very surprising because both guided local search and GRASP include
received considerable more problem dependent knowledge in their implementation
than the other metaheuristics implemented during this master thesis.</p>
        <p>It is also worthy to mention that guided local search and GRASP were the only
algorithms which were able to find distinct optimal solutions if the problem instance
has more than one. This capability is allegable with the major strengths of these
algorithms. GLS gradually moves away from attractive solutions and therefor the
embedded random local search is able to reach widespread areas of the search space.
GRASP operates somewhat different, its strenghts lies the randomized greed
heuristics which, in the optimal case, produces good starting solutions for the embedded
local search procedure, which are distributed among the whole search space.</p>
        <p>An other important feature that table 6.11 and 6.12 show is that the quality of
the obtained solutions only decreases somewhat and so these solutions, altough not
global optimal, can be adequate, too.</p>
        <p>Tabu search also achieved good results in terms of the mean %-gap. However, it
has reached significant fewer global optima than guided local search or GRASP and
the deviation values indicate that the stability of the search process is somewhat
deteriorated. A reason for this behavior is the fixed tabulist length which could
cause a either a lockout of interesting regions of the search space when the tabulist
is too long or the search process gets stuck around a local optimum when the tabulist
is too short.</p>
        <p>The results obtained with the simulated annealing metaheuristc were mixed.
For some problem instances, especially instances from the bur collection and smaller
instances from the other collections, simulated annealing clearly performs better
than tabu search. On the other side some results, e.g. for instances from the chr
collection, are not very satisfactory. This indicates that simulated annealing, in its
traditional fashion, suffers from a worse stability of the obtained results when applied
to the quadratic assignment problem, which could be an effect of the geometric
cooling schedule. An improvement like reheating or an occasional perturbation phase
might yield better solutions.</p>
        <p>As expected local search only yields a few global optimal solutions but although
no global optimal solution was found for many problem instances especially from
the bur set the obtained solutions were nearly optimal. This implies that the chosen
neighborhood structure is well suited for solving the quadratic assignment
problem which is certainly important for the other metaheuristics, too. However, it is
somewhat surprising that only results for the instances from the chr set were very
unsatisfactory.</p>
        <p>The following tables show the results of our tests per algorithm and test instance.</p>
        <p>%-gap
Mean
0.35
0.50
0.36
0.46
0.36
0.43
0.38
0.43
44.35
49.39
47.13
5.81
4.52
4.75
4.65
3.92
4.46
5.65
8.82
4.61
5.89
5.67</p>
        <p>%-gap
Mean
0.14
0.14
0.03
0.03
0.01
0.09
0.02
0.06
4.18
16.68
33.85
0.61
3.66
1.84
2.44
2.93
2.58
0.16
0.62
1.58
1.75
2.89</p>
        <p>%-gap
Mean
0.19
0.37
0.22
0.31
0.25
0.40
0.13
0.45
1.18
0.00
8.85
1.36
0.87
1.26
1.16
0.63
0.75
0.04
0.00
0.19
1.00
0.52</p>
        <p>%-gap
Mean
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.93
5.22
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.26</p>
        <p>%-gap
Mean
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
2.02
0.00
0.00
0.00
0.00
0.00
0.30
0.00
0.00
0.00
0.00
0.23</p>
        <p>In the following figures the results of the algorithms are grouped per test instance
to show which instances were tackled best by what algorithms.
Chapter 7
Conclusions
After an elaborated introduction of the quadratic assignment problem and the
implemented metaheuristics this thesis presented a generic library for metaheuristics
and its application to the QAP.</p>
        <p>The already existing foundations of the EAlib library have been improved to meet
the requirements for the new generic metaheuristics. In particular interfaces classes
have been introduced that allow fine grained modelling of new classes and support
runtime queries for implemented features of specific components. Additionally the
parameter handling mechanism has been extended with parameter groups that allow
to denote different groups of parameter values for different components in EAlib.</p>
        <p>With this enhanced EAlib generic versions of the local search, simulated
annealing, tabu search, guided local search and greedy randomized adapetive search
procedure metaheuristics have been implemented. The latter two algorithms also
introduced an efficient way of handling an embedded algorithm.</p>
        <p>All considered metaheuristics have then been applied to the quadratic assignment
problem which showed that only some special parts need to be implemeted separately
and most of the problem dependent sourcecode can be shared among all algorithms
involved.</p>
        <p>Of course there are many interesting and useful ideas and task left open for future
work.</p>
        <p>• implement more interesting algorithms like antcolony optimization, variable
neighborhood search or iterated local search,
• add more “standard” features to the implemented algorithms, e.g. dynamic
tabulist length, reheating, disturbance methods
• itegrate useful template chromosomes, e.g. a generic string chromosome,
• provide additional language bindings e.g. for Java and C#.
2.1 A quadratic assignment example . . . . . . . . . . . . . . . . . . . . . 8
2.2 Original Backboard of the Steinberg Wiring Problem . . . . . . . . . 15
2.3 Conceptual design of a large space antenna (from [33]) . . . . . . . . 16
(a) Antenna configuration . . . . . . . . . . . . . . . . . . . . . . . 16
(b) Finite element model . . . . . . . . . . . . . . . . . . . . . . . . 16
3.1 Escaping a local optimum with GLS . . . . . . . . . . . . . . . . . . 25
6.1 Overall mean %-gap . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
6.2 Overall count of reached global optima . . . . . . . . . . . . . . . . . 57
6.3 Mean %-gap for bur Instances . . . . . . . . . . . . . . . . . . . . . . 63
6.4 Mean %-gap for chr instances . . . . . . . . . . . . . . . . . . . . . . 64
6.5 Mean %-gap for nug instances . . . . . . . . . . . . . . . . . . . . . . 64
6.6 Mean %-gap for tai instances . . . . . . . . . . . . . . . . . . . . . . 65
[1] Anstreicher, K. M., and Brixius, N. W. A New Bound for the Quadratic
Assignment Problem Based on Convex Quadratic Programming. Mathematical
Programming 89, 3 (2001), 341–357.
[2] Anstreicher, K. M., Brixius, N. W., Goux, J.-P., and Linderoth, J.</p>
        <p>Solving large quadratic assignment problems on computational grids.
Mathematical Programming 91, 3 (February 2002), 563–588.
[3] Battiti, R., and Tecchiolli, G. The reactive tabu search. ORSA Journal
on Computing 6, 2 (1994), 126–140.
[4] Blum, C., and Roli, A. Metaheuristics in combinatorial optimization:
Overview and conceptual comparison. ACM Computing Surveys 35, 3 (2003),
268–308.
[5] Brixius, N. W., and Anstreicher, K. M. Solving quadratic assignment
problems using convex quadratic programming relaxations. Optimization
Methods and Software 16 (2001), 49–68.
[6] Brixius, N. W., and Anstreicher, K. M. The Steinberg Wiring
Problem. In The Sharpest Cut: The Impact of Manfred Padberg and His Work,
M. Gro¨tschel, Ed. SIAM, June 2004.
[7] Burkard, R., Karisch, S., and Rendl, F. QAPLIB - A Quadratic
Assignment Problem Library. Journal of Global Optimization 10 (1997), 391–403.
http://www.seas.upenn.edu/qaplib/.
[8] Cerny, V. Thermodynamical Approach to the Traveling Salesman Problem:
An Efficient Simulation Algorithm. Journal of Optimization Theory and
Applications 45, 1 (1985), 41–51.
[9] Commander, C. W., and Pardalos, P. M. A Survey of the Quadratic
Assignment Problem, with Applications. Submitted to The Moreahead Electronic
Journal of Applicable Mathematics, April 2003.
[10] Edwards, C. The derivation of a greedy approximator for the Koopmans–
Beckmann quadratic assigment problem. In Proceedings of the 77-th
Combinatorial Programming Conference (CP77) (1977), pp. 55–86.
[11] Feo, T. A., and Resende, M. G. C. A probabilistic heuristic for a
computationally difficult set covering problem. Operations Research Letters 8 (April
1989), 67–71.
[18] Glover, F. W. Tabu Search — Part II. ORSA Journal on Computing 2, 1
(1990), 4–32.
[19] Glover, F. W., and Kochenberger, G. A., Eds. Handbook of
Metaheuristics, vol. 57 of International series in operations research and
management science. Kluwer Academic Publishers, Boston Hardbound, 2003.
[20] Gutin, G., and Yeo, A. Polynomial approximation algorithms for the TSP
and the QAP with a factorial domination number. Discrete Applied
Mathematics 119, 1–2 (June 2002), 107–116.
[21] Henderson, D., and Jacobson, S. H. The Theory and Practice of
Simulated Annealing. In Handbook of Metaheuristics, F. W. Glover and G. A.
Kochenberger, Eds., vol. 57 of International series in operations research and
management science. Kluwer Academic Publishers, Boston Hardbound, 2003,
ch. 10, pp. 287–319.
[22] Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. Optimization by</p>
        <p>Simulated Annealing. Science 220, 4598 (May 1983), 671–680.
[23] Koopmans, T. C., and Beckmann, M. Assignment Problems and the
Location of Economic Activities. Economethica, Journal of the Econometric
Society 25, 1 (January 1957), 53–76.
[24] Kuhn, H. W. The Hungarian method for the assignment problem. Naval</p>
        <p>Research Logistics Quarterly 2 (1955), 83–97.
[25] Lawler, E. L. The Quadratic Assignment Problem. Management Science 9
(1963), 586–599.
[26] Li, Y., Pardalos, P. M., and Resende, M. A Greedy Randomized
Adaptive Search Procedure for the Quadratic Assignment Problem. In Quadratic
assignment and related problems, P. M. Pardalos and H. Wolkowicz, Eds., vol. 16
of DIMACS Series on Discrete Mathematics and Theoretical Computer Science.</p>
        <p>American Mathematical Society, 1994, pp. 237–261.
[33] Padula, S. L., and Kincaid, R. K. Aerospace Applications of Integer and
Combinatorial Optimization. NASA Technical Memorandum 110210, NASA,
Langley Research Center, Hampton, Virginia 23681-0001, October 1995.
[34] Palubeckis, G. An Algorithm for Construction of Test Cases for the</p>
        <p>Quadratic Assigmnet Problem. Informatica 11, 3 (2000), 281–296.
[35] Raidl, G. EAlib 1.1 – A Generic Library for Metaheuristics. Institute of</p>
        <p>Computer Graphics and Algorithms, Vienna University of Technology, 2004.
[36] Rendl, F., and Sotirov, R. Bounds for the Quadratic Assignment Problem</p>
        <p>Using the Bundle Method, August 2003.
[37] Resende, M. G. C. Greedy Randomized Adaptive Search Procedures. In
Handbook of Metaheuristics, F. W. Glover and G. A. Kochenberger, Eds., vol. 57
of International series in operations research and management science. Kluwer
Academic Publishers, Boston Hardbound, 2003, ch. 8, pp. 219–249.
[38] Resende, M. G. C., and Ribeiro, C. C. Parallel Greedy Randomized
Adaptive Search Procedures. Tech. Rep. TD-67EKXH, AT&amp;T Labs Research,
December 2004.
[39] Sahni, S., and Gonzales, T. P-Complete Approximation Problems. Journal
of the ACM 23, 3 (July 1976), 555–565.
[40] Steinberg, L. The Backboard Wiring Problem: A Placement Algorithm.</p>
        <p>SIAM Review 3, 1 (1961), 37–50.</p>
      </sec>
    </sec>
  </body>
  <back>
    <ref-list>
      <ref id="ref1">
        <mixed-citation>
          [12]
          <string-name>
            <surname>Feo</surname>
            ,
            <given-names>T. A.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Resende</surname>
          </string-name>
          ,
          <string-name>
            <surname>M. G. C.</surname>
          </string-name>
          <article-title>Greedy Randomized Adaptive Search Procedures</article-title>
          .
          <source>Journal of Global Optimization</source>
          <volume>6</volume>
          ,
          <issue>2</issue>
          (March
          <year>1995</year>
          ),
          <fpage>109</fpage>
          -
          <lpage>133</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref2">
        <mixed-citation>
          [13]
          <string-name>
            <surname>Frazer</surname>
            ,
            <given-names>M.</given-names>
          </string-name>
          <article-title>Exact Solution of the Quadratic Assignment Problem</article-title>
          ,
          <year>April 1997</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref3">
        <mixed-citation>
          [14]
          <string-name>
            <surname>Garey</surname>
            ,
            <given-names>M. R.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Johnson</surname>
          </string-name>
          , D. S.
          <article-title>Computers and Intractability; A Guide to the Theory of NP-Completeness. A series of books in the mathematical sciences</article-title>
          . W.H. Freeman and Company, New York, NY,
          <year>1979</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref4">
        <mixed-citation>
          [15]
          <string-name>
            <surname>Gilmore</surname>
            ,
            <given-names>P. C.</given-names>
          </string-name>
          <article-title>Optimal and Suboptimal Algorithms for the Quadratic Assignment Problem</article-title>
          .
          <source>SIAM Journal on Applied Mathematics</source>
          <volume>10</volume>
          (
          <year>1962</year>
          ),
          <fpage>305</fpage>
          -
          <lpage>313</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref5">
        <mixed-citation>
          [16]
          <string-name>
            <surname>Glover</surname>
            ,
            <given-names>F. W.</given-names>
          </string-name>
          <article-title>Future paths for integer programming and links to artificial intelligence</article-title>
          .
          <source>Computers and Operations Research</source>
          <volume>13</volume>
          ,
          <issue>5</issue>
          (May
          <year>1986</year>
          ),
          <fpage>533</fpage>
          -
          <lpage>549</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref6">
        <mixed-citation>
          [17]
          <string-name>
            <surname>Glover</surname>
            ,
            <given-names>F. W.</given-names>
          </string-name>
          <string-name>
            <surname>Tabu Search - Part</surname>
            <given-names>I</given-names>
          </string-name>
          .
          <source>ORSA Journal on Computing 1</source>
          ,
          <issue>3</issue>
          (
          <year>1989</year>
          ),
          <fpage>190</fpage>
          -
          <lpage>206</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref7">
        <mixed-citation>
          [27]
          <string-name>
            <surname>Loiola</surname>
            ,
            <given-names>E. M.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>de Abreu</surname>
            ,
            <given-names>N. M. M.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Boaventura-Netto</surname>
            ,
            <given-names>P. O.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Hahn</surname>
            ,
            <given-names>P.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Querido</surname>
            ,
            <given-names>T.</given-names>
          </string-name>
          <article-title>An analytical Survey for the Quadratic Assignment Problem</article-title>
          ,
          <year>2004</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref8">
        <mixed-citation>
          [28] Lourenc¸o,
          <string-name>
            <given-names>H. R.</given-names>
            ,
            <surname>Martin</surname>
          </string-name>
          ,
          <string-name>
            <surname>O. C.</surname>
          </string-name>
          , and Stu¨tzle,
          <string-name>
            <surname>T.</surname>
          </string-name>
          <article-title>A Beginner's Introduction to Iterated Local Search</article-title>
          .
          <source>In Proceedings of MIC'2001-Meta-heuristics International Conference (July</source>
          <year>2001</year>
          ), vol.
          <volume>1</volume>
          , pp.
          <fpage>1</fpage>
          -
          <lpage>6</lpage>
          . Porto, Portugal.
        </mixed-citation>
      </ref>
      <ref id="ref9">
        <mixed-citation>
          [29] Lourenc¸o,
          <string-name>
            <given-names>H. R.</given-names>
            ,
            <surname>Martin</surname>
          </string-name>
          ,
          <string-name>
            <surname>O. C.</surname>
          </string-name>
          , and Stu¨tzle, T. Iterated Local Search. In Handbook of Metaheuristics,
          <string-name>
            <given-names>F. W.</given-names>
            <surname>Glover</surname>
          </string-name>
          and
          <string-name>
            <given-names>G. A.</given-names>
            <surname>Kochenberger</surname>
          </string-name>
          , Eds., vol.
          <volume>57</volume>
          of International series in operations research and management science. Kluwer Academic Publishers, Boston Hardbound,
          <year>2003</year>
          , ch. 11, pp.
          <fpage>321</fpage>
          -
          <lpage>353</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref10">
        <mixed-citation>
          [30]
          <string-name>
            <surname>Mart</surname>
          </string-name>
          <article-title>´ı, R. Multi-Start Methods</article-title>
          . In Handbook of Metaheuristics,
          <string-name>
            <given-names>F. W.</given-names>
            <surname>Glover</surname>
          </string-name>
          and
          <string-name>
            <given-names>G. A.</given-names>
            <surname>Kochenberger</surname>
          </string-name>
          , Eds., vol.
          <volume>57</volume>
          of International series in operations research and management science. Kluwer Academic Publishers, Boston Hardbound,
          <year>2003</year>
          , ch. 12, pp.
          <fpage>355</fpage>
          -
          <lpage>368</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref11">
        <mixed-citation>
          [31]
          <string-name>
            <surname>Metropolis</surname>
            ,
            <given-names>N.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Rosenbluth</surname>
            ,
            <given-names>A.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Rosenbluth</surname>
            ,
            <given-names>M. N.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Teller</surname>
            ,
            <given-names>A. H.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Teller</surname>
            ,
            <given-names>E.</given-names>
          </string-name>
          <article-title>Equation of State Calculations by Fast Computing Machines</article-title>
          .
          <source>Journal of Chemical Physics</source>
          <volume>21</volume>
          ,
          <issue>6</issue>
          (
          <year>June 1953</year>
          ),
          <fpage>1088</fpage>
          -
          <lpage>1092</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref12">
        <mixed-citation>
          [32]
          <string-name>
            <surname>Mills</surname>
            ,
            <given-names>P.</given-names>
          </string-name>
          ,
          <string-name>
            <surname>Tsang</surname>
            ,
            <given-names>E. P. K.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Ford</surname>
            ,
            <given-names>J. Applying</given-names>
          </string-name>
          <article-title>an extended Guided Local Search to the Quadratic Assignment Problem</article-title>
          .
          <source>Annals of Operations Research</source>
          <volume>118</volume>
          ,
          <issue>1</issue>
          (Feburary
          <year>2003</year>
          ),
          <fpage>121</fpage>
          -
          <lpage>135</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref13">
        <mixed-citation>
          [41]
          <string-name>
            <surname>Taillard</surname>
            ,
            <given-names>E. D.</given-names>
          </string-name>
          <article-title>Robust taboo search for the quadratic assignment problem</article-title>
          .
          <source>Parallel Computing</source>
          <volume>17</volume>
          ,
          <fpage>4</fpage>
          -
          <lpage>5</lpage>
          (
          <year>July 1991</year>
          ),
          <fpage>443</fpage>
          -
          <lpage>455</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref14">
        <mixed-citation>
          [42]
          <string-name>
            <surname>Tsang</surname>
            ,
            <given-names>E. P. K.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Voudouris</surname>
            ,
            <given-names>C.</given-names>
          </string-name>
          <article-title>Fast Local Search and Guided Local Search and Their Application to British Telecom's Workforce Scheduling Problem</article-title>
          .
          <source>Tech. Rep. CSM-246</source>
          , Department of Computer Science, University of Essex,
          <source>Colchester CO4 3SQ</source>
          ,
          <year>August 1995</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref15">
        <mixed-citation>
          [43]
          <string-name>
            <surname>Tsang</surname>
            ,
            <given-names>E. P. K.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Wang</surname>
            ,
            <given-names>C. J. A Generic</given-names>
          </string-name>
          <string-name>
            <surname>Neural</surname>
          </string-name>
          <article-title>Network Approach for Constraint Satisfaction Problems</article-title>
          . In Neural Network Applications,
          <string-name>
            <surname>J. G</surname>
          </string-name>
          . Taylor, Ed. Springer-Verlag,
          <year>1992</year>
          , pp.
          <fpage>12</fpage>
          -
          <lpage>22</lpage>
          .
        </mixed-citation>
      </ref>
      <ref id="ref16">
        <mixed-citation>
          [44]
          <string-name>
            <surname>Voudouris</surname>
            ,
            <given-names>C.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Tsang</surname>
            ,
            <given-names>E. P. K.</given-names>
          </string-name>
          <string-name>
            <surname>Guided Local</surname>
          </string-name>
          <article-title>Search</article-title>
          .
          <source>Tech. Rep. CSM-247</source>
          , Department of Computer Science, University of Essex, Colchester, C04 3SQ, UK,
          <year>August 1995</year>
          .
        </mixed-citation>
      </ref>
      <ref id="ref17">
        <mixed-citation>
          [45]
          <string-name>
            <surname>Voudouris</surname>
            ,
            <given-names>C.</given-names>
          </string-name>
          , and
          <string-name>
            <surname>Tsang</surname>
            ,
            <given-names>E. P. K.</given-names>
          </string-name>
          <string-name>
            <surname>Guided Local</surname>
          </string-name>
          <article-title>Search</article-title>
          . In Handbook of Metaheuristics,
          <string-name>
            <given-names>F. W.</given-names>
            <surname>Glover</surname>
          </string-name>
          and
          <string-name>
            <given-names>G. A.</given-names>
            <surname>Kochenberger</surname>
          </string-name>
          , Eds., vol.
          <volume>57</volume>
          of International series in operations research and management science. Kluwer Academic Publishers, Boston Hardbound,
          <year>2003</year>
          , ch. 7, pp.
          <fpage>185</fpage>
          -
          <lpage>217</lpage>
          .
        </mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>